/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/builder.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/builder.h"
    6|       |
    7|       |#include "db/dbformat.h"
    8|       |#include "db/filename.h"
    9|       |#include "db/table_cache.h"
   10|       |#include "db/version_edit.h"
   11|       |#include "leveldb/db.h"
   12|       |#include "leveldb/env.h"
   13|       |#include "leveldb/iterator.h"
   14|       |
   15|       |namespace leveldb {
   16|       |
   17|       |Status BuildTable(const std::string& dbname, Env* env, const Options& options,
   18|      0|                  TableCache* table_cache, Iterator* iter, FileMetaData* meta) {
   19|      0|  Status s;
   20|      0|  meta->file_size = 0;
   21|      0|  iter->SeekToFirst();
   22|      0|
   23|      0|  std::string fname = TableFileName(dbname, meta->number);
   24|      0|  if (iter->Valid()) {
   25|      0|    WritableFile* file;
   26|      0|    s = env->NewWritableFile(fname, &file);
   27|      0|    if (!s.ok()) {
   28|      0|      return s;
   29|      0|    }
   30|      0|
   31|      0|    TableBuilder* builder = new TableBuilder(options, file);
   32|      0|    meta->smallest.DecodeFrom(iter->key());
   33|      0|    for (; iter->Valid(); iter->Next()) {
   34|      0|      Slice key = iter->key();
   35|      0|      meta->largest.DecodeFrom(key);
   36|      0|      builder->Add(key, iter->value());
   37|      0|    }
   38|      0|
   39|      0|    // Finish and check for builder errors
   40|      0|    s = builder->Finish();
   41|      0|    if (s.ok()) {
   42|      0|      meta->file_size = builder->FileSize();
   43|      0|      assert(meta->file_size > 0);
   44|      0|    }
   45|      0|    delete builder;
   46|      0|
   47|      0|    // Finish and check for file errors
   48|      0|    if (s.ok()) {
   49|      0|      s = file->Sync();
   50|      0|    }
   51|      0|    if (s.ok()) {
   52|      0|      s = file->Close();
   53|      0|    }
   54|      0|    delete file;
   55|      0|    file = nullptr;
   56|      0|
   57|      0|    if (s.ok()) {
   58|      0|      // Verify that the table is usable
   59|      0|      Iterator* it = table_cache->NewIterator(ReadOptions(), meta->number,
   60|      0|                                              meta->file_size);
   61|      0|      s = it->status();
   62|      0|      delete it;
   63|      0|    }
   64|      0|  }
   65|      0|
   66|      0|  // Check for input iterator errors
   67|      0|  if (!iter->status().ok()) {
   68|      0|    s = iter->status();
   69|      0|  }
   70|      0|
   71|      0|  if (s.ok() && meta->file_size > 0) {
   72|      0|    // Keep it
   73|      0|  } else {
   74|      0|    env->DeleteFile(fname);
   75|      0|  }
   76|      0|  return s;
   77|      0|}
   78|       |
   79|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/c.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "leveldb/c.h"
    6|       |
    7|       |#include <stdlib.h>
    8|       |
    9|       |#include "leveldb/cache.h"
   10|       |#include "leveldb/comparator.h"
   11|       |#include "leveldb/db.h"
   12|       |#include "leveldb/env.h"
   13|       |#include "leveldb/filter_policy.h"
   14|       |#include "leveldb/iterator.h"
   15|       |#include "leveldb/options.h"
   16|       |#include "leveldb/status.h"
   17|       |#include "leveldb/write_batch.h"
   18|       |
   19|       |using leveldb::Cache;
   20|       |using leveldb::Comparator;
   21|       |using leveldb::CompressionType;
   22|       |using leveldb::DB;
   23|       |using leveldb::Env;
   24|       |using leveldb::FileLock;
   25|       |using leveldb::FilterPolicy;
   26|       |using leveldb::Iterator;
   27|       |using leveldb::kMajorVersion;
   28|       |using leveldb::kMinorVersion;
   29|       |using leveldb::Logger;
   30|       |using leveldb::NewBloomFilterPolicy;
   31|       |using leveldb::NewLRUCache;
   32|       |using leveldb::Options;
   33|       |using leveldb::RandomAccessFile;
   34|       |using leveldb::Range;
   35|       |using leveldb::ReadOptions;
   36|       |using leveldb::SequentialFile;
   37|       |using leveldb::Slice;
   38|       |using leveldb::Snapshot;
   39|       |using leveldb::Status;
   40|       |using leveldb::WritableFile;
   41|       |using leveldb::WriteBatch;
   42|       |using leveldb::WriteOptions;
   43|       |
   44|       |extern "C" {
   45|       |
   46|       |struct leveldb_t {
   47|       |  DB* rep;
   48|       |};
   49|       |struct leveldb_iterator_t {
   50|       |  Iterator* rep;
   51|       |};
   52|       |struct leveldb_writebatch_t {
   53|       |  WriteBatch rep;
   54|       |};
   55|       |struct leveldb_snapshot_t {
   56|       |  const Snapshot* rep;
   57|       |};
   58|       |struct leveldb_readoptions_t {
   59|       |  ReadOptions rep;
   60|       |};
   61|       |struct leveldb_writeoptions_t {
   62|       |  WriteOptions rep;
   63|       |};
   64|       |struct leveldb_options_t {
   65|       |  Options rep;
   66|       |};
   67|       |struct leveldb_cache_t {
   68|       |  Cache* rep;
   69|       |};
   70|       |struct leveldb_seqfile_t {
   71|       |  SequentialFile* rep;
   72|       |};
   73|       |struct leveldb_randomfile_t {
   74|       |  RandomAccessFile* rep;
   75|       |};
   76|       |struct leveldb_writablefile_t {
   77|       |  WritableFile* rep;
   78|       |};
   79|       |struct leveldb_logger_t {
   80|       |  Logger* rep;
   81|       |};
   82|       |struct leveldb_filelock_t {
   83|       |  FileLock* rep;
   84|       |};
   85|       |
   86|       |struct leveldb_comparator_t : public Comparator {
   87|      0|  virtual ~leveldb_comparator_t() { (*destructor_)(state_); }
   88|       |
   89|      0|  virtual int Compare(const Slice& a, const Slice& b) const {
   90|      0|    return (*compare_)(state_, a.data(), a.size(), b.data(), b.size());
   91|      0|  }
   92|       |
   93|      0|  virtual const char* Name() const { return (*name_)(state_); }
   94|       |
   95|       |  // No-ops since the C binding does not support key shortening methods.
   96|      0|  virtual void FindShortestSeparator(std::string*, const Slice&) const {}
   97|      0|  virtual void FindShortSuccessor(std::string* key) const {}
   98|       |
   99|       |  void* state_;
  100|       |  void (*destructor_)(void*);
  101|       |  int (*compare_)(void*, const char* a, size_t alen, const char* b,
  102|       |                  size_t blen);
  103|       |  const char* (*name_)(void*);
  104|       |};
  105|       |
  106|       |struct leveldb_filterpolicy_t : public FilterPolicy {
  107|      0|  virtual ~leveldb_filterpolicy_t() { (*destructor_)(state_); }
  108|       |
  109|      0|  virtual const char* Name() const { return (*name_)(state_); }
  110|       |
  111|      0|  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const {
  112|      0|    std::vector<const char*> key_pointers(n);
  113|      0|    std::vector<size_t> key_sizes(n);
  114|      0|    for (int i = 0; i < n; i++) {
  115|      0|      key_pointers[i] = keys[i].data();
  116|      0|      key_sizes[i] = keys[i].size();
  117|      0|    }
  118|      0|    size_t len;
  119|      0|    char* filter = (*create_)(state_, &key_pointers[0], &key_sizes[0], n, &len);
  120|      0|    dst->append(filter, len);
  121|      0|    free(filter);
  122|      0|  }
  123|       |
  124|      0|  virtual bool KeyMayMatch(const Slice& key, const Slice& filter) const {
  125|      0|    return (*key_match_)(state_, key.data(), key.size(), filter.data(),
  126|      0|                         filter.size());
  127|      0|  }
  128|       |
  129|       |  void* state_;
  130|       |  void (*destructor_)(void*);
  131|       |  const char* (*name_)(void*);
  132|       |  char* (*create_)(void*, const char* const* key_array,
  133|       |                   const size_t* key_length_array, int num_keys,
  134|       |                   size_t* filter_length);
  135|       |  unsigned char (*key_match_)(void*, const char* key, size_t length,
  136|       |                              const char* filter, size_t filter_length);
  137|       |};
  138|       |
  139|       |struct leveldb_env_t {
  140|       |  Env* rep;
  141|       |  bool is_default;
  142|       |};
  143|       |
  144|      0|static bool SaveError(char** errptr, const Status& s) {
  145|      0|  assert(errptr != nullptr);
  146|      0|  if (s.ok()) {
  147|      0|    return false;
  148|      0|  } else if (*errptr == nullptr) {
  149|      0|    *errptr = strdup(s.ToString().c_str());
  150|      0|  } else {
  151|      0|    // TODO(sanjay): Merge with existing error?
  152|      0|    free(*errptr);
  153|      0|    *errptr = strdup(s.ToString().c_str());
  154|      0|  }
  155|      0|  return true;
  156|      0|}
  157|       |
  158|      0|static char* CopyString(const std::string& str) {
  159|      0|  char* result = reinterpret_cast<char*>(malloc(sizeof(char) * str.size()));
  160|      0|  memcpy(result, str.data(), sizeof(char) * str.size());
  161|      0|  return result;
  162|      0|}
  163|       |
  164|       |leveldb_t* leveldb_open(const leveldb_options_t* options, const char* name,
  165|      0|                        char** errptr) {
  166|      0|  DB* db;
  167|      0|  if (SaveError(errptr, DB::Open(options->rep, std::string(name), &db))) {
  168|      0|    return nullptr;
  169|      0|  }
  170|      0|  leveldb_t* result = new leveldb_t;
  171|      0|  result->rep = db;
  172|      0|  return result;
  173|      0|}
  174|       |
  175|      0|void leveldb_close(leveldb_t* db) {
  176|      0|  delete db->rep;
  177|      0|  delete db;
  178|      0|}
  179|       |
  180|       |void leveldb_put(leveldb_t* db, const leveldb_writeoptions_t* options,
  181|       |                 const char* key, size_t keylen, const char* val, size_t vallen,
  182|      0|                 char** errptr) {
  183|      0|  SaveError(errptr,
  184|      0|            db->rep->Put(options->rep, Slice(key, keylen), Slice(val, vallen)));
  185|      0|}
  186|       |
  187|       |void leveldb_delete(leveldb_t* db, const leveldb_writeoptions_t* options,
  188|      0|                    const char* key, size_t keylen, char** errptr) {
  189|      0|  SaveError(errptr, db->rep->Delete(options->rep, Slice(key, keylen)));
  190|      0|}
  191|       |
  192|       |void leveldb_write(leveldb_t* db, const leveldb_writeoptions_t* options,
  193|      0|                   leveldb_writebatch_t* batch, char** errptr) {
  194|      0|  SaveError(errptr, db->rep->Write(options->rep, &batch->rep));
  195|      0|}
  196|       |
  197|       |char* leveldb_get(leveldb_t* db, const leveldb_readoptions_t* options,
  198|       |                  const char* key, size_t keylen, size_t* vallen,
  199|      0|                  char** errptr) {
  200|      0|  char* result = nullptr;
  201|      0|  std::string tmp;
  202|      0|  Status s = db->rep->Get(options->rep, Slice(key, keylen), &tmp);
  203|      0|  if (s.ok()) {
  204|      0|    *vallen = tmp.size();
  205|      0|    result = CopyString(tmp);
  206|      0|  } else {
  207|      0|    *vallen = 0;
  208|      0|    if (!s.IsNotFound()) {
  209|      0|      SaveError(errptr, s);
  210|      0|    }
  211|      0|  }
  212|      0|  return result;
  213|      0|}
  214|       |
  215|       |leveldb_iterator_t* leveldb_create_iterator(
  216|      0|    leveldb_t* db, const leveldb_readoptions_t* options) {
  217|      0|  leveldb_iterator_t* result = new leveldb_iterator_t;
  218|      0|  result->rep = db->rep->NewIterator(options->rep);
  219|      0|  return result;
  220|      0|}
  221|       |
  222|      0|const leveldb_snapshot_t* leveldb_create_snapshot(leveldb_t* db) {
  223|      0|  leveldb_snapshot_t* result = new leveldb_snapshot_t;
  224|      0|  result->rep = db->rep->GetSnapshot();
  225|      0|  return result;
  226|      0|}
  227|       |
  228|       |void leveldb_release_snapshot(leveldb_t* db,
  229|      0|                              const leveldb_snapshot_t* snapshot) {
  230|      0|  db->rep->ReleaseSnapshot(snapshot->rep);
  231|      0|  delete snapshot;
  232|      0|}
  233|       |
  234|      0|char* leveldb_property_value(leveldb_t* db, const char* propname) {
  235|      0|  std::string tmp;
  236|      0|  if (db->rep->GetProperty(Slice(propname), &tmp)) {
  237|      0|    // We use strdup() since we expect human readable output.
  238|      0|    return strdup(tmp.c_str());
  239|      0|  } else {
  240|      0|    return nullptr;
  241|      0|  }
  242|      0|}
  243|       |
  244|       |void leveldb_approximate_sizes(leveldb_t* db, int num_ranges,
  245|       |                               const char* const* range_start_key,
  246|       |                               const size_t* range_start_key_len,
  247|       |                               const char* const* range_limit_key,
  248|       |                               const size_t* range_limit_key_len,
  249|      0|                               uint64_t* sizes) {
  250|      0|  Range* ranges = new Range[num_ranges];
  251|      0|  for (int i = 0; i < num_ranges; i++) {
  252|      0|    ranges[i].start = Slice(range_start_key[i], range_start_key_len[i]);
  253|      0|    ranges[i].limit = Slice(range_limit_key[i], range_limit_key_len[i]);
  254|      0|  }
  255|      0|  db->rep->GetApproximateSizes(ranges, num_ranges, sizes);
  256|      0|  delete[] ranges;
  257|      0|}
  258|       |
  259|       |void leveldb_compact_range(leveldb_t* db, const char* start_key,
  260|       |                           size_t start_key_len, const char* limit_key,
  261|      0|                           size_t limit_key_len) {
  262|      0|  Slice a, b;
  263|      0|  db->rep->CompactRange(
  264|      0|      // Pass null Slice if corresponding "const char*" is null
  265|      0|      (start_key ? (a = Slice(start_key, start_key_len), &a) : nullptr),
  266|      0|      (limit_key ? (b = Slice(limit_key, limit_key_len), &b) : nullptr));
  267|      0|}
  268|       |
  269|       |void leveldb_destroy_db(const leveldb_options_t* options, const char* name,
  270|      0|                        char** errptr) {
  271|      0|  SaveError(errptr, DestroyDB(name, options->rep));
  272|      0|}
  273|       |
  274|       |void leveldb_repair_db(const leveldb_options_t* options, const char* name,
  275|      0|                       char** errptr) {
  276|      0|  SaveError(errptr, RepairDB(name, options->rep));
  277|      0|}
  278|       |
  279|      0|void leveldb_iter_destroy(leveldb_iterator_t* iter) {
  280|      0|  delete iter->rep;
  281|      0|  delete iter;
  282|      0|}
  283|       |
  284|      0|unsigned char leveldb_iter_valid(const leveldb_iterator_t* iter) {
  285|      0|  return iter->rep->Valid();
  286|      0|}
  287|       |
  288|      0|void leveldb_iter_seek_to_first(leveldb_iterator_t* iter) {
  289|      0|  iter->rep->SeekToFirst();
  290|      0|}
  291|       |
  292|      0|void leveldb_iter_seek_to_last(leveldb_iterator_t* iter) {
  293|      0|  iter->rep->SeekToLast();
  294|      0|}
  295|       |
  296|      0|void leveldb_iter_seek(leveldb_iterator_t* iter, const char* k, size_t klen) {
  297|      0|  iter->rep->Seek(Slice(k, klen));
  298|      0|}
  299|       |
  300|      0|void leveldb_iter_next(leveldb_iterator_t* iter) { iter->rep->Next(); }
  301|       |
  302|      0|void leveldb_iter_prev(leveldb_iterator_t* iter) { iter->rep->Prev(); }
  303|       |
  304|      0|const char* leveldb_iter_key(const leveldb_iterator_t* iter, size_t* klen) {
  305|      0|  Slice s = iter->rep->key();
  306|      0|  *klen = s.size();
  307|      0|  return s.data();
  308|      0|}
  309|       |
  310|      0|const char* leveldb_iter_value(const leveldb_iterator_t* iter, size_t* vlen) {
  311|      0|  Slice s = iter->rep->value();
  312|      0|  *vlen = s.size();
  313|      0|  return s.data();
  314|      0|}
  315|       |
  316|      0|void leveldb_iter_get_error(const leveldb_iterator_t* iter, char** errptr) {
  317|      0|  SaveError(errptr, iter->rep->status());
  318|      0|}
  319|       |
  320|      0|leveldb_writebatch_t* leveldb_writebatch_create() {
  321|      0|  return new leveldb_writebatch_t;
  322|      0|}
  323|       |
  324|      0|void leveldb_writebatch_destroy(leveldb_writebatch_t* b) { delete b; }
  325|       |
  326|      0|void leveldb_writebatch_clear(leveldb_writebatch_t* b) { b->rep.Clear(); }
  327|       |
  328|       |void leveldb_writebatch_put(leveldb_writebatch_t* b, const char* key,
  329|      0|                            size_t klen, const char* val, size_t vlen) {
  330|      0|  b->rep.Put(Slice(key, klen), Slice(val, vlen));
  331|      0|}
  332|       |
  333|       |void leveldb_writebatch_delete(leveldb_writebatch_t* b, const char* key,
  334|      0|                               size_t klen) {
  335|      0|  b->rep.Delete(Slice(key, klen));
  336|      0|}
  337|       |
  338|       |void leveldb_writebatch_iterate(const leveldb_writebatch_t* b, void* state,
  339|       |                                void (*put)(void*, const char* k, size_t klen,
  340|       |                                            const char* v, size_t vlen),
  341|       |                                void (*deleted)(void*, const char* k,
  342|      0|                                                size_t klen)) {
  343|      0|  class H : public WriteBatch::Handler {
  344|      0|   public:
  345|      0|    void* state_;
  346|      0|    void (*put_)(void*, const char* k, size_t klen, const char* v, size_t vlen);
  347|      0|    void (*deleted_)(void*, const char* k, size_t klen);
  348|      0|    virtual void Put(const Slice& key, const Slice& value) {
  349|      0|      (*put_)(state_, key.data(), key.size(), value.data(), value.size());
  350|      0|    }
  351|      0|    virtual void Delete(const Slice& key) {
  352|      0|      (*deleted_)(state_, key.data(), key.size());
  353|      0|    }
  354|      0|  };
  355|      0|  H handler;
  356|      0|  handler.state_ = state;
  357|      0|  handler.put_ = put;
  358|      0|  handler.deleted_ = deleted;
  359|      0|  b->rep.Iterate(&handler);
  360|      0|}
  361|       |
  362|       |void leveldb_writebatch_append(leveldb_writebatch_t* destination,
  363|      0|                               const leveldb_writebatch_t* source) {
  364|      0|  destination->rep.Append(source->rep);
  365|      0|}
  366|       |
  367|      0|leveldb_options_t* leveldb_options_create() { return new leveldb_options_t; }
  368|       |
  369|      0|void leveldb_options_destroy(leveldb_options_t* options) { delete options; }
  370|       |
  371|       |void leveldb_options_set_comparator(leveldb_options_t* opt,
  372|      0|                                    leveldb_comparator_t* cmp) {
  373|      0|  opt->rep.comparator = cmp;
  374|      0|}
  375|       |
  376|       |void leveldb_options_set_filter_policy(leveldb_options_t* opt,
  377|      0|                                       leveldb_filterpolicy_t* policy) {
  378|      0|  opt->rep.filter_policy = policy;
  379|      0|}
  380|       |
  381|       |void leveldb_options_set_create_if_missing(leveldb_options_t* opt,
  382|      0|                                           unsigned char v) {
  383|      0|  opt->rep.create_if_missing = v;
  384|      0|}
  385|       |
  386|       |void leveldb_options_set_error_if_exists(leveldb_options_t* opt,
  387|      0|                                         unsigned char v) {
  388|      0|  opt->rep.error_if_exists = v;
  389|      0|}
  390|       |
  391|       |void leveldb_options_set_paranoid_checks(leveldb_options_t* opt,
  392|      0|                                         unsigned char v) {
  393|      0|  opt->rep.paranoid_checks = v;
  394|      0|}
  395|       |
  396|      0|void leveldb_options_set_env(leveldb_options_t* opt, leveldb_env_t* env) {
  397|      0|  opt->rep.env = (env ? env->rep : nullptr);
  398|      0|}
  399|       |
  400|      0|void leveldb_options_set_info_log(leveldb_options_t* opt, leveldb_logger_t* l) {
  401|      0|  opt->rep.info_log = (l ? l->rep : nullptr);
  402|      0|}
  403|       |
  404|      0|void leveldb_options_set_write_buffer_size(leveldb_options_t* opt, size_t s) {
  405|      0|  opt->rep.write_buffer_size = s;
  406|      0|}
  407|       |
  408|      0|void leveldb_options_set_max_open_files(leveldb_options_t* opt, int n) {
  409|      0|  opt->rep.max_open_files = n;
  410|      0|}
  411|       |
  412|      0|void leveldb_options_set_cache(leveldb_options_t* opt, leveldb_cache_t* c) {
  413|      0|  opt->rep.block_cache = c->rep;
  414|      0|}
  415|       |
  416|      0|void leveldb_options_set_block_size(leveldb_options_t* opt, size_t s) {
  417|      0|  opt->rep.block_size = s;
  418|      0|}
  419|       |
  420|      0|void leveldb_options_set_block_restart_interval(leveldb_options_t* opt, int n) {
  421|      0|  opt->rep.block_restart_interval = n;
  422|      0|}
  423|       |
  424|      0|void leveldb_options_set_max_file_size(leveldb_options_t* opt, size_t s) {
  425|      0|  opt->rep.max_file_size = s;
  426|      0|}
  427|       |
  428|      0|void leveldb_options_set_compression(leveldb_options_t* opt, int t) {
  429|      0|  opt->rep.compression = static_cast<CompressionType>(t);
  430|      0|}
  431|       |
  432|       |leveldb_comparator_t* leveldb_comparator_create(
  433|       |    void* state, void (*destructor)(void*),
  434|       |    int (*compare)(void*, const char* a, size_t alen, const char* b,
  435|       |                   size_t blen),
  436|      0|    const char* (*name)(void*)) {
  437|      0|  leveldb_comparator_t* result = new leveldb_comparator_t;
  438|      0|  result->state_ = state;
  439|      0|  result->destructor_ = destructor;
  440|      0|  result->compare_ = compare;
  441|      0|  result->name_ = name;
  442|      0|  return result;
  443|      0|}
  444|       |
  445|      0|void leveldb_comparator_destroy(leveldb_comparator_t* cmp) { delete cmp; }
  446|       |
  447|       |leveldb_filterpolicy_t* leveldb_filterpolicy_create(
  448|       |    void* state, void (*destructor)(void*),
  449|       |    char* (*create_filter)(void*, const char* const* key_array,
  450|       |                           const size_t* key_length_array, int num_keys,
  451|       |                           size_t* filter_length),
  452|       |    unsigned char (*key_may_match)(void*, const char* key, size_t length,
  453|       |                                   const char* filter, size_t filter_length),
  454|      0|    const char* (*name)(void*)) {
  455|      0|  leveldb_filterpolicy_t* result = new leveldb_filterpolicy_t;
  456|      0|  result->state_ = state;
  457|      0|  result->destructor_ = destructor;
  458|      0|  result->create_ = create_filter;
  459|      0|  result->key_match_ = key_may_match;
  460|      0|  result->name_ = name;
  461|      0|  return result;
  462|      0|}
  463|       |
  464|      0|void leveldb_filterpolicy_destroy(leveldb_filterpolicy_t* filter) {
  465|      0|  delete filter;
  466|      0|}
  467|       |
  468|      0|leveldb_filterpolicy_t* leveldb_filterpolicy_create_bloom(int bits_per_key) {
  469|      0|  // Make a leveldb_filterpolicy_t, but override all of its methods so
  470|      0|  // they delegate to a NewBloomFilterPolicy() instead of user
  471|      0|  // supplied C functions.
  472|      0|  struct Wrapper : public leveldb_filterpolicy_t {
  473|      0|    static void DoNothing(void*) {}
  474|      0|
  475|      0|    ~Wrapper() { delete rep_; }
  476|      0|    const char* Name() const { return rep_->Name(); }
  477|      0|    void CreateFilter(const Slice* keys, int n, std::string* dst) const {
  478|      0|      return rep_->CreateFilter(keys, n, dst);
  479|      0|    }
  480|      0|    bool KeyMayMatch(const Slice& key, const Slice& filter) const {
  481|      0|      return rep_->KeyMayMatch(key, filter);
  482|      0|    }
  483|      0|
  484|      0|    const FilterPolicy* rep_;
  485|      0|  };
  486|      0|  Wrapper* wrapper = new Wrapper;
  487|      0|  wrapper->rep_ = NewBloomFilterPolicy(bits_per_key);
  488|      0|  wrapper->state_ = nullptr;
  489|      0|  wrapper->destructor_ = &Wrapper::DoNothing;
  490|      0|  return wrapper;
  491|      0|}
  492|       |
  493|      0|leveldb_readoptions_t* leveldb_readoptions_create() {
  494|      0|  return new leveldb_readoptions_t;
  495|      0|}
  496|       |
  497|      0|void leveldb_readoptions_destroy(leveldb_readoptions_t* opt) { delete opt; }
  498|       |
  499|       |void leveldb_readoptions_set_verify_checksums(leveldb_readoptions_t* opt,
  500|      0|                                              unsigned char v) {
  501|      0|  opt->rep.verify_checksums = v;
  502|      0|}
  503|       |
  504|       |void leveldb_readoptions_set_fill_cache(leveldb_readoptions_t* opt,
  505|      0|                                        unsigned char v) {
  506|      0|  opt->rep.fill_cache = v;
  507|      0|}
  508|       |
  509|       |void leveldb_readoptions_set_snapshot(leveldb_readoptions_t* opt,
  510|      0|                                      const leveldb_snapshot_t* snap) {
  511|      0|  opt->rep.snapshot = (snap ? snap->rep : nullptr);
  512|      0|}
  513|       |
  514|      0|leveldb_writeoptions_t* leveldb_writeoptions_create() {
  515|      0|  return new leveldb_writeoptions_t;
  516|      0|}
  517|       |
  518|      0|void leveldb_writeoptions_destroy(leveldb_writeoptions_t* opt) { delete opt; }
  519|       |
  520|       |void leveldb_writeoptions_set_sync(leveldb_writeoptions_t* opt,
  521|      0|                                   unsigned char v) {
  522|      0|  opt->rep.sync = v;
  523|      0|}
  524|       |
  525|      0|leveldb_cache_t* leveldb_cache_create_lru(size_t capacity) {
  526|      0|  leveldb_cache_t* c = new leveldb_cache_t;
  527|      0|  c->rep = NewLRUCache(capacity);
  528|      0|  return c;
  529|      0|}
  530|       |
  531|      0|void leveldb_cache_destroy(leveldb_cache_t* cache) {
  532|      0|  delete cache->rep;
  533|      0|  delete cache;
  534|      0|}
  535|       |
  536|      0|leveldb_env_t* leveldb_create_default_env() {
  537|      0|  leveldb_env_t* result = new leveldb_env_t;
  538|      0|  result->rep = Env::Default();
  539|      0|  result->is_default = true;
  540|      0|  return result;
  541|      0|}
  542|       |
  543|      0|void leveldb_env_destroy(leveldb_env_t* env) {
  544|      0|  if (!env->is_default) delete env->rep;
  545|      0|  delete env;
  546|      0|}
  547|       |
  548|      0|char* leveldb_env_get_test_directory(leveldb_env_t* env) {
  549|      0|  std::string result;
  550|      0|  if (!env->rep->GetTestDirectory(&result).ok()) {
  551|      0|    return nullptr;
  552|      0|  }
  553|      0|
  554|      0|  char* buffer = static_cast<char*>(malloc(result.size() + 1));
  555|      0|  memcpy(buffer, result.data(), result.size());
  556|      0|  buffer[result.size()] = '\0';
  557|      0|  return buffer;
  558|      0|}
  559|       |
  560|      0|void leveldb_free(void* ptr) { free(ptr); }
  561|       |
  562|      0|int leveldb_major_version() { return kMajorVersion; }
  563|       |
  564|      0|int leveldb_minor_version() { return kMinorVersion; }
  565|       |
  566|       |}  // end extern "C"

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/db_impl.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/db_impl.h"
    6|       |
    7|       |#include <stdint.h>
    8|       |#include <stdio.h>
    9|       |
   10|       |#include <algorithm>
   11|       |#include <atomic>
   12|       |#include <set>
   13|       |#include <string>
   14|       |#include <vector>
   15|       |
   16|       |#include "db/builder.h"
   17|       |#include "db/db_iter.h"
   18|       |#include "db/dbformat.h"
   19|       |#include "db/filename.h"
   20|       |#include "db/log_reader.h"
   21|       |#include "db/log_writer.h"
   22|       |#include "db/memtable.h"
   23|       |#include "db/table_cache.h"
   24|       |#include "db/version_set.h"
   25|       |#include "db/write_batch_internal.h"
   26|       |#include "leveldb/db.h"
   27|       |#include "leveldb/env.h"
   28|       |#include "leveldb/status.h"
   29|       |#include "leveldb/table.h"
   30|       |#include "leveldb/table_builder.h"
   31|       |#include "port/port.h"
   32|       |#include "table/block.h"
   33|       |#include "table/merger.h"
   34|       |#include "table/two_level_iterator.h"
   35|       |#include "util/coding.h"
   36|       |#include "util/logging.h"
   37|       |#include "util/mutexlock.h"
   38|       |
   39|       |namespace leveldb {
   40|       |
   41|       |const int kNumNonTableCacheFiles = 10;
   42|       |
   43|       |// Information kept for every waiting writer
   44|       |struct DBImpl::Writer {
   45|       |  explicit Writer(port::Mutex* mu)
   46|      0|      : batch(nullptr), sync(false), done(false), cv(mu) {}
   47|       |
   48|       |  Status status;
   49|       |  WriteBatch* batch;
   50|       |  bool sync;
   51|       |  bool done;
   52|       |  port::CondVar cv;
   53|       |};
   54|       |
   55|       |struct DBImpl::CompactionState {
   56|       |  // Files produced by compaction
   57|       |  struct Output {
   58|       |    uint64_t number;
   59|       |    uint64_t file_size;
   60|       |    InternalKey smallest, largest;
   61|       |  };
   62|       |
   63|      0|  Output* current_output() { return &outputs[outputs.size() - 1]; }
   64|       |
   65|       |  explicit CompactionState(Compaction* c)
   66|       |      : compaction(c),
   67|       |        smallest_snapshot(0),
   68|       |        outfile(nullptr),
   69|       |        builder(nullptr),
   70|      0|        total_bytes(0) {}
   71|       |
   72|       |  Compaction* const compaction;
   73|       |
   74|       |  // Sequence numbers < smallest_snapshot are not significant since we
   75|       |  // will never have to service a snapshot below smallest_snapshot.
   76|       |  // Therefore if we have seen a sequence number S <= smallest_snapshot,
   77|       |  // we can drop all entries for the same key with sequence numbers < S.
   78|       |  SequenceNumber smallest_snapshot;
   79|       |
   80|       |  std::vector<Output> outputs;
   81|       |
   82|       |  // State kept for output being generated
   83|       |  WritableFile* outfile;
   84|       |  TableBuilder* builder;
   85|       |
   86|       |  uint64_t total_bytes;
   87|       |};
   88|       |
   89|       |// Fix user-supplied options to be reasonable
   90|       |template <class T, class V>
   91|      0|static void ClipToRange(T* ptr, V minvalue, V maxvalue) {
   92|      0|  if (static_cast<V>(*ptr) > maxvalue) *ptr = maxvalue;
   93|      0|  if (static_cast<V>(*ptr) < minvalue) *ptr = minvalue;
   94|      0|}
  ------------------
  | Unexecuted instantiation: db_impl.cc:_ZN7leveldbL11ClipToRangeIiiEEvPT_T0_S3_
  ------------------
  | Unexecuted instantiation: db_impl.cc:_ZN7leveldbL11ClipToRangeImiEEvPT_T0_S3_
  ------------------
   95|       |Options SanitizeOptions(const std::string& dbname,
   96|       |                        const InternalKeyComparator* icmp,
   97|       |                        const InternalFilterPolicy* ipolicy,
   98|      0|                        const Options& src) {
   99|      0|  Options result = src;
  100|      0|  result.comparator = icmp;
  101|      0|  result.filter_policy = (src.filter_policy != nullptr) ? ipolicy : nullptr;
  102|      0|  ClipToRange(&result.max_open_files, 64 + kNumNonTableCacheFiles, 50000);
  103|      0|  ClipToRange(&result.write_buffer_size, 64 << 10, 1 << 30);
  104|      0|  ClipToRange(&result.max_file_size, 1 << 20, 1 << 30);
  105|      0|  ClipToRange(&result.block_size, 1 << 10, 4 << 20);
  106|      0|  if (result.info_log == nullptr) {
  107|      0|    // Open a log file in the same directory as the db
  108|      0|    src.env->CreateDir(dbname);  // In case it does not exist
  109|      0|    src.env->RenameFile(InfoLogFileName(dbname), OldInfoLogFileName(dbname));
  110|      0|    Status s = src.env->NewLogger(InfoLogFileName(dbname), &result.info_log);
  111|      0|    if (!s.ok()) {
  112|      0|      // No place suitable for logging
  113|      0|      result.info_log = nullptr;
  114|      0|    }
  115|      0|  }
  116|      0|  if (result.block_cache == nullptr) {
  117|      0|    result.block_cache = NewLRUCache(8 << 20);
  118|      0|  }
  119|      0|  return result;
  120|      0|}
  121|       |
  122|      0|static int TableCacheSize(const Options& sanitized_options) {
  123|      0|  // Reserve ten files or so for other uses and give the rest to TableCache.
  124|      0|  return sanitized_options.max_open_files - kNumNonTableCacheFiles;
  125|      0|}
  126|       |
  127|       |DBImpl::DBImpl(const Options& raw_options, const std::string& dbname)
  128|       |    : env_(raw_options.env),
  129|       |      internal_comparator_(raw_options.comparator),
  130|       |      internal_filter_policy_(raw_options.filter_policy),
  131|       |      options_(SanitizeOptions(dbname, &internal_comparator_,
  132|       |                               &internal_filter_policy_, raw_options)),
  133|       |      owns_info_log_(options_.info_log != raw_options.info_log),
  134|       |      owns_cache_(options_.block_cache != raw_options.block_cache),
  135|       |      dbname_(dbname),
  136|       |      table_cache_(new TableCache(dbname_, options_, TableCacheSize(options_))),
  137|       |      db_lock_(nullptr),
  138|       |      shutting_down_(false),
  139|       |      background_work_finished_signal_(&mutex_),
  140|       |      mem_(nullptr),
  141|       |      imm_(nullptr),
  142|       |      has_imm_(false),
  143|       |      logfile_(nullptr),
  144|       |      logfile_number_(0),
  145|       |      log_(nullptr),
  146|       |      seed_(0),
  147|       |      tmp_batch_(new WriteBatch),
  148|       |      background_compaction_scheduled_(false),
  149|       |      manual_compaction_(nullptr),
  150|       |      versions_(new VersionSet(dbname_, &options_, table_cache_,
  151|      0|                               &internal_comparator_)) {}
  152|       |
  153|      0|DBImpl::~DBImpl() {
  154|      0|  // Wait for background work to finish.
  155|      0|  mutex_.Lock();
  156|      0|  shutting_down_.store(true, std::memory_order_release);
  157|      0|  while (background_compaction_scheduled_) {
  158|      0|    background_work_finished_signal_.Wait();
  159|      0|  }
  160|      0|  mutex_.Unlock();
  161|      0|
  162|      0|  if (db_lock_ != nullptr) {
  163|      0|    env_->UnlockFile(db_lock_);
  164|      0|  }
  165|      0|
  166|      0|  delete versions_;
  167|      0|  if (mem_ != nullptr) mem_->Unref();
  168|      0|  if (imm_ != nullptr) imm_->Unref();
  169|      0|  delete tmp_batch_;
  170|      0|  delete log_;
  171|      0|  delete logfile_;
  172|      0|  delete table_cache_;
  173|      0|
  174|      0|  if (owns_info_log_) {
  175|      0|    delete options_.info_log;
  176|      0|  }
  177|      0|  if (owns_cache_) {
  178|      0|    delete options_.block_cache;
  179|      0|  }
  180|      0|}
  181|       |
  182|      0|Status DBImpl::NewDB() {
  183|      0|  VersionEdit new_db;
  184|      0|  new_db.SetComparatorName(user_comparator()->Name());
  185|      0|  new_db.SetLogNumber(0);
  186|      0|  new_db.SetNextFile(2);
  187|      0|  new_db.SetLastSequence(0);
  188|      0|
  189|      0|  const std::string manifest = DescriptorFileName(dbname_, 1);
  190|      0|  WritableFile* file;
  191|      0|  Status s = env_->NewWritableFile(manifest, &file);
  192|      0|  if (!s.ok()) {
  193|      0|    return s;
  194|      0|  }
  195|      0|  {
  196|      0|    log::Writer log(file);
  197|      0|    std::string record;
  198|      0|    new_db.EncodeTo(&record);
  199|      0|    s = log.AddRecord(record);
  200|      0|    if (s.ok()) {
  201|      0|      s = file->Close();
  202|      0|    }
  203|      0|  }
  204|      0|  delete file;
  205|      0|  if (s.ok()) {
  206|      0|    // Make "CURRENT" file that points to the new manifest file.
  207|      0|    s = SetCurrentFile(env_, dbname_, 1);
  208|      0|  } else {
  209|      0|    env_->DeleteFile(manifest);
  210|      0|  }
  211|      0|  return s;
  212|      0|}
  213|       |
  214|      0|void DBImpl::MaybeIgnoreError(Status* s) const {
  215|      0|  if (s->ok() || options_.paranoid_checks) {
  216|      0|    // No change needed
  217|      0|  } else {
  218|      0|    Log(options_.info_log, "Ignoring error %s", s->ToString().c_str());
  219|      0|    *s = Status::OK();
  220|      0|  }
  221|      0|}
  222|       |
  223|      0|void DBImpl::DeleteObsoleteFiles() {
  224|      0|  mutex_.AssertHeld();
  225|      0|
  226|      0|  if (!bg_error_.ok()) {
  227|      0|    // After a background error, we don't know whether a new version may
  228|      0|    // or may not have been committed, so we cannot safely garbage collect.
  229|      0|    return;
  230|      0|  }
  231|      0|
  232|      0|  // Make a set of all of the live files
  233|      0|  std::set<uint64_t> live = pending_outputs_;
  234|      0|  versions_->AddLiveFiles(&live);
  235|      0|
  236|      0|  std::vector<std::string> filenames;
  237|      0|  env_->GetChildren(dbname_, &filenames);  // Ignoring errors on purpose
  238|      0|  uint64_t number;
  239|      0|  FileType type;
  240|      0|  for (size_t i = 0; i < filenames.size(); i++) {
  241|      0|    if (ParseFileName(filenames[i], &number, &type)) {
  242|      0|      bool keep = true;
  243|      0|      switch (type) {
  244|      0|        case kLogFile:
  245|      0|          keep = ((number >= versions_->LogNumber()) ||
  246|      0|                  (number == versions_->PrevLogNumber()));
  247|      0|          break;
  248|      0|        case kDescriptorFile:
  249|      0|          // Keep my manifest file, and any newer incarnations'
  250|      0|          // (in case there is a race that allows other incarnations)
  251|      0|          keep = (number >= versions_->ManifestFileNumber());
  252|      0|          break;
  253|      0|        case kTableFile:
  254|      0|          keep = (live.find(number) != live.end());
  255|      0|          break;
  256|      0|        case kTempFile:
  257|      0|          // Any temp files that are currently being written to must
  258|      0|          // be recorded in pending_outputs_, which is inserted into "live"
  259|      0|          keep = (live.find(number) != live.end());
  260|      0|          break;
  261|      0|        case kCurrentFile:
  262|      0|        case kDBLockFile:
  263|      0|        case kInfoLogFile:
  264|      0|          keep = true;
  265|      0|          break;
  266|      0|      }
  267|      0|
  268|      0|      if (!keep) {
  269|      0|        if (type == kTableFile) {
  270|      0|          table_cache_->Evict(number);
  271|      0|        }
  272|      0|        Log(options_.info_log, "Delete type=%d #%lld\n", static_cast<int>(type),
  273|      0|            static_cast<unsigned long long>(number));
  274|      0|        env_->DeleteFile(dbname_ + "/" + filenames[i]);
  275|      0|      }
  276|      0|    }
  277|      0|  }
  278|      0|}
  279|       |
  280|      0|Status DBImpl::Recover(VersionEdit* edit, bool* save_manifest) {
  281|      0|  mutex_.AssertHeld();
  282|      0|
  283|      0|  // Ignore error from CreateDir since the creation of the DB is
  284|      0|  // committed only when the descriptor is created, and this directory
  285|      0|  // may already exist from a previous failed creation attempt.
  286|      0|  env_->CreateDir(dbname_);
  287|      0|  assert(db_lock_ == nullptr);
  288|      0|  Status s = env_->LockFile(LockFileName(dbname_), &db_lock_);
  289|      0|  if (!s.ok()) {
  290|      0|    return s;
  291|      0|  }
  292|      0|
  293|      0|  if (!env_->FileExists(CurrentFileName(dbname_))) {
  294|      0|    if (options_.create_if_missing) {
  295|      0|      s = NewDB();
  296|      0|      if (!s.ok()) {
  297|      0|        return s;
  298|      0|      }
  299|      0|    } else {
  300|      0|      return Status::InvalidArgument(
  301|      0|          dbname_, "does not exist (create_if_missing is false)");
  302|      0|    }
  303|      0|  } else {
  304|      0|    if (options_.error_if_exists) {
  305|      0|      return Status::InvalidArgument(dbname_,
  306|      0|                                     "exists (error_if_exists is true)");
  307|      0|    }
  308|      0|  }
  309|      0|
  310|      0|  s = versions_->Recover(save_manifest);
  311|      0|  if (!s.ok()) {
  312|      0|    return s;
  313|      0|  }
  314|      0|  SequenceNumber max_sequence(0);
  315|      0|
  316|      0|  // Recover from all newer log files than the ones named in the
  317|      0|  // descriptor (new log files may have been added by the previous
  318|      0|  // incarnation without registering them in the descriptor).
  319|      0|  //
  320|      0|  // Note that PrevLogNumber() is no longer used, but we pay
  321|      0|  // attention to it in case we are recovering a database
  322|      0|  // produced by an older version of leveldb.
  323|      0|  const uint64_t min_log = versions_->LogNumber();
  324|      0|  const uint64_t prev_log = versions_->PrevLogNumber();
  325|      0|  std::vector<std::string> filenames;
  326|      0|  s = env_->GetChildren(dbname_, &filenames);
  327|      0|  if (!s.ok()) {
  328|      0|    return s;
  329|      0|  }
  330|      0|  std::set<uint64_t> expected;
  331|      0|  versions_->AddLiveFiles(&expected);
  332|      0|  uint64_t number;
  333|      0|  FileType type;
  334|      0|  std::vector<uint64_t> logs;
  335|      0|  for (size_t i = 0; i < filenames.size(); i++) {
  336|      0|    if (ParseFileName(filenames[i], &number, &type)) {
  337|      0|      expected.erase(number);
  338|      0|      if (type == kLogFile && ((number >= min_log) || (number == prev_log)))
  339|      0|        logs.push_back(number);
  340|      0|    }
  341|      0|  }
  342|      0|  if (!expected.empty()) {
  343|      0|    char buf[50];
  344|      0|    snprintf(buf, sizeof(buf), "%d missing files; e.g.",
  345|      0|             static_cast<int>(expected.size()));
  346|      0|    return Status::Corruption(buf, TableFileName(dbname_, *(expected.begin())));
  347|      0|  }
  348|      0|
  349|      0|  // Recover in the order in which the logs were generated
  350|      0|  std::sort(logs.begin(), logs.end());
  351|      0|  for (size_t i = 0; i < logs.size(); i++) {
  352|      0|    s = RecoverLogFile(logs[i], (i == logs.size() - 1), save_manifest, edit,
  353|      0|                       &max_sequence);
  354|      0|    if (!s.ok()) {
  355|      0|      return s;
  356|      0|    }
  357|      0|
  358|      0|    // The previous incarnation may not have written any MANIFEST
  359|      0|    // records after allocating this log number.  So we manually
  360|      0|    // update the file number allocation counter in VersionSet.
  361|      0|    versions_->MarkFileNumberUsed(logs[i]);
  362|      0|  }
  363|      0|
  364|      0|  if (versions_->LastSequence() < max_sequence) {
  365|      0|    versions_->SetLastSequence(max_sequence);
  366|      0|  }
  367|      0|
  368|      0|  return Status::OK();
  369|      0|}
  370|       |
  371|       |Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,
  372|       |                              bool* save_manifest, VersionEdit* edit,
  373|      0|                              SequenceNumber* max_sequence) {
  374|      0|  struct LogReporter : public log::Reader::Reporter {
  375|      0|    Env* env;
  376|      0|    Logger* info_log;
  377|      0|    const char* fname;
  378|      0|    Status* status;  // null if options_.paranoid_checks==false
  379|      0|    virtual void Corruption(size_t bytes, const Status& s) {
  380|      0|      Log(info_log, "%s%s: dropping %d bytes; %s",
  381|      0|          (this->status == nullptr ? "(ignoring error) " : ""), fname,
  382|      0|          static_cast<int>(bytes), s.ToString().c_str());
  383|      0|      if (this->status != nullptr && this->status->ok()) *this->status = s;
  384|      0|    }
  385|      0|  };
  386|      0|
  387|      0|  mutex_.AssertHeld();
  388|      0|
  389|      0|  // Open the log file
  390|      0|  std::string fname = LogFileName(dbname_, log_number);
  391|      0|  SequentialFile* file;
  392|      0|  Status status = env_->NewSequentialFile(fname, &file);
  393|      0|  if (!status.ok()) {
  394|      0|    MaybeIgnoreError(&status);
  395|      0|    return status;
  396|      0|  }
  397|      0|
  398|      0|  // Create the log reader.
  399|      0|  LogReporter reporter;
  400|      0|  reporter.env = env_;
  401|      0|  reporter.info_log = options_.info_log;
  402|      0|  reporter.fname = fname.c_str();
  403|      0|  reporter.status = (options_.paranoid_checks ? &status : nullptr);
  404|      0|  // We intentionally make log::Reader do checksumming even if
  405|      0|  // paranoid_checks==false so that corruptions cause entire commits
  406|      0|  // to be skipped instead of propagating bad information (like overly
  407|      0|  // large sequence numbers).
  408|      0|  log::Reader reader(file, &reporter, true /*checksum*/, 0 /*initial_offset*/);
  409|      0|  Log(options_.info_log, "Recovering log #%llu",
  410|      0|      (unsigned long long)log_number);
  411|      0|
  412|      0|  // Read all the records and add to a memtable
  413|      0|  std::string scratch;
  414|      0|  Slice record;
  415|      0|  WriteBatch batch;
  416|      0|  int compactions = 0;
  417|      0|  MemTable* mem = nullptr;
  418|      0|  while (reader.ReadRecord(&record, &scratch) && status.ok()) {
  419|      0|    if (record.size() < 12) {
  420|      0|      reporter.Corruption(record.size(),
  421|      0|                          Status::Corruption("log record too small"));
  422|      0|      continue;
  423|      0|    }
  424|      0|    WriteBatchInternal::SetContents(&batch, record);
  425|      0|
  426|      0|    if (mem == nullptr) {
  427|      0|      mem = new MemTable(internal_comparator_);
  428|      0|      mem->Ref();
  429|      0|    }
  430|      0|    status = WriteBatchInternal::InsertInto(&batch, mem);
  431|      0|    MaybeIgnoreError(&status);
  432|      0|    if (!status.ok()) {
  433|      0|      break;
  434|      0|    }
  435|      0|    const SequenceNumber last_seq = WriteBatchInternal::Sequence(&batch) +
  436|      0|                                    WriteBatchInternal::Count(&batch) - 1;
  437|      0|    if (last_seq > *max_sequence) {
  438|      0|      *max_sequence = last_seq;
  439|      0|    }
  440|      0|
  441|      0|    if (mem->ApproximateMemoryUsage() > options_.write_buffer_size) {
  442|      0|      compactions++;
  443|      0|      *save_manifest = true;
  444|      0|      status = WriteLevel0Table(mem, edit, nullptr);
  445|      0|      mem->Unref();
  446|      0|      mem = nullptr;
  447|      0|      if (!status.ok()) {
  448|      0|        // Reflect errors immediately so that conditions like full
  449|      0|        // file-systems cause the DB::Open() to fail.
  450|      0|        break;
  451|      0|      }
  452|      0|    }
  453|      0|  }
  454|      0|
  455|      0|  delete file;
  456|      0|
  457|      0|  // See if we should keep reusing the last log file.
  458|      0|  if (status.ok() && options_.reuse_logs && last_log && compactions == 0) {
  459|      0|    assert(logfile_ == nullptr);
  460|      0|    assert(log_ == nullptr);
  461|      0|    assert(mem_ == nullptr);
  462|      0|    uint64_t lfile_size;
  463|      0|    if (env_->GetFileSize(fname, &lfile_size).ok() &&
  464|      0|        env_->NewAppendableFile(fname, &logfile_).ok()) {
  465|      0|      Log(options_.info_log, "Reusing old log %s \n", fname.c_str());
  466|      0|      log_ = new log::Writer(logfile_, lfile_size);
  467|      0|      logfile_number_ = log_number;
  468|      0|      if (mem != nullptr) {
  469|      0|        mem_ = mem;
  470|      0|        mem = nullptr;
  471|      0|      } else {
  472|      0|        // mem can be nullptr if lognum exists but was empty.
  473|      0|        mem_ = new MemTable(internal_comparator_);
  474|      0|        mem_->Ref();
  475|      0|      }
  476|      0|    }
  477|      0|  }
  478|      0|
  479|      0|  if (mem != nullptr) {
  480|      0|    // mem did not get reused; compact it.
  481|      0|    if (status.ok()) {
  482|      0|      *save_manifest = true;
  483|      0|      status = WriteLevel0Table(mem, edit, nullptr);
  484|      0|    }
  485|      0|    mem->Unref();
  486|      0|  }
  487|      0|
  488|      0|  return status;
  489|      0|}
  490|       |
  491|       |Status DBImpl::WriteLevel0Table(MemTable* mem, VersionEdit* edit,
  492|      0|                                Version* base) {
  493|      0|  mutex_.AssertHeld();
  494|      0|  const uint64_t start_micros = env_->NowMicros();
  495|      0|  FileMetaData meta;
  496|      0|  meta.number = versions_->NewFileNumber();
  497|      0|  pending_outputs_.insert(meta.number);
  498|      0|  Iterator* iter = mem->NewIterator();
  499|      0|  Log(options_.info_log, "Level-0 table #%llu: started",
  500|      0|      (unsigned long long)meta.number);
  501|      0|
  502|      0|  Status s;
  503|      0|  {
  504|      0|    mutex_.Unlock();
  505|      0|    s = BuildTable(dbname_, env_, options_, table_cache_, iter, &meta);
  506|      0|    mutex_.Lock();
  507|      0|  }
  508|      0|
  509|      0|  Log(options_.info_log, "Level-0 table #%llu: %lld bytes %s",
  510|      0|      (unsigned long long)meta.number, (unsigned long long)meta.file_size,
  511|      0|      s.ToString().c_str());
  512|      0|  delete iter;
  513|      0|  pending_outputs_.erase(meta.number);
  514|      0|
  515|      0|  // Note that if file_size is zero, the file has been deleted and
  516|      0|  // should not be added to the manifest.
  517|      0|  int level = 0;
  518|      0|  if (s.ok() && meta.file_size > 0) {
  519|      0|    const Slice min_user_key = meta.smallest.user_key();
  520|      0|    const Slice max_user_key = meta.largest.user_key();
  521|      0|    if (base != nullptr) {
  522|      0|      level = base->PickLevelForMemTableOutput(min_user_key, max_user_key);
  523|      0|    }
  524|      0|    edit->AddFile(level, meta.number, meta.file_size, meta.smallest,
  525|      0|                  meta.largest);
  526|      0|  }
  527|      0|
  528|      0|  CompactionStats stats;
  529|      0|  stats.micros = env_->NowMicros() - start_micros;
  530|      0|  stats.bytes_written = meta.file_size;
  531|      0|  stats_[level].Add(stats);
  532|      0|  return s;
  533|      0|}
  534|       |
  535|      0|void DBImpl::CompactMemTable() {
  536|      0|  mutex_.AssertHeld();
  537|      0|  assert(imm_ != nullptr);
  538|      0|
  539|      0|  // Save the contents of the memtable as a new Table
  540|      0|  VersionEdit edit;
  541|      0|  Version* base = versions_->current();
  542|      0|  base->Ref();
  543|      0|  Status s = WriteLevel0Table(imm_, &edit, base);
  544|      0|  base->Unref();
  545|      0|
  546|      0|  if (s.ok() && shutting_down_.load(std::memory_order_acquire)) {
  547|      0|    s = Status::IOError("Deleting DB during memtable compaction");
  548|      0|  }
  549|      0|
  550|      0|  // Replace immutable memtable with the generated Table
  551|      0|  if (s.ok()) {
  552|      0|    edit.SetPrevLogNumber(0);
  553|      0|    edit.SetLogNumber(logfile_number_);  // Earlier logs no longer needed
  554|      0|    s = versions_->LogAndApply(&edit, &mutex_);
  555|      0|  }
  556|      0|
  557|      0|  if (s.ok()) {
  558|      0|    // Commit to the new state
  559|      0|    imm_->Unref();
  560|      0|    imm_ = nullptr;
  561|      0|    has_imm_.store(false, std::memory_order_release);
  562|      0|    DeleteObsoleteFiles();
  563|      0|  } else {
  564|      0|    RecordBackgroundError(s);
  565|      0|  }
  566|      0|}
  567|       |
  568|      0|void DBImpl::CompactRange(const Slice* begin, const Slice* end) {
  569|      0|  int max_level_with_files = 1;
  570|      0|  {
  571|      0|    MutexLock l(&mutex_);
  572|      0|    Version* base = versions_->current();
  573|      0|    for (int level = 1; level < config::kNumLevels; level++) {
  574|      0|      if (base->OverlapInLevel(level, begin, end)) {
  575|      0|        max_level_with_files = level;
  576|      0|      }
  577|      0|    }
  578|      0|  }
  579|      0|  TEST_CompactMemTable();  // TODO(sanjay): Skip if memtable does not overlap
  580|      0|  for (int level = 0; level < max_level_with_files; level++) {
  581|      0|    TEST_CompactRange(level, begin, end);
  582|      0|  }
  583|      0|}
  584|       |
  585|       |void DBImpl::TEST_CompactRange(int level, const Slice* begin,
  586|      0|                               const Slice* end) {
  587|      0|  assert(level >= 0);
  588|      0|  assert(level + 1 < config::kNumLevels);
  589|      0|
  590|      0|  InternalKey begin_storage, end_storage;
  591|      0|
  592|      0|  ManualCompaction manual;
  593|      0|  manual.level = level;
  594|      0|  manual.done = false;
  595|      0|  if (begin == nullptr) {
  596|      0|    manual.begin = nullptr;
  597|      0|  } else {
  598|      0|    begin_storage = InternalKey(*begin, kMaxSequenceNumber, kValueTypeForSeek);
  599|      0|    manual.begin = &begin_storage;
  600|      0|  }
  601|      0|  if (end == nullptr) {
  602|      0|    manual.end = nullptr;
  603|      0|  } else {
  604|      0|    end_storage = InternalKey(*end, 0, static_cast<ValueType>(0));
  605|      0|    manual.end = &end_storage;
  606|      0|  }
  607|      0|
  608|      0|  MutexLock l(&mutex_);
  609|      0|  while (!manual.done && !shutting_down_.load(std::memory_order_acquire) &&
  610|      0|         bg_error_.ok()) {
  611|      0|    if (manual_compaction_ == nullptr) {  // Idle
  612|      0|      manual_compaction_ = &manual;
  613|      0|      MaybeScheduleCompaction();
  614|      0|    } else {  // Running either my compaction or another compaction.
  615|      0|      background_work_finished_signal_.Wait();
  616|      0|    }
  617|      0|  }
  618|      0|  if (manual_compaction_ == &manual) {
  619|      0|    // Cancel my manual compaction since we aborted early for some reason.
  620|      0|    manual_compaction_ = nullptr;
  621|      0|  }
  622|      0|}
  623|       |
  624|      0|Status DBImpl::TEST_CompactMemTable() {
  625|      0|  // nullptr batch means just wait for earlier writes to be done
  626|      0|  Status s = Write(WriteOptions(), nullptr);
  627|      0|  if (s.ok()) {
  628|      0|    // Wait until the compaction completes
  629|      0|    MutexLock l(&mutex_);
  630|      0|    while (imm_ != nullptr && bg_error_.ok()) {
  631|      0|      background_work_finished_signal_.Wait();
  632|      0|    }
  633|      0|    if (imm_ != nullptr) {
  634|      0|      s = bg_error_;
  635|      0|    }
  636|      0|  }
  637|      0|  return s;
  638|      0|}
  639|       |
  640|      0|void DBImpl::RecordBackgroundError(const Status& s) {
  641|      0|  mutex_.AssertHeld();
  642|      0|  if (bg_error_.ok()) {
  643|      0|    bg_error_ = s;
  644|      0|    background_work_finished_signal_.SignalAll();
  645|      0|  }
  646|      0|}
  647|       |
  648|      0|void DBImpl::MaybeScheduleCompaction() {
  649|      0|  mutex_.AssertHeld();
  650|      0|  if (background_compaction_scheduled_) {
  651|      0|    // Already scheduled
  652|      0|  } else if (shutting_down_.load(std::memory_order_acquire)) {
  653|      0|    // DB is being deleted; no more background compactions
  654|      0|  } else if (!bg_error_.ok()) {
  655|      0|    // Already got an error; no more changes
  656|      0|  } else if (imm_ == nullptr && manual_compaction_ == nullptr &&
  657|      0|             !versions_->NeedsCompaction()) {
  658|      0|    // No work to be done
  659|      0|  } else {
  660|      0|    background_compaction_scheduled_ = true;
  661|      0|    env_->Schedule(&DBImpl::BGWork, this);
  662|      0|  }
  663|      0|}
  664|       |
  665|      0|void DBImpl::BGWork(void* db) {
  666|      0|  reinterpret_cast<DBImpl*>(db)->BackgroundCall();
  667|      0|}
  668|       |
  669|      0|void DBImpl::BackgroundCall() {
  670|      0|  MutexLock l(&mutex_);
  671|      0|  assert(background_compaction_scheduled_);
  672|      0|  if (shutting_down_.load(std::memory_order_acquire)) {
  673|      0|    // No more background work when shutting down.
  674|      0|  } else if (!bg_error_.ok()) {
  675|      0|    // No more background work after a background error.
  676|      0|  } else {
  677|      0|    BackgroundCompaction();
  678|      0|  }
  679|      0|
  680|      0|  background_compaction_scheduled_ = false;
  681|      0|
  682|      0|  // Previous compaction may have produced too many files in a level,
  683|      0|  // so reschedule another compaction if needed.
  684|      0|  MaybeScheduleCompaction();
  685|      0|  background_work_finished_signal_.SignalAll();
  686|      0|}
  687|       |
  688|      0|void DBImpl::BackgroundCompaction() {
  689|      0|  mutex_.AssertHeld();
  690|      0|
  691|      0|  if (imm_ != nullptr) {
  692|      0|    CompactMemTable();
  693|      0|    return;
  694|      0|  }
  695|      0|
  696|      0|  Compaction* c;
  697|      0|  bool is_manual = (manual_compaction_ != nullptr);
  698|      0|  InternalKey manual_end;
  699|      0|  if (is_manual) {
  700|      0|    ManualCompaction* m = manual_compaction_;
  701|      0|    c = versions_->CompactRange(m->level, m->begin, m->end);
  702|      0|    m->done = (c == nullptr);
  703|      0|    if (c != nullptr) {
  704|      0|      manual_end = c->input(0, c->num_input_files(0) - 1)->largest;
  705|      0|    }
  706|      0|    Log(options_.info_log,
  707|      0|        "Manual compaction at level-%d from %s .. %s; will stop at %s\n",
  708|      0|        m->level, (m->begin ? m->begin->DebugString().c_str() : "(begin)"),
  709|      0|        (m->end ? m->end->DebugString().c_str() : "(end)"),
  710|      0|        (m->done ? "(end)" : manual_end.DebugString().c_str()));
  711|      0|  } else {
  712|      0|    c = versions_->PickCompaction();
  713|      0|  }
  714|      0|
  715|      0|  Status status;
  716|      0|  if (c == nullptr) {
  717|      0|    // Nothing to do
  718|      0|  } else if (!is_manual && c->IsTrivialMove()) {
  719|      0|    // Move file to next level
  720|      0|    assert(c->num_input_files(0) == 1);
  721|      0|    FileMetaData* f = c->input(0, 0);
  722|      0|    c->edit()->DeleteFile(c->level(), f->number);
  723|      0|    c->edit()->AddFile(c->level() + 1, f->number, f->file_size, f->smallest,
  724|      0|                       f->largest);
  725|      0|    status = versions_->LogAndApply(c->edit(), &mutex_);
  726|      0|    if (!status.ok()) {
  727|      0|      RecordBackgroundError(status);
  728|      0|    }
  729|      0|    VersionSet::LevelSummaryStorage tmp;
  730|      0|    Log(options_.info_log, "Moved #%lld to level-%d %lld bytes %s: %s\n",
  731|      0|        static_cast<unsigned long long>(f->number), c->level() + 1,
  732|      0|        static_cast<unsigned long long>(f->file_size),
  733|      0|        status.ToString().c_str(), versions_->LevelSummary(&tmp));
  734|      0|  } else {
  735|      0|    CompactionState* compact = new CompactionState(c);
  736|      0|    status = DoCompactionWork(compact);
  737|      0|    if (!status.ok()) {
  738|      0|      RecordBackgroundError(status);
  739|      0|    }
  740|      0|    CleanupCompaction(compact);
  741|      0|    c->ReleaseInputs();
  742|      0|    DeleteObsoleteFiles();
  743|      0|  }
  744|      0|  delete c;
  745|      0|
  746|      0|  if (status.ok()) {
  747|      0|    // Done
  748|      0|  } else if (shutting_down_.load(std::memory_order_acquire)) {
  749|      0|    // Ignore compaction errors found during shutting down
  750|      0|  } else {
  751|      0|    Log(options_.info_log, "Compaction error: %s", status.ToString().c_str());
  752|      0|  }
  753|      0|
  754|      0|  if (is_manual) {
  755|      0|    ManualCompaction* m = manual_compaction_;
  756|      0|    if (!status.ok()) {
  757|      0|      m->done = true;
  758|      0|    }
  759|      0|    if (!m->done) {
  760|      0|      // We only compacted part of the requested range.  Update *m
  761|      0|      // to the range that is left to be compacted.
  762|      0|      m->tmp_storage = manual_end;
  763|      0|      m->begin = &m->tmp_storage;
  764|      0|    }
  765|      0|    manual_compaction_ = nullptr;
  766|      0|  }
  767|      0|}
  768|       |
  769|      0|void DBImpl::CleanupCompaction(CompactionState* compact) {
  770|      0|  mutex_.AssertHeld();
  771|      0|  if (compact->builder != nullptr) {
  772|      0|    // May happen if we get a shutdown call in the middle of compaction
  773|      0|    compact->builder->Abandon();
  774|      0|    delete compact->builder;
  775|      0|  } else {
  776|      0|    assert(compact->outfile == nullptr);
  777|      0|  }
  778|      0|  delete compact->outfile;
  779|      0|  for (size_t i = 0; i < compact->outputs.size(); i++) {
  780|      0|    const CompactionState::Output& out = compact->outputs[i];
  781|      0|    pending_outputs_.erase(out.number);
  782|      0|  }
  783|      0|  delete compact;
  784|      0|}
  785|       |
  786|      0|Status DBImpl::OpenCompactionOutputFile(CompactionState* compact) {
  787|      0|  assert(compact != nullptr);
  788|      0|  assert(compact->builder == nullptr);
  789|      0|  uint64_t file_number;
  790|      0|  {
  791|      0|    mutex_.Lock();
  792|      0|    file_number = versions_->NewFileNumber();
  793|      0|    pending_outputs_.insert(file_number);
  794|      0|    CompactionState::Output out;
  795|      0|    out.number = file_number;
  796|      0|    out.smallest.Clear();
  797|      0|    out.largest.Clear();
  798|      0|    compact->outputs.push_back(out);
  799|      0|    mutex_.Unlock();
  800|      0|  }
  801|      0|
  802|      0|  // Make the output file
  803|      0|  std::string fname = TableFileName(dbname_, file_number);
  804|      0|  Status s = env_->NewWritableFile(fname, &compact->outfile);
  805|      0|  if (s.ok()) {
  806|      0|    compact->builder = new TableBuilder(options_, compact->outfile);
  807|      0|  }
  808|      0|  return s;
  809|      0|}
  810|       |
  811|       |Status DBImpl::FinishCompactionOutputFile(CompactionState* compact,
  812|      0|                                          Iterator* input) {
  813|      0|  assert(compact != nullptr);
  814|      0|  assert(compact->outfile != nullptr);
  815|      0|  assert(compact->builder != nullptr);
  816|      0|
  817|      0|  const uint64_t output_number = compact->current_output()->number;
  818|      0|  assert(output_number != 0);
  819|      0|
  820|      0|  // Check for iterator errors
  821|      0|  Status s = input->status();
  822|      0|  const uint64_t current_entries = compact->builder->NumEntries();
  823|      0|  if (s.ok()) {
  824|      0|    s = compact->builder->Finish();
  825|      0|  } else {
  826|      0|    compact->builder->Abandon();
  827|      0|  }
  828|      0|  const uint64_t current_bytes = compact->builder->FileSize();
  829|      0|  compact->current_output()->file_size = current_bytes;
  830|      0|  compact->total_bytes += current_bytes;
  831|      0|  delete compact->builder;
  832|      0|  compact->builder = nullptr;
  833|      0|
  834|      0|  // Finish and check for file errors
  835|      0|  if (s.ok()) {
  836|      0|    s = compact->outfile->Sync();
  837|      0|  }
  838|      0|  if (s.ok()) {
  839|      0|    s = compact->outfile->Close();
  840|      0|  }
  841|      0|  delete compact->outfile;
  842|      0|  compact->outfile = nullptr;
  843|      0|
  844|      0|  if (s.ok() && current_entries > 0) {
  845|      0|    // Verify that the table is usable
  846|      0|    Iterator* iter =
  847|      0|        table_cache_->NewIterator(ReadOptions(), output_number, current_bytes);
  848|      0|    s = iter->status();
  849|      0|    delete iter;
  850|      0|    if (s.ok()) {
  851|      0|      Log(options_.info_log, "Generated table #%llu@%d: %lld keys, %lld bytes",
  852|      0|          (unsigned long long)output_number, compact->compaction->level(),
  853|      0|          (unsigned long long)current_entries,
  854|      0|          (unsigned long long)current_bytes);
  855|      0|    }
  856|      0|  }
  857|      0|  return s;
  858|      0|}
  859|       |
  860|      0|Status DBImpl::InstallCompactionResults(CompactionState* compact) {
  861|      0|  mutex_.AssertHeld();
  862|      0|  Log(options_.info_log, "Compacted %d@%d + %d@%d files => %lld bytes",
  863|      0|      compact->compaction->num_input_files(0), compact->compaction->level(),
  864|      0|      compact->compaction->num_input_files(1), compact->compaction->level() + 1,
  865|      0|      static_cast<long long>(compact->total_bytes));
  866|      0|
  867|      0|  // Add compaction outputs
  868|      0|  compact->compaction->AddInputDeletions(compact->compaction->edit());
  869|      0|  const int level = compact->compaction->level();
  870|      0|  for (size_t i = 0; i < compact->outputs.size(); i++) {
  871|      0|    const CompactionState::Output& out = compact->outputs[i];
  872|      0|    compact->compaction->edit()->AddFile(level + 1, out.number, out.file_size,
  873|      0|                                         out.smallest, out.largest);
  874|      0|  }
  875|      0|  return versions_->LogAndApply(compact->compaction->edit(), &mutex_);
  876|      0|}
  877|       |
  878|      0|Status DBImpl::DoCompactionWork(CompactionState* compact) {
  879|      0|  const uint64_t start_micros = env_->NowMicros();
  880|      0|  int64_t imm_micros = 0;  // Micros spent doing imm_ compactions
  881|      0|
  882|      0|  Log(options_.info_log, "Compacting %d@%d + %d@%d files",
  883|      0|      compact->compaction->num_input_files(0), compact->compaction->level(),
  884|      0|      compact->compaction->num_input_files(1),
  885|      0|      compact->compaction->level() + 1);
  886|      0|
  887|      0|  assert(versions_->NumLevelFiles(compact->compaction->level()) > 0);
  888|      0|  assert(compact->builder == nullptr);
  889|      0|  assert(compact->outfile == nullptr);
  890|      0|  if (snapshots_.empty()) {
  891|      0|    compact->smallest_snapshot = versions_->LastSequence();
  892|      0|  } else {
  893|      0|    compact->smallest_snapshot = snapshots_.oldest()->sequence_number();
  894|      0|  }
  895|      0|
  896|      0|  // Release mutex while we're actually doing the compaction work
  897|      0|  mutex_.Unlock();
  898|      0|
  899|      0|  Iterator* input = versions_->MakeInputIterator(compact->compaction);
  900|      0|  input->SeekToFirst();
  901|      0|  Status status;
  902|      0|  ParsedInternalKey ikey;
  903|      0|  std::string current_user_key;
  904|      0|  bool has_current_user_key = false;
  905|      0|  SequenceNumber last_sequence_for_key = kMaxSequenceNumber;
  906|      0|  for (; input->Valid() && !shutting_down_.load(std::memory_order_acquire);) {
  907|      0|    // Prioritize immutable compaction work
  908|      0|    if (has_imm_.load(std::memory_order_relaxed)) {
  909|      0|      const uint64_t imm_start = env_->NowMicros();
  910|      0|      mutex_.Lock();
  911|      0|      if (imm_ != nullptr) {
  912|      0|        CompactMemTable();
  913|      0|        // Wake up MakeRoomForWrite() if necessary.
  914|      0|        background_work_finished_signal_.SignalAll();
  915|      0|      }
  916|      0|      mutex_.Unlock();
  917|      0|      imm_micros += (env_->NowMicros() - imm_start);
  918|      0|    }
  919|      0|
  920|      0|    Slice key = input->key();
  921|      0|    if (compact->compaction->ShouldStopBefore(key) &&
  922|      0|        compact->builder != nullptr) {
  923|      0|      status = FinishCompactionOutputFile(compact, input);
  924|      0|      if (!status.ok()) {
  925|      0|        break;
  926|      0|      }
  927|      0|    }
  928|      0|
  929|      0|    // Handle key/value, add to state, etc.
  930|      0|    bool drop = false;
  931|      0|    if (!ParseInternalKey(key, &ikey)) {
  932|      0|      // Do not hide error keys
  933|      0|      current_user_key.clear();
  934|      0|      has_current_user_key = false;
  935|      0|      last_sequence_for_key = kMaxSequenceNumber;
  936|      0|    } else {
  937|      0|      if (!has_current_user_key ||
  938|      0|          user_comparator()->Compare(ikey.user_key, Slice(current_user_key)) !=
  939|      0|              0) {
  940|      0|        // First occurrence of this user key
  941|      0|        current_user_key.assign(ikey.user_key.data(), ikey.user_key.size());
  942|      0|        has_current_user_key = true;
  943|      0|        last_sequence_for_key = kMaxSequenceNumber;
  944|      0|      }
  945|      0|
  946|      0|      if (last_sequence_for_key <= compact->smallest_snapshot) {
  947|      0|        // Hidden by an newer entry for same user key
  948|      0|        drop = true;  // (A)
  949|      0|      } else if (ikey.type == kTypeDeletion &&
  950|      0|                 ikey.sequence <= compact->smallest_snapshot &&
  951|      0|                 compact->compaction->IsBaseLevelForKey(ikey.user_key)) {
  952|      0|        // For this user key:
  953|      0|        // (1) there is no data in higher levels
  954|      0|        // (2) data in lower levels will have larger sequence numbers
  955|      0|        // (3) data in layers that are being compacted here and have
  956|      0|        //     smaller sequence numbers will be dropped in the next
  957|      0|        //     few iterations of this loop (by rule (A) above).
  958|      0|        // Therefore this deletion marker is obsolete and can be dropped.
  959|      0|        drop = true;
  960|      0|      }
  961|      0|
  962|      0|      last_sequence_for_key = ikey.sequence;
  963|      0|    }
  964|       |#if 0
  965|       |    Log(options_.info_log,
  966|       |        "  Compact: %s, seq %d, type: %d %d, drop: %d, is_base: %d, "
  967|       |        "%d smallest_snapshot: %d",
  968|       |        ikey.user_key.ToString().c_str(),
  969|       |        (int)ikey.sequence, ikey.type, kTypeValue, drop,
  970|       |        compact->compaction->IsBaseLevelForKey(ikey.user_key),
  971|       |        (int)last_sequence_for_key, (int)compact->smallest_snapshot);
  972|       |#endif
  973|       |
  974|      0|    if (!drop) {
  975|      0|      // Open output file if necessary
  976|      0|      if (compact->builder == nullptr) {
  977|      0|        status = OpenCompactionOutputFile(compact);
  978|      0|        if (!status.ok()) {
  979|      0|          break;
  980|      0|        }
  981|      0|      }
  982|      0|      if (compact->builder->NumEntries() == 0) {
  983|      0|        compact->current_output()->smallest.DecodeFrom(key);
  984|      0|      }
  985|      0|      compact->current_output()->largest.DecodeFrom(key);
  986|      0|      compact->builder->Add(key, input->value());
  987|      0|
  988|      0|      // Close output file if it is big enough
  989|      0|      if (compact->builder->FileSize() >=
  990|      0|          compact->compaction->MaxOutputFileSize()) {
  991|      0|        status = FinishCompactionOutputFile(compact, input);
  992|      0|        if (!status.ok()) {
  993|      0|          break;
  994|      0|        }
  995|      0|      }
  996|      0|    }
  997|      0|
  998|      0|    input->Next();
  999|      0|  }
 1000|      0|
 1001|      0|  if (status.ok() && shutting_down_.load(std::memory_order_acquire)) {
 1002|      0|    status = Status::IOError("Deleting DB during compaction");
 1003|      0|  }
 1004|      0|  if (status.ok() && compact->builder != nullptr) {
 1005|      0|    status = FinishCompactionOutputFile(compact, input);
 1006|      0|  }
 1007|      0|  if (status.ok()) {
 1008|      0|    status = input->status();
 1009|      0|  }
 1010|      0|  delete input;
 1011|      0|  input = nullptr;
 1012|      0|
 1013|      0|  CompactionStats stats;
 1014|      0|  stats.micros = env_->NowMicros() - start_micros - imm_micros;
 1015|      0|  for (int which = 0; which < 2; which++) {
 1016|      0|    for (int i = 0; i < compact->compaction->num_input_files(which); i++) {
 1017|      0|      stats.bytes_read += compact->compaction->input(which, i)->file_size;
 1018|      0|    }
 1019|      0|  }
 1020|      0|  for (size_t i = 0; i < compact->outputs.size(); i++) {
 1021|      0|    stats.bytes_written += compact->outputs[i].file_size;
 1022|      0|  }
 1023|      0|
 1024|      0|  mutex_.Lock();
 1025|      0|  stats_[compact->compaction->level() + 1].Add(stats);
 1026|      0|
 1027|      0|  if (status.ok()) {
 1028|      0|    status = InstallCompactionResults(compact);
 1029|      0|  }
 1030|      0|  if (!status.ok()) {
 1031|      0|    RecordBackgroundError(status);
 1032|      0|  }
 1033|      0|  VersionSet::LevelSummaryStorage tmp;
 1034|      0|  Log(options_.info_log, "compacted to: %s", versions_->LevelSummary(&tmp));
 1035|      0|  return status;
 1036|      0|}
 1037|       |
 1038|       |namespace {
 1039|       |
 1040|       |struct IterState {
 1041|       |  port::Mutex* const mu;
 1042|       |  Version* const version GUARDED_BY(mu);
 1043|       |  MemTable* const mem GUARDED_BY(mu);
 1044|       |  MemTable* const imm GUARDED_BY(mu);
 1045|       |
 1046|       |  IterState(port::Mutex* mutex, MemTable* mem, MemTable* imm, Version* version)
 1047|      0|      : mu(mutex), version(version), mem(mem), imm(imm) {}
 1048|       |};
 1049|       |
 1050|      0|static void CleanupIteratorState(void* arg1, void* arg2) {
 1051|      0|  IterState* state = reinterpret_cast<IterState*>(arg1);
 1052|      0|  state->mu->Lock();
 1053|      0|  state->mem->Unref();
 1054|      0|  if (state->imm != nullptr) state->imm->Unref();
 1055|      0|  state->version->Unref();
 1056|      0|  state->mu->Unlock();
 1057|      0|  delete state;
 1058|      0|}
 1059|       |
 1060|       |}  // anonymous namespace
 1061|       |
 1062|       |Iterator* DBImpl::NewInternalIterator(const ReadOptions& options,
 1063|       |                                      SequenceNumber* latest_snapshot,
 1064|      0|                                      uint32_t* seed) {
 1065|      0|  mutex_.Lock();
 1066|      0|  *latest_snapshot = versions_->LastSequence();
 1067|      0|
 1068|      0|  // Collect together all needed child iterators
 1069|      0|  std::vector<Iterator*> list;
 1070|      0|  list.push_back(mem_->NewIterator());
 1071|      0|  mem_->Ref();
 1072|      0|  if (imm_ != nullptr) {
 1073|      0|    list.push_back(imm_->NewIterator());
 1074|      0|    imm_->Ref();
 1075|      0|  }
 1076|      0|  versions_->current()->AddIterators(options, &list);
 1077|      0|  Iterator* internal_iter =
 1078|      0|      NewMergingIterator(&internal_comparator_, &list[0], list.size());
 1079|      0|  versions_->current()->Ref();
 1080|      0|
 1081|      0|  IterState* cleanup = new IterState(&mutex_, mem_, imm_, versions_->current());
 1082|      0|  internal_iter->RegisterCleanup(CleanupIteratorState, cleanup, nullptr);
 1083|      0|
 1084|      0|  *seed = ++seed_;
 1085|      0|  mutex_.Unlock();
 1086|      0|  return internal_iter;
 1087|      0|}
 1088|       |
 1089|      0|Iterator* DBImpl::TEST_NewInternalIterator() {
 1090|      0|  SequenceNumber ignored;
 1091|      0|  uint32_t ignored_seed;
 1092|      0|  return NewInternalIterator(ReadOptions(), &ignored, &ignored_seed);
 1093|      0|}
 1094|       |
 1095|      0|int64_t DBImpl::TEST_MaxNextLevelOverlappingBytes() {
 1096|      0|  MutexLock l(&mutex_);
 1097|      0|  return versions_->MaxNextLevelOverlappingBytes();
 1098|      0|}
 1099|       |
 1100|       |Status DBImpl::Get(const ReadOptions& options, const Slice& key,
 1101|      0|                   std::string* value) {
 1102|      0|  Status s;
 1103|      0|  MutexLock l(&mutex_);
 1104|      0|  SequenceNumber snapshot;
 1105|      0|  if (options.snapshot != nullptr) {
 1106|      0|    snapshot =
 1107|      0|        static_cast<const SnapshotImpl*>(options.snapshot)->sequence_number();
 1108|      0|  } else {
 1109|      0|    snapshot = versions_->LastSequence();
 1110|      0|  }
 1111|      0|
 1112|      0|  MemTable* mem = mem_;
 1113|      0|  MemTable* imm = imm_;
 1114|      0|  Version* current = versions_->current();
 1115|      0|  mem->Ref();
 1116|      0|  if (imm != nullptr) imm->Ref();
 1117|      0|  current->Ref();
 1118|      0|
 1119|      0|  bool have_stat_update = false;
 1120|      0|  Version::GetStats stats;
 1121|      0|
 1122|      0|  // Unlock while reading from files and memtables
 1123|      0|  {
 1124|      0|    mutex_.Unlock();
 1125|      0|    // First look in the memtable, then in the immutable memtable (if any).
 1126|      0|    LookupKey lkey(key, snapshot);
 1127|      0|    if (mem->Get(lkey, value, &s)) {
 1128|      0|      // Done
 1129|      0|    } else if (imm != nullptr && imm->Get(lkey, value, &s)) {
 1130|      0|      // Done
 1131|      0|    } else {
 1132|      0|      s = current->Get(options, lkey, value, &stats);
 1133|      0|      have_stat_update = true;
 1134|      0|    }
 1135|      0|    mutex_.Lock();
 1136|      0|  }
 1137|      0|
 1138|      0|  if (have_stat_update && current->UpdateStats(stats)) {
 1139|      0|    MaybeScheduleCompaction();
 1140|      0|  }
 1141|      0|  mem->Unref();
 1142|      0|  if (imm != nullptr) imm->Unref();
 1143|      0|  current->Unref();
 1144|      0|  return s;
 1145|      0|}
 1146|       |
 1147|      0|Iterator* DBImpl::NewIterator(const ReadOptions& options) {
 1148|      0|  SequenceNumber latest_snapshot;
 1149|      0|  uint32_t seed;
 1150|      0|  Iterator* iter = NewInternalIterator(options, &latest_snapshot, &seed);
 1151|      0|  return NewDBIterator(this, user_comparator(), iter,
 1152|      0|                       (options.snapshot != nullptr
 1153|      0|                            ? static_cast<const SnapshotImpl*>(options.snapshot)
 1154|      0|                                  ->sequence_number()
 1155|      0|                            : latest_snapshot),
 1156|      0|                       seed);
 1157|      0|}
 1158|       |
 1159|      0|void DBImpl::RecordReadSample(Slice key) {
 1160|      0|  MutexLock l(&mutex_);
 1161|      0|  if (versions_->current()->RecordReadSample(key)) {
 1162|      0|    MaybeScheduleCompaction();
 1163|      0|  }
 1164|      0|}
 1165|       |
 1166|      0|const Snapshot* DBImpl::GetSnapshot() {
 1167|      0|  MutexLock l(&mutex_);
 1168|      0|  return snapshots_.New(versions_->LastSequence());
 1169|      0|}
 1170|       |
 1171|      0|void DBImpl::ReleaseSnapshot(const Snapshot* snapshot) {
 1172|      0|  MutexLock l(&mutex_);
 1173|      0|  snapshots_.Delete(static_cast<const SnapshotImpl*>(snapshot));
 1174|      0|}
 1175|       |
 1176|       |// Convenience methods
 1177|      0|Status DBImpl::Put(const WriteOptions& o, const Slice& key, const Slice& val) {
 1178|      0|  return DB::Put(o, key, val);
 1179|      0|}
 1180|       |
 1181|      0|Status DBImpl::Delete(const WriteOptions& options, const Slice& key) {
 1182|      0|  return DB::Delete(options, key);
 1183|      0|}
 1184|       |
 1185|      0|Status DBImpl::Write(const WriteOptions& options, WriteBatch* updates) {
 1186|      0|  Writer w(&mutex_);
 1187|      0|  w.batch = updates;
 1188|      0|  w.sync = options.sync;
 1189|      0|  w.done = false;
 1190|      0|
 1191|      0|  MutexLock l(&mutex_);
 1192|      0|  writers_.push_back(&w);
 1193|      0|  while (!w.done && &w != writers_.front()) {
 1194|      0|    w.cv.Wait();
 1195|      0|  }
 1196|      0|  if (w.done) {
 1197|      0|    return w.status;
 1198|      0|  }
 1199|      0|
 1200|      0|  // May temporarily unlock and wait.
 1201|      0|  Status status = MakeRoomForWrite(updates == nullptr);
 1202|      0|  uint64_t last_sequence = versions_->LastSequence();
 1203|      0|  Writer* last_writer = &w;
 1204|      0|  if (status.ok() && updates != nullptr) {  // nullptr batch is for compactions
 1205|      0|    WriteBatch* updates = BuildBatchGroup(&last_writer);
 1206|      0|    WriteBatchInternal::SetSequence(updates, last_sequence + 1);
 1207|      0|    last_sequence += WriteBatchInternal::Count(updates);
 1208|      0|
 1209|      0|    // Add to log and apply to memtable.  We can release the lock
 1210|      0|    // during this phase since &w is currently responsible for logging
 1211|      0|    // and protects against concurrent loggers and concurrent writes
 1212|      0|    // into mem_.
 1213|      0|    {
 1214|      0|      mutex_.Unlock();
 1215|      0|      status = log_->AddRecord(WriteBatchInternal::Contents(updates));
 1216|      0|      bool sync_error = false;
 1217|      0|      if (status.ok() && options.sync) {
 1218|      0|        status = logfile_->Sync();
 1219|      0|        if (!status.ok()) {
 1220|      0|          sync_error = true;
 1221|      0|        }
 1222|      0|      }
 1223|      0|      if (status.ok()) {
 1224|      0|        status = WriteBatchInternal::InsertInto(updates, mem_);
 1225|      0|      }
 1226|      0|      mutex_.Lock();
 1227|      0|      if (sync_error) {
 1228|      0|        // The state of the log file is indeterminate: the log record we
 1229|      0|        // just added may or may not show up when the DB is re-opened.
 1230|      0|        // So we force the DB into a mode where all future writes fail.
 1231|      0|        RecordBackgroundError(status);
 1232|      0|      }
 1233|      0|    }
 1234|      0|    if (updates == tmp_batch_) tmp_batch_->Clear();
 1235|      0|
 1236|      0|    versions_->SetLastSequence(last_sequence);
 1237|      0|  }
 1238|      0|
 1239|      0|  while (true) {
 1240|      0|    Writer* ready = writers_.front();
 1241|      0|    writers_.pop_front();
 1242|      0|    if (ready != &w) {
 1243|      0|      ready->status = status;
 1244|      0|      ready->done = true;
 1245|      0|      ready->cv.Signal();
 1246|      0|    }
 1247|      0|    if (ready == last_writer) break;
 1248|      0|  }
 1249|      0|
 1250|      0|  // Notify new head of write queue
 1251|      0|  if (!writers_.empty()) {
 1252|      0|    writers_.front()->cv.Signal();
 1253|      0|  }
 1254|      0|
 1255|      0|  return status;
 1256|      0|}
 1257|       |
 1258|       |// REQUIRES: Writer list must be non-empty
 1259|       |// REQUIRES: First writer must have a non-null batch
 1260|      0|WriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) {
 1261|      0|  mutex_.AssertHeld();
 1262|      0|  assert(!writers_.empty());
 1263|      0|  Writer* first = writers_.front();
 1264|      0|  WriteBatch* result = first->batch;
 1265|      0|  assert(result != nullptr);
 1266|      0|
 1267|      0|  size_t size = WriteBatchInternal::ByteSize(first->batch);
 1268|      0|
 1269|      0|  // Allow the group to grow up to a maximum size, but if the
 1270|      0|  // original write is small, limit the growth so we do not slow
 1271|      0|  // down the small write too much.
 1272|      0|  size_t max_size = 1 << 20;
 1273|      0|  if (size <= (128 << 10)) {
 1274|      0|    max_size = size + (128 << 10);
 1275|      0|  }
 1276|      0|
 1277|      0|  *last_writer = first;
 1278|      0|  std::deque<Writer*>::iterator iter = writers_.begin();
 1279|      0|  ++iter;  // Advance past "first"
 1280|      0|  for (; iter != writers_.end(); ++iter) {
 1281|      0|    Writer* w = *iter;
 1282|      0|    if (w->sync && !first->sync) {
 1283|      0|      // Do not include a sync write into a batch handled by a non-sync write.
 1284|      0|      break;
 1285|      0|    }
 1286|      0|
 1287|      0|    if (w->batch != nullptr) {
 1288|      0|      size += WriteBatchInternal::ByteSize(w->batch);
 1289|      0|      if (size > max_size) {
 1290|      0|        // Do not make batch too big
 1291|      0|        break;
 1292|      0|      }
 1293|      0|
 1294|      0|      // Append to *result
 1295|      0|      if (result == first->batch) {
 1296|      0|        // Switch to temporary batch instead of disturbing caller's batch
 1297|      0|        result = tmp_batch_;
 1298|      0|        assert(WriteBatchInternal::Count(result) == 0);
 1299|      0|        WriteBatchInternal::Append(result, first->batch);
 1300|      0|      }
 1301|      0|      WriteBatchInternal::Append(result, w->batch);
 1302|      0|    }
 1303|      0|    *last_writer = w;
 1304|      0|  }
 1305|      0|  return result;
 1306|      0|}
 1307|       |
 1308|       |// REQUIRES: mutex_ is held
 1309|       |// REQUIRES: this thread is currently at the front of the writer queue
 1310|      0|Status DBImpl::MakeRoomForWrite(bool force) {
 1311|      0|  mutex_.AssertHeld();
 1312|      0|  assert(!writers_.empty());
 1313|      0|  bool allow_delay = !force;
 1314|      0|  Status s;
 1315|      0|  while (true) {
 1316|      0|    if (!bg_error_.ok()) {
 1317|      0|      // Yield previous error
 1318|      0|      s = bg_error_;
 1319|      0|      break;
 1320|      0|    } else if (allow_delay && versions_->NumLevelFiles(0) >=
 1321|      0|                                  config::kL0_SlowdownWritesTrigger) {
 1322|      0|      // We are getting close to hitting a hard limit on the number of
 1323|      0|      // L0 files.  Rather than delaying a single write by several
 1324|      0|      // seconds when we hit the hard limit, start delaying each
 1325|      0|      // individual write by 1ms to reduce latency variance.  Also,
 1326|      0|      // this delay hands over some CPU to the compaction thread in
 1327|      0|      // case it is sharing the same core as the writer.
 1328|      0|      mutex_.Unlock();
 1329|      0|      env_->SleepForMicroseconds(1000);
 1330|      0|      allow_delay = false;  // Do not delay a single write more than once
 1331|      0|      mutex_.Lock();
 1332|      0|    } else if (!force &&
 1333|      0|               (mem_->ApproximateMemoryUsage() <= options_.write_buffer_size)) {
 1334|      0|      // There is room in current memtable
 1335|      0|      break;
 1336|      0|    } else if (imm_ != nullptr) {
 1337|      0|      // We have filled up the current memtable, but the previous
 1338|      0|      // one is still being compacted, so we wait.
 1339|      0|      Log(options_.info_log, "Current memtable full; waiting...\n");
 1340|      0|      background_work_finished_signal_.Wait();
 1341|      0|    } else if (versions_->NumLevelFiles(0) >= config::kL0_StopWritesTrigger) {
 1342|      0|      // There are too many level-0 files.
 1343|      0|      Log(options_.info_log, "Too many L0 files; waiting...\n");
 1344|      0|      background_work_finished_signal_.Wait();
 1345|      0|    } else {
 1346|      0|      // Attempt to switch to a new memtable and trigger compaction of old
 1347|      0|      assert(versions_->PrevLogNumber() == 0);
 1348|      0|      uint64_t new_log_number = versions_->NewFileNumber();
 1349|      0|      WritableFile* lfile = nullptr;
 1350|      0|      s = env_->NewWritableFile(LogFileName(dbname_, new_log_number), &lfile);
 1351|      0|      if (!s.ok()) {
 1352|      0|        // Avoid chewing through file number space in a tight loop.
 1353|      0|        versions_->ReuseFileNumber(new_log_number);
 1354|      0|        break;
 1355|      0|      }
 1356|      0|      delete log_;
 1357|      0|      delete logfile_;
 1358|      0|      logfile_ = lfile;
 1359|      0|      logfile_number_ = new_log_number;
 1360|      0|      log_ = new log::Writer(lfile);
 1361|      0|      imm_ = mem_;
 1362|      0|      has_imm_.store(true, std::memory_order_release);
 1363|      0|      mem_ = new MemTable(internal_comparator_);
 1364|      0|      mem_->Ref();
 1365|      0|      force = false;  // Do not force another compaction if have room
 1366|      0|      MaybeScheduleCompaction();
 1367|      0|    }
 1368|      0|  }
 1369|      0|  return s;
 1370|      0|}
 1371|       |
 1372|      0|bool DBImpl::GetProperty(const Slice& property, std::string* value) {
 1373|      0|  value->clear();
 1374|      0|
 1375|      0|  MutexLock l(&mutex_);
 1376|      0|  Slice in = property;
 1377|      0|  Slice prefix("leveldb.");
 1378|      0|  if (!in.starts_with(prefix)) return false;
 1379|      0|  in.remove_prefix(prefix.size());
 1380|      0|
 1381|      0|  if (in.starts_with("num-files-at-level")) {
 1382|      0|    in.remove_prefix(strlen("num-files-at-level"));
 1383|      0|    uint64_t level;
 1384|      0|    bool ok = ConsumeDecimalNumber(&in, &level) && in.empty();
 1385|      0|    if (!ok || level >= config::kNumLevels) {
 1386|      0|      return false;
 1387|      0|    } else {
 1388|      0|      char buf[100];
 1389|      0|      snprintf(buf, sizeof(buf), "%d",
 1390|      0|               versions_->NumLevelFiles(static_cast<int>(level)));
 1391|      0|      *value = buf;
 1392|      0|      return true;
 1393|      0|    }
 1394|      0|  } else if (in == "stats") {
 1395|      0|    char buf[200];
 1396|      0|    snprintf(buf, sizeof(buf),
 1397|      0|             "                               Compactions\n"
 1398|      0|             "Level  Files Size(MB) Time(sec) Read(MB) Write(MB)\n"
 1399|      0|             "--------------------------------------------------\n");
 1400|      0|    value->append(buf);
 1401|      0|    for (int level = 0; level < config::kNumLevels; level++) {
 1402|      0|      int files = versions_->NumLevelFiles(level);
 1403|      0|      if (stats_[level].micros > 0 || files > 0) {
 1404|      0|        snprintf(buf, sizeof(buf), "%3d %8d %8.0f %9.0f %8.0f %9.0f\n", level,
 1405|      0|                 files, versions_->NumLevelBytes(level) / 1048576.0,
 1406|      0|                 stats_[level].micros / 1e6,
 1407|      0|                 stats_[level].bytes_read / 1048576.0,
 1408|      0|                 stats_[level].bytes_written / 1048576.0);
 1409|      0|        value->append(buf);
 1410|      0|      }
 1411|      0|    }
 1412|      0|    return true;
 1413|      0|  } else if (in == "sstables") {
 1414|      0|    *value = versions_->current()->DebugString();
 1415|      0|    return true;
 1416|      0|  } else if (in == "approximate-memory-usage") {
 1417|      0|    size_t total_usage = options_.block_cache->TotalCharge();
 1418|      0|    if (mem_) {
 1419|      0|      total_usage += mem_->ApproximateMemoryUsage();
 1420|      0|    }
 1421|      0|    if (imm_) {
 1422|      0|      total_usage += imm_->ApproximateMemoryUsage();
 1423|      0|    }
 1424|      0|    char buf[50];
 1425|      0|    snprintf(buf, sizeof(buf), "%llu",
 1426|      0|             static_cast<unsigned long long>(total_usage));
 1427|      0|    value->append(buf);
 1428|      0|    return true;
 1429|      0|  }
 1430|      0|
 1431|      0|  return false;
 1432|      0|}
 1433|       |
 1434|      0|void DBImpl::GetApproximateSizes(const Range* range, int n, uint64_t* sizes) {
 1435|      0|  // TODO(opt): better implementation
 1436|      0|  Version* v;
 1437|      0|  {
 1438|      0|    MutexLock l(&mutex_);
 1439|      0|    versions_->current()->Ref();
 1440|      0|    v = versions_->current();
 1441|      0|  }
 1442|      0|
 1443|      0|  for (int i = 0; i < n; i++) {
 1444|      0|    // Convert user_key into a corresponding internal key.
 1445|      0|    InternalKey k1(range[i].start, kMaxSequenceNumber, kValueTypeForSeek);
 1446|      0|    InternalKey k2(range[i].limit, kMaxSequenceNumber, kValueTypeForSeek);
 1447|      0|    uint64_t start = versions_->ApproximateOffsetOf(v, k1);
 1448|      0|    uint64_t limit = versions_->ApproximateOffsetOf(v, k2);
 1449|      0|    sizes[i] = (limit >= start ? limit - start : 0);
 1450|      0|  }
 1451|      0|
 1452|      0|  {
 1453|      0|    MutexLock l(&mutex_);
 1454|      0|    v->Unref();
 1455|      0|  }
 1456|      0|}
 1457|       |
 1458|       |// Default implementations of convenience methods that subclasses of DB
 1459|       |// can call if they wish
 1460|      0|Status DB::Put(const WriteOptions& opt, const Slice& key, const Slice& value) {
 1461|      0|  WriteBatch batch;
 1462|      0|  batch.Put(key, value);
 1463|      0|  return Write(opt, &batch);
 1464|      0|}
 1465|       |
 1466|      0|Status DB::Delete(const WriteOptions& opt, const Slice& key) {
 1467|      0|  WriteBatch batch;
 1468|      0|  batch.Delete(key);
 1469|      0|  return Write(opt, &batch);
 1470|      0|}
 1471|       |
 1472|      0|DB::~DB() {}
 1473|       |
 1474|      0|Status DB::Open(const Options& options, const std::string& dbname, DB** dbptr) {
 1475|      0|  *dbptr = nullptr;
 1476|      0|
 1477|      0|  DBImpl* impl = new DBImpl(options, dbname);
 1478|      0|  impl->mutex_.Lock();
 1479|      0|  VersionEdit edit;
 1480|      0|  // Recover handles create_if_missing, error_if_exists
 1481|      0|  bool save_manifest = false;
 1482|      0|  Status s = impl->Recover(&edit, &save_manifest);
 1483|      0|  if (s.ok() && impl->mem_ == nullptr) {
 1484|      0|    // Create new log and a corresponding memtable.
 1485|      0|    uint64_t new_log_number = impl->versions_->NewFileNumber();
 1486|      0|    WritableFile* lfile;
 1487|      0|    s = options.env->NewWritableFile(LogFileName(dbname, new_log_number),
 1488|      0|                                     &lfile);
 1489|      0|    if (s.ok()) {
 1490|      0|      edit.SetLogNumber(new_log_number);
 1491|      0|      impl->logfile_ = lfile;
 1492|      0|      impl->logfile_number_ = new_log_number;
 1493|      0|      impl->log_ = new log::Writer(lfile);
 1494|      0|      impl->mem_ = new MemTable(impl->internal_comparator_);
 1495|      0|      impl->mem_->Ref();
 1496|      0|    }
 1497|      0|  }
 1498|      0|  if (s.ok() && save_manifest) {
 1499|      0|    edit.SetPrevLogNumber(0);  // No older logs needed after recovery.
 1500|      0|    edit.SetLogNumber(impl->logfile_number_);
 1501|      0|    s = impl->versions_->LogAndApply(&edit, &impl->mutex_);
 1502|      0|  }
 1503|      0|  if (s.ok()) {
 1504|      0|    impl->DeleteObsoleteFiles();
 1505|      0|    impl->MaybeScheduleCompaction();
 1506|      0|  }
 1507|      0|  impl->mutex_.Unlock();
 1508|      0|  if (s.ok()) {
 1509|      0|    assert(impl->mem_ != nullptr);
 1510|      0|    *dbptr = impl;
 1511|      0|  } else {
 1512|      0|    delete impl;
 1513|      0|  }
 1514|      0|  return s;
 1515|      0|}
 1516|       |
 1517|      0|Snapshot::~Snapshot() {}
 1518|       |
 1519|      0|Status DestroyDB(const std::string& dbname, const Options& options) {
 1520|      0|  Env* env = options.env;
 1521|      0|  std::vector<std::string> filenames;
 1522|      0|  Status result = env->GetChildren(dbname, &filenames);
 1523|      0|  if (!result.ok()) {
 1524|      0|    // Ignore error in case directory does not exist
 1525|      0|    return Status::OK();
 1526|      0|  }
 1527|      0|
 1528|      0|  FileLock* lock;
 1529|      0|  const std::string lockname = LockFileName(dbname);
 1530|      0|  result = env->LockFile(lockname, &lock);
 1531|      0|  if (result.ok()) {
 1532|      0|    uint64_t number;
 1533|      0|    FileType type;
 1534|      0|    for (size_t i = 0; i < filenames.size(); i++) {
 1535|      0|      if (ParseFileName(filenames[i], &number, &type) &&
 1536|      0|          type != kDBLockFile) {  // Lock file will be deleted at end
 1537|      0|        Status del = env->DeleteFile(dbname + "/" + filenames[i]);
 1538|      0|        if (result.ok() && !del.ok()) {
 1539|      0|          result = del;
 1540|      0|        }
 1541|      0|      }
 1542|      0|    }
 1543|      0|    env->UnlockFile(lock);  // Ignore error since state is already gone
 1544|      0|    env->DeleteFile(lockname);
 1545|      0|    env->DeleteDir(dbname);  // Ignore error in case dir contains other files
 1546|      0|  }
 1547|      0|  return result;
 1548|      0|}
 1549|       |
 1550|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/db_impl.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_DB_DB_IMPL_H_
    6|       |#define STORAGE_LEVELDB_DB_DB_IMPL_H_
    7|       |
    8|       |#include <atomic>
    9|       |#include <deque>
   10|       |#include <set>
   11|       |#include <string>
   12|       |
   13|       |#include "db/dbformat.h"
   14|       |#include "db/log_writer.h"
   15|       |#include "db/snapshot.h"
   16|       |#include "leveldb/db.h"
   17|       |#include "leveldb/env.h"
   18|       |#include "port/port.h"
   19|       |#include "port/thread_annotations.h"
   20|       |
   21|       |namespace leveldb {
   22|       |
   23|       |class MemTable;
   24|       |class TableCache;
   25|       |class Version;
   26|       |class VersionEdit;
   27|       |class VersionSet;
   28|       |
   29|       |class DBImpl : public DB {
   30|       | public:
   31|       |  DBImpl(const Options& options, const std::string& dbname);
   32|       |
   33|       |  DBImpl(const DBImpl&) = delete;
   34|       |  DBImpl& operator=(const DBImpl&) = delete;
   35|       |
   36|       |  virtual ~DBImpl();
   37|       |
   38|       |  // Implementations of the DB interface
   39|       |  virtual Status Put(const WriteOptions&, const Slice& key, const Slice& value);
   40|       |  virtual Status Delete(const WriteOptions&, const Slice& key);
   41|       |  virtual Status Write(const WriteOptions& options, WriteBatch* updates);
   42|       |  virtual Status Get(const ReadOptions& options, const Slice& key,
   43|       |                     std::string* value);
   44|       |  virtual Iterator* NewIterator(const ReadOptions&);
   45|       |  virtual const Snapshot* GetSnapshot();
   46|       |  virtual void ReleaseSnapshot(const Snapshot* snapshot);
   47|       |  virtual bool GetProperty(const Slice& property, std::string* value);
   48|       |  virtual void GetApproximateSizes(const Range* range, int n, uint64_t* sizes);
   49|       |  virtual void CompactRange(const Slice* begin, const Slice* end);
   50|       |
   51|       |  // Extra methods (for testing) that are not in the public DB interface
   52|       |
   53|       |  // Compact any files in the named level that overlap [*begin,*end]
   54|       |  void TEST_CompactRange(int level, const Slice* begin, const Slice* end);
   55|       |
   56|       |  // Force current memtable contents to be compacted.
   57|       |  Status TEST_CompactMemTable();
   58|       |
   59|       |  // Return an internal iterator over the current state of the database.
   60|       |  // The keys of this iterator are internal keys (see format.h).
   61|       |  // The returned iterator should be deleted when no longer needed.
   62|       |  Iterator* TEST_NewInternalIterator();
   63|       |
   64|       |  // Return the maximum overlapping data (in bytes) at next level for any
   65|       |  // file at a level >= 1.
   66|       |  int64_t TEST_MaxNextLevelOverlappingBytes();
   67|       |
   68|       |  // Record a sample of bytes read at the specified internal key.
   69|       |  // Samples are taken approximately once every config::kReadBytesPeriod
   70|       |  // bytes.
   71|       |  void RecordReadSample(Slice key);
   72|       |
   73|       | private:
   74|       |  friend class DB;
   75|       |  struct CompactionState;
   76|       |  struct Writer;
   77|       |
   78|       |  // Information for a manual compaction
   79|       |  struct ManualCompaction {
   80|       |    int level;
   81|       |    bool done;
   82|       |    const InternalKey* begin;  // null means beginning of key range
   83|       |    const InternalKey* end;    // null means end of key range
   84|       |    InternalKey tmp_storage;   // Used to keep track of compaction progress
   85|       |  };
   86|       |
   87|       |  // Per level compaction stats.  stats_[level] stores the stats for
   88|       |  // compactions that produced data for the specified "level".
   89|       |  struct CompactionStats {
   90|      0|    CompactionStats() : micros(0), bytes_read(0), bytes_written(0) {}
   91|       |
   92|      0|    void Add(const CompactionStats& c) {
   93|      0|      this->micros += c.micros;
   94|      0|      this->bytes_read += c.bytes_read;
   95|      0|      this->bytes_written += c.bytes_written;
   96|      0|    }
   97|       |
   98|       |    int64_t micros;
   99|       |    int64_t bytes_read;
  100|       |    int64_t bytes_written;
  101|       |  };
  102|       |
  103|       |  Iterator* NewInternalIterator(const ReadOptions&,
  104|       |                                SequenceNumber* latest_snapshot,
  105|       |                                uint32_t* seed);
  106|       |
  107|       |  Status NewDB();
  108|       |
  109|       |  // Recover the descriptor from persistent storage.  May do a significant
  110|       |  // amount of work to recover recently logged updates.  Any changes to
  111|       |  // be made to the descriptor are added to *edit.
  112|       |  Status Recover(VersionEdit* edit, bool* save_manifest)
  113|       |      EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  114|       |
  115|       |  void MaybeIgnoreError(Status* s) const;
  116|       |
  117|       |  // Delete any unneeded files and stale in-memory entries.
  118|       |  void DeleteObsoleteFiles() EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  119|       |
  120|       |  // Compact the in-memory write buffer to disk.  Switches to a new
  121|       |  // log-file/memtable and writes a new descriptor iff successful.
  122|       |  // Errors are recorded in bg_error_.
  123|       |  void CompactMemTable() EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  124|       |
  125|       |  Status RecoverLogFile(uint64_t log_number, bool last_log, bool* save_manifest,
  126|       |                        VersionEdit* edit, SequenceNumber* max_sequence)
  127|       |      EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  128|       |
  129|       |  Status WriteLevel0Table(MemTable* mem, VersionEdit* edit, Version* base)
  130|       |      EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  131|       |
  132|       |  Status MakeRoomForWrite(bool force /* compact even if there is room? */)
  133|       |      EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  134|       |  WriteBatch* BuildBatchGroup(Writer** last_writer)
  135|       |      EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  136|       |
  137|       |  void RecordBackgroundError(const Status& s);
  138|       |
  139|       |  void MaybeScheduleCompaction() EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  140|       |  static void BGWork(void* db);
  141|       |  void BackgroundCall();
  142|       |  void BackgroundCompaction() EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  143|       |  void CleanupCompaction(CompactionState* compact)
  144|       |      EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  145|       |  Status DoCompactionWork(CompactionState* compact)
  146|       |      EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  147|       |
  148|       |  Status OpenCompactionOutputFile(CompactionState* compact);
  149|       |  Status FinishCompactionOutputFile(CompactionState* compact, Iterator* input);
  150|       |  Status InstallCompactionResults(CompactionState* compact)
  151|       |      EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  152|       |
  153|      0|  const Comparator* user_comparator() const {
  154|      0|    return internal_comparator_.user_comparator();
  155|      0|  }
  156|       |
  157|       |  // Constant after construction
  158|       |  Env* const env_;
  159|       |  const InternalKeyComparator internal_comparator_;
  160|       |  const InternalFilterPolicy internal_filter_policy_;
  161|       |  const Options options_;  // options_.comparator == &internal_comparator_
  162|       |  const bool owns_info_log_;
  163|       |  const bool owns_cache_;
  164|       |  const std::string dbname_;
  165|       |
  166|       |  // table_cache_ provides its own synchronization
  167|       |  TableCache* const table_cache_;
  168|       |
  169|       |  // Lock over the persistent DB state.  Non-null iff successfully acquired.
  170|       |  FileLock* db_lock_;
  171|       |
  172|       |  // State below is protected by mutex_
  173|       |  port::Mutex mutex_;
  174|       |  std::atomic<bool> shutting_down_;
  175|       |  port::CondVar background_work_finished_signal_ GUARDED_BY(mutex_);
  176|       |  MemTable* mem_;
  177|       |  MemTable* imm_ GUARDED_BY(mutex_);  // Memtable being compacted
  178|       |  std::atomic<bool> has_imm_;         // So bg thread can detect non-null imm_
  179|       |  WritableFile* logfile_;
  180|       |  uint64_t logfile_number_ GUARDED_BY(mutex_);
  181|       |  log::Writer* log_;
  182|       |  uint32_t seed_ GUARDED_BY(mutex_);  // For sampling.
  183|       |
  184|       |  // Queue of writers.
  185|       |  std::deque<Writer*> writers_ GUARDED_BY(mutex_);
  186|       |  WriteBatch* tmp_batch_ GUARDED_BY(mutex_);
  187|       |
  188|       |  SnapshotList snapshots_ GUARDED_BY(mutex_);
  189|       |
  190|       |  // Set of table files to protect from deletion because they are
  191|       |  // part of ongoing compactions.
  192|       |  std::set<uint64_t> pending_outputs_ GUARDED_BY(mutex_);
  193|       |
  194|       |  // Has a background compaction been scheduled or is running?
  195|       |  bool background_compaction_scheduled_ GUARDED_BY(mutex_);
  196|       |
  197|       |  ManualCompaction* manual_compaction_ GUARDED_BY(mutex_);
  198|       |
  199|       |  VersionSet* const versions_;
  200|       |
  201|       |  // Have we encountered a background error in paranoid mode?
  202|       |  Status bg_error_ GUARDED_BY(mutex_);
  203|       |
  204|       |  CompactionStats stats_[config::kNumLevels] GUARDED_BY(mutex_);
  205|       |};
  206|       |
  207|       |// Sanitize db options.  The caller should delete result.info_log if
  208|       |// it is not equal to src.info_log.
  209|       |Options SanitizeOptions(const std::string& db,
  210|       |                        const InternalKeyComparator* icmp,
  211|       |                        const InternalFilterPolicy* ipolicy,
  212|       |                        const Options& src);
  213|       |
  214|       |}  // namespace leveldb
  215|       |
  216|       |#endif  // STORAGE_LEVELDB_DB_DB_IMPL_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/db_iter.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/db_iter.h"
    6|       |
    7|       |#include "db/db_impl.h"
    8|       |#include "db/dbformat.h"
    9|       |#include "db/filename.h"
   10|       |#include "leveldb/env.h"
   11|       |#include "leveldb/iterator.h"
   12|       |#include "port/port.h"
   13|       |#include "util/logging.h"
   14|       |#include "util/mutexlock.h"
   15|       |#include "util/random.h"
   16|       |
   17|       |namespace leveldb {
   18|       |
   19|       |#if 0
   20|       |static void DumpInternalIter(Iterator* iter) {
   21|       |  for (iter->SeekToFirst(); iter->Valid(); iter->Next()) {
   22|       |    ParsedInternalKey k;
   23|       |    if (!ParseInternalKey(iter->key(), &k)) {
   24|       |      fprintf(stderr, "Corrupt '%s'\n", EscapeString(iter->key()).c_str());
   25|       |    } else {
   26|       |      fprintf(stderr, "@ '%s'\n", k.DebugString().c_str());
   27|       |    }
   28|       |  }
   29|       |}
   30|       |#endif
   31|       |
   32|       |namespace {
   33|       |
   34|       |// Memtables and sstables that make the DB representation contain
   35|       |// (userkey,seq,type) => uservalue entries.  DBIter
   36|       |// combines multiple entries for the same userkey found in the DB
   37|       |// representation into a single entry while accounting for sequence
   38|       |// numbers, deletion markers, overwrites, etc.
   39|       |class DBIter : public Iterator {
   40|       | public:
   41|       |  // Which direction is the iterator currently moving?
   42|       |  // (1) When moving forward, the internal iterator is positioned at
   43|       |  //     the exact entry that yields this->key(), this->value()
   44|       |  // (2) When moving backwards, the internal iterator is positioned
   45|       |  //     just before all entries whose user key == this->key().
   46|       |  enum Direction { kForward, kReverse };
   47|       |
   48|       |  DBIter(DBImpl* db, const Comparator* cmp, Iterator* iter, SequenceNumber s,
   49|       |         uint32_t seed)
   50|       |      : db_(db),
   51|       |        user_comparator_(cmp),
   52|       |        iter_(iter),
   53|       |        sequence_(s),
   54|       |        direction_(kForward),
   55|       |        valid_(false),
   56|       |        rnd_(seed),
   57|      0|        bytes_until_read_sampling_(RandomCompactionPeriod()) {}
   58|       |
   59|       |  DBIter(const DBIter&) = delete;
   60|       |  DBIter& operator=(const DBIter&) = delete;
   61|       |
   62|      0|  virtual ~DBIter() { delete iter_; }
   63|      0|  virtual bool Valid() const { return valid_; }
   64|      0|  virtual Slice key() const {
   65|      0|    assert(valid_);
   66|      0|    return (direction_ == kForward) ? ExtractUserKey(iter_->key()) : saved_key_;
   67|      0|  }
   68|      0|  virtual Slice value() const {
   69|      0|    assert(valid_);
   70|      0|    return (direction_ == kForward) ? iter_->value() : saved_value_;
   71|      0|  }
   72|      0|  virtual Status status() const {
   73|      0|    if (status_.ok()) {
   74|      0|      return iter_->status();
   75|      0|    } else {
   76|      0|      return status_;
   77|      0|    }
   78|      0|  }
   79|       |
   80|       |  virtual void Next();
   81|       |  virtual void Prev();
   82|       |  virtual void Seek(const Slice& target);
   83|       |  virtual void SeekToFirst();
   84|       |  virtual void SeekToLast();
   85|       |
   86|       | private:
   87|       |  void FindNextUserEntry(bool skipping, std::string* skip);
   88|       |  void FindPrevUserEntry();
   89|       |  bool ParseKey(ParsedInternalKey* key);
   90|       |
   91|      0|  inline void SaveKey(const Slice& k, std::string* dst) {
   92|      0|    dst->assign(k.data(), k.size());
   93|      0|  }
   94|       |
   95|      0|  inline void ClearSavedValue() {
   96|      0|    if (saved_value_.capacity() > 1048576) {
   97|      0|      std::string empty;
   98|      0|      swap(empty, saved_value_);
   99|      0|    } else {
  100|      0|      saved_value_.clear();
  101|      0|    }
  102|      0|  }
  103|       |
  104|       |  // Picks the number of bytes that can be read until a compaction is scheduled.
  105|      0|  size_t RandomCompactionPeriod() {
  106|      0|    return rnd_.Uniform(2 * config::kReadBytesPeriod);
  107|      0|  }
  108|       |
  109|       |  DBImpl* db_;
  110|       |  const Comparator* const user_comparator_;
  111|       |  Iterator* const iter_;
  112|       |  SequenceNumber const sequence_;
  113|       |  Status status_;
  114|       |  std::string saved_key_;    // == current key when direction_==kReverse
  115|       |  std::string saved_value_;  // == current raw value when direction_==kReverse
  116|       |  Direction direction_;
  117|       |  bool valid_;
  118|       |  Random rnd_;
  119|       |  size_t bytes_until_read_sampling_;
  120|       |};
  121|       |
  122|      0|inline bool DBIter::ParseKey(ParsedInternalKey* ikey) {
  123|      0|  Slice k = iter_->key();
  124|      0|
  125|      0|  size_t bytes_read = k.size() + iter_->value().size();
  126|      0|  while (bytes_until_read_sampling_ < bytes_read) {
  127|      0|    bytes_until_read_sampling_ += RandomCompactionPeriod();
  128|      0|    db_->RecordReadSample(k);
  129|      0|  }
  130|      0|  assert(bytes_until_read_sampling_ >= bytes_read);
  131|      0|  bytes_until_read_sampling_ -= bytes_read;
  132|      0|
  133|      0|  if (!ParseInternalKey(k, ikey)) {
  134|      0|    status_ = Status::Corruption("corrupted internal key in DBIter");
  135|      0|    return false;
  136|      0|  } else {
  137|      0|    return true;
  138|      0|  }
  139|      0|}
  140|       |
  141|      0|void DBIter::Next() {
  142|      0|  assert(valid_);
  143|      0|
  144|      0|  if (direction_ == kReverse) {  // Switch directions?
  145|      0|    direction_ = kForward;
  146|      0|    // iter_ is pointing just before the entries for this->key(),
  147|      0|    // so advance into the range of entries for this->key() and then
  148|      0|    // use the normal skipping code below.
  149|      0|    if (!iter_->Valid()) {
  150|      0|      iter_->SeekToFirst();
  151|      0|    } else {
  152|      0|      iter_->Next();
  153|      0|    }
  154|      0|    if (!iter_->Valid()) {
  155|      0|      valid_ = false;
  156|      0|      saved_key_.clear();
  157|      0|      return;
  158|      0|    }
  159|      0|    // saved_key_ already contains the key to skip past.
  160|      0|  } else {
  161|      0|    // Store in saved_key_ the current key so we skip it below.
  162|      0|    SaveKey(ExtractUserKey(iter_->key()), &saved_key_);
  163|      0|  }
  164|      0|
  165|      0|  FindNextUserEntry(true, &saved_key_);
  166|      0|}
  167|       |
  168|      0|void DBIter::FindNextUserEntry(bool skipping, std::string* skip) {
  169|      0|  // Loop until we hit an acceptable entry to yield
  170|      0|  assert(iter_->Valid());
  171|      0|  assert(direction_ == kForward);
  172|      0|  do {
  173|      0|    ParsedInternalKey ikey;
  174|      0|    if (ParseKey(&ikey) && ikey.sequence <= sequence_) {
  175|      0|      switch (ikey.type) {
  176|      0|        case kTypeDeletion:
  177|      0|          // Arrange to skip all upcoming entries for this key since
  178|      0|          // they are hidden by this deletion.
  179|      0|          SaveKey(ikey.user_key, skip);
  180|      0|          skipping = true;
  181|      0|          break;
  182|      0|        case kTypeValue:
  183|      0|          if (skipping &&
  184|      0|              user_comparator_->Compare(ikey.user_key, *skip) <= 0) {
  185|      0|            // Entry hidden
  186|      0|          } else {
  187|      0|            valid_ = true;
  188|      0|            saved_key_.clear();
  189|      0|            return;
  190|      0|          }
  191|      0|          break;
  192|      0|      }
  193|      0|    }
  194|      0|    iter_->Next();
  195|      0|  } while (iter_->Valid());
  196|      0|  saved_key_.clear();
  197|      0|  valid_ = false;
  198|      0|}
  199|       |
  200|      0|void DBIter::Prev() {
  201|      0|  assert(valid_);
  202|      0|
  203|      0|  if (direction_ == kForward) {  // Switch directions?
  204|      0|    // iter_ is pointing at the current entry.  Scan backwards until
  205|      0|    // the key changes so we can use the normal reverse scanning code.
  206|      0|    assert(iter_->Valid());  // Otherwise valid_ would have been false
  207|      0|    SaveKey(ExtractUserKey(iter_->key()), &saved_key_);
  208|      0|    while (true) {
  209|      0|      iter_->Prev();
  210|      0|      if (!iter_->Valid()) {
  211|      0|        valid_ = false;
  212|      0|        saved_key_.clear();
  213|      0|        ClearSavedValue();
  214|      0|        return;
  215|      0|      }
  216|      0|      if (user_comparator_->Compare(ExtractUserKey(iter_->key()), saved_key_) <
  217|      0|          0) {
  218|      0|        break;
  219|      0|      }
  220|      0|    }
  221|      0|    direction_ = kReverse;
  222|      0|  }
  223|      0|
  224|      0|  FindPrevUserEntry();
  225|      0|}
  226|       |
  227|      0|void DBIter::FindPrevUserEntry() {
  228|      0|  assert(direction_ == kReverse);
  229|      0|
  230|      0|  ValueType value_type = kTypeDeletion;
  231|      0|  if (iter_->Valid()) {
  232|      0|    do {
  233|      0|      ParsedInternalKey ikey;
  234|      0|      if (ParseKey(&ikey) && ikey.sequence <= sequence_) {
  235|      0|        if ((value_type != kTypeDeletion) &&
  236|      0|            user_comparator_->Compare(ikey.user_key, saved_key_) < 0) {
  237|      0|          // We encountered a non-deleted value in entries for previous keys,
  238|      0|          break;
  239|      0|        }
  240|      0|        value_type = ikey.type;
  241|      0|        if (value_type == kTypeDeletion) {
  242|      0|          saved_key_.clear();
  243|      0|          ClearSavedValue();
  244|      0|        } else {
  245|      0|          Slice raw_value = iter_->value();
  246|      0|          if (saved_value_.capacity() > raw_value.size() + 1048576) {
  247|      0|            std::string empty;
  248|      0|            swap(empty, saved_value_);
  249|      0|          }
  250|      0|          SaveKey(ExtractUserKey(iter_->key()), &saved_key_);
  251|      0|          saved_value_.assign(raw_value.data(), raw_value.size());
  252|      0|        }
  253|      0|      }
  254|      0|      iter_->Prev();
  255|      0|    } while (iter_->Valid());
  256|      0|  }
  257|      0|
  258|      0|  if (value_type == kTypeDeletion) {
  259|      0|    // End
  260|      0|    valid_ = false;
  261|      0|    saved_key_.clear();
  262|      0|    ClearSavedValue();
  263|      0|    direction_ = kForward;
  264|      0|  } else {
  265|      0|    valid_ = true;
  266|      0|  }
  267|      0|}
  268|       |
  269|      0|void DBIter::Seek(const Slice& target) {
  270|      0|  direction_ = kForward;
  271|      0|  ClearSavedValue();
  272|      0|  saved_key_.clear();
  273|      0|  AppendInternalKey(&saved_key_,
  274|      0|                    ParsedInternalKey(target, sequence_, kValueTypeForSeek));
  275|      0|  iter_->Seek(saved_key_);
  276|      0|  if (iter_->Valid()) {
  277|      0|    FindNextUserEntry(false, &saved_key_ /* temporary storage */);
  278|      0|  } else {
  279|      0|    valid_ = false;
  280|      0|  }
  281|      0|}
  282|       |
  283|      0|void DBIter::SeekToFirst() {
  284|      0|  direction_ = kForward;
  285|      0|  ClearSavedValue();
  286|      0|  iter_->SeekToFirst();
  287|      0|  if (iter_->Valid()) {
  288|      0|    FindNextUserEntry(false, &saved_key_ /* temporary storage */);
  289|      0|  } else {
  290|      0|    valid_ = false;
  291|      0|  }
  292|      0|}
  293|       |
  294|      0|void DBIter::SeekToLast() {
  295|      0|  direction_ = kReverse;
  296|      0|  ClearSavedValue();
  297|      0|  iter_->SeekToLast();
  298|      0|  FindPrevUserEntry();
  299|      0|}
  300|       |
  301|       |}  // anonymous namespace
  302|       |
  303|       |Iterator* NewDBIterator(DBImpl* db, const Comparator* user_key_comparator,
  304|       |                        Iterator* internal_iter, SequenceNumber sequence,
  305|      0|                        uint32_t seed) {
  306|      0|  return new DBIter(db, user_key_comparator, internal_iter, sequence, seed);
  307|      0|}
  308|       |
  309|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/dbformat.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/dbformat.h"
    6|       |
    7|       |#include <stdio.h>
    8|       |
    9|       |#include "port/port.h"
   10|       |#include "util/coding.h"
   11|       |
   12|       |namespace leveldb {
   13|       |
   14|      0|static uint64_t PackSequenceAndType(uint64_t seq, ValueType t) {
   15|      0|  assert(seq <= kMaxSequenceNumber);
   16|      0|  assert(t <= kValueTypeForSeek);
   17|      0|  return (seq << 8) | t;
   18|      0|}
   19|       |
   20|      0|void AppendInternalKey(std::string* result, const ParsedInternalKey& key) {
   21|      0|  result->append(key.user_key.data(), key.user_key.size());
   22|      0|  PutFixed64(result, PackSequenceAndType(key.sequence, key.type));
   23|      0|}
   24|       |
   25|      0|std::string ParsedInternalKey::DebugString() const {
   26|      0|  char buf[50];
   27|      0|  snprintf(buf, sizeof(buf), "' @ %llu : %d", (unsigned long long)sequence,
   28|      0|           int(type));
   29|      0|  std::string result = "'";
   30|      0|  result += EscapeString(user_key.ToString());
   31|      0|  result += buf;
   32|      0|  return result;
   33|      0|}
   34|       |
   35|      0|std::string InternalKey::DebugString() const {
   36|      0|  std::string result;
   37|      0|  ParsedInternalKey parsed;
   38|      0|  if (ParseInternalKey(rep_, &parsed)) {
   39|      0|    result = parsed.DebugString();
   40|      0|  } else {
   41|      0|    result = "(bad)";
   42|      0|    result.append(EscapeString(rep_));
   43|      0|  }
   44|      0|  return result;
   45|      0|}
   46|       |
   47|      0|const char* InternalKeyComparator::Name() const {
   48|      0|  return "leveldb.InternalKeyComparator";
   49|      0|}
   50|       |
   51|      0|int InternalKeyComparator::Compare(const Slice& akey, const Slice& bkey) const {
   52|      0|  // Order by:
   53|      0|  //    increasing user key (according to user-supplied comparator)
   54|      0|  //    decreasing sequence number
   55|      0|  //    decreasing type (though sequence# should be enough to disambiguate)
   56|      0|  int r = user_comparator_->Compare(ExtractUserKey(akey), ExtractUserKey(bkey));
   57|      0|  if (r == 0) {
   58|      0|    const uint64_t anum = DecodeFixed64(akey.data() + akey.size() - 8);
   59|      0|    const uint64_t bnum = DecodeFixed64(bkey.data() + bkey.size() - 8);
   60|      0|    if (anum > bnum) {
   61|      0|      r = -1;
   62|      0|    } else if (anum < bnum) {
   63|      0|      r = +1;
   64|      0|    }
   65|      0|  }
   66|      0|  return r;
   67|      0|}
   68|       |
   69|       |void InternalKeyComparator::FindShortestSeparator(std::string* start,
   70|      0|                                                  const Slice& limit) const {
   71|      0|  // Attempt to shorten the user portion of the key
   72|      0|  Slice user_start = ExtractUserKey(*start);
   73|      0|  Slice user_limit = ExtractUserKey(limit);
   74|      0|  std::string tmp(user_start.data(), user_start.size());
   75|      0|  user_comparator_->FindShortestSeparator(&tmp, user_limit);
   76|      0|  if (tmp.size() < user_start.size() &&
   77|      0|      user_comparator_->Compare(user_start, tmp) < 0) {
   78|      0|    // User key has become shorter physically, but larger logically.
   79|      0|    // Tack on the earliest possible number to the shortened user key.
   80|      0|    PutFixed64(&tmp,
   81|      0|               PackSequenceAndType(kMaxSequenceNumber, kValueTypeForSeek));
   82|      0|    assert(this->Compare(*start, tmp) < 0);
   83|      0|    assert(this->Compare(tmp, limit) < 0);
   84|      0|    start->swap(tmp);
   85|      0|  }
   86|      0|}
   87|       |
   88|      0|void InternalKeyComparator::FindShortSuccessor(std::string* key) const {
   89|      0|  Slice user_key = ExtractUserKey(*key);
   90|      0|  std::string tmp(user_key.data(), user_key.size());
   91|      0|  user_comparator_->FindShortSuccessor(&tmp);
   92|      0|  if (tmp.size() < user_key.size() &&
   93|      0|      user_comparator_->Compare(user_key, tmp) < 0) {
   94|      0|    // User key has become shorter physically, but larger logically.
   95|      0|    // Tack on the earliest possible number to the shortened user key.
   96|      0|    PutFixed64(&tmp,
   97|      0|               PackSequenceAndType(kMaxSequenceNumber, kValueTypeForSeek));
   98|      0|    assert(this->Compare(*key, tmp) < 0);
   99|      0|    key->swap(tmp);
  100|      0|  }
  101|      0|}
  102|       |
  103|      0|const char* InternalFilterPolicy::Name() const { return user_policy_->Name(); }
  104|       |
  105|       |void InternalFilterPolicy::CreateFilter(const Slice* keys, int n,
  106|      0|                                        std::string* dst) const {
  107|      0|  // We rely on the fact that the code in table.cc does not mind us
  108|      0|  // adjusting keys[].
  109|      0|  Slice* mkey = const_cast<Slice*>(keys);
  110|      0|  for (int i = 0; i < n; i++) {
  111|      0|    mkey[i] = ExtractUserKey(keys[i]);
  112|      0|    // TODO(sanjay): Suppress dups?
  113|      0|  }
  114|      0|  user_policy_->CreateFilter(keys, n, dst);
  115|      0|}
  116|       |
  117|      0|bool InternalFilterPolicy::KeyMayMatch(const Slice& key, const Slice& f) const {
  118|      0|  return user_policy_->KeyMayMatch(ExtractUserKey(key), f);
  119|      0|}
  120|       |
  121|      0|LookupKey::LookupKey(const Slice& user_key, SequenceNumber s) {
  122|      0|  size_t usize = user_key.size();
  123|      0|  size_t needed = usize + 13;  // A conservative estimate
  124|      0|  char* dst;
  125|      0|  if (needed <= sizeof(space_)) {
  126|      0|    dst = space_;
  127|      0|  } else {
  128|      0|    dst = new char[needed];
  129|      0|  }
  130|      0|  start_ = dst;
  131|      0|  dst = EncodeVarint32(dst, usize + 8);
  132|      0|  kstart_ = dst;
  133|      0|  memcpy(dst, user_key.data(), usize);
  134|      0|  dst += usize;
  135|      0|  EncodeFixed64(dst, PackSequenceAndType(s, kValueTypeForSeek));
  136|      0|  dst += 8;
  137|      0|  end_ = dst;
  138|      0|}
  139|       |
  140|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/dbformat.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_DB_DBFORMAT_H_
    6|       |#define STORAGE_LEVELDB_DB_DBFORMAT_H_
    7|       |
    8|       |#include <stdio.h>
    9|       |
   10|       |#include "leveldb/comparator.h"
   11|       |#include "leveldb/db.h"
   12|       |#include "leveldb/filter_policy.h"
   13|       |#include "leveldb/slice.h"
   14|       |#include "leveldb/table_builder.h"
   15|       |#include "util/coding.h"
   16|       |#include "util/logging.h"
   17|       |
   18|       |namespace leveldb {
   19|       |
   20|       |// Grouping of constants.  We may want to make some of these
   21|       |// parameters set via options.
   22|       |namespace config {
   23|       |static const int kNumLevels = 7;
   24|       |
   25|       |// Level-0 compaction is started when we hit this many files.
   26|       |static const int kL0_CompactionTrigger = 4;
   27|       |
   28|       |// Soft limit on number of level-0 files.  We slow down writes at this point.
   29|       |static const int kL0_SlowdownWritesTrigger = 8;
   30|       |
   31|       |// Maximum number of level-0 files.  We stop writes at this point.
   32|       |static const int kL0_StopWritesTrigger = 12;
   33|       |
   34|       |// Maximum level to which a new compacted memtable is pushed if it
   35|       |// does not create overlap.  We try to push to level 2 to avoid the
   36|       |// relatively expensive level 0=>1 compactions and to avoid some
   37|       |// expensive manifest file operations.  We do not push all the way to
   38|       |// the largest level since that can generate a lot of wasted disk
   39|       |// space if the same key space is being repeatedly overwritten.
   40|       |static const int kMaxMemCompactLevel = 2;
   41|       |
   42|       |// Approximate gap in bytes between samples of data read during iteration.
   43|       |static const int kReadBytesPeriod = 1048576;
   44|       |
   45|       |}  // namespace config
   46|       |
   47|       |class InternalKey;
   48|       |
   49|       |// Value types encoded as the last component of internal keys.
   50|       |// DO NOT CHANGE THESE ENUM VALUES: they are embedded in the on-disk
   51|       |// data structures.
   52|       |enum ValueType { kTypeDeletion = 0x0, kTypeValue = 0x1 };
   53|       |// kValueTypeForSeek defines the ValueType that should be passed when
   54|       |// constructing a ParsedInternalKey object for seeking to a particular
   55|       |// sequence number (since we sort sequence numbers in decreasing order
   56|       |// and the value type is embedded as the low 8 bits in the sequence
   57|       |// number in internal keys, we need to use the highest-numbered
   58|       |// ValueType, not the lowest).
   59|       |static const ValueType kValueTypeForSeek = kTypeValue;
   60|       |
   61|       |typedef uint64_t SequenceNumber;
   62|       |
   63|       |// We leave eight bits empty at the bottom so a type and sequence#
   64|       |// can be packed together into 64-bits.
   65|       |static const SequenceNumber kMaxSequenceNumber = ((0x1ull << 56) - 1);
   66|       |
   67|       |struct ParsedInternalKey {
   68|       |  Slice user_key;
   69|       |  SequenceNumber sequence;
   70|       |  ValueType type;
   71|       |
   72|      0|  ParsedInternalKey() {}  // Intentionally left uninitialized (for speed)
   73|       |  ParsedInternalKey(const Slice& u, const SequenceNumber& seq, ValueType t)
   74|      0|      : user_key(u), sequence(seq), type(t) {}
   75|       |  std::string DebugString() const;
   76|       |};
   77|       |
   78|       |// Return the length of the encoding of "key".
   79|      0|inline size_t InternalKeyEncodingLength(const ParsedInternalKey& key) {
   80|      0|  return key.user_key.size() + 8;
   81|      0|}
   82|       |
   83|       |// Append the serialization of "key" to *result.
   84|       |void AppendInternalKey(std::string* result, const ParsedInternalKey& key);
   85|       |
   86|       |// Attempt to parse an internal key from "internal_key".  On success,
   87|       |// stores the parsed data in "*result", and returns true.
   88|       |//
   89|       |// On error, returns false, leaves "*result" in an undefined state.
   90|       |bool ParseInternalKey(const Slice& internal_key, ParsedInternalKey* result);
   91|       |
   92|       |// Returns the user key portion of an internal key.
   93|      0|inline Slice ExtractUserKey(const Slice& internal_key) {
   94|      0|  assert(internal_key.size() >= 8);
   95|      0|  return Slice(internal_key.data(), internal_key.size() - 8);
   96|      0|}
   97|       |
   98|       |// A comparator for internal keys that uses a specified comparator for
   99|       |// the user key portion and breaks ties by decreasing sequence number.
  100|       |class InternalKeyComparator : public Comparator {
  101|       | private:
  102|       |  const Comparator* user_comparator_;
  103|       |
  104|       | public:
  105|      0|  explicit InternalKeyComparator(const Comparator* c) : user_comparator_(c) {}
  106|       |  virtual const char* Name() const;
  107|       |  virtual int Compare(const Slice& a, const Slice& b) const;
  108|       |  virtual void FindShortestSeparator(std::string* start,
  109|       |                                     const Slice& limit) const;
  110|       |  virtual void FindShortSuccessor(std::string* key) const;
  111|       |
  112|      0|  const Comparator* user_comparator() const { return user_comparator_; }
  113|       |
  114|       |  int Compare(const InternalKey& a, const InternalKey& b) const;
  115|       |};
  116|       |
  117|       |// Filter policy wrapper that converts from internal keys to user keys
  118|       |class InternalFilterPolicy : public FilterPolicy {
  119|       | private:
  120|       |  const FilterPolicy* const user_policy_;
  121|       |
  122|       | public:
  123|      0|  explicit InternalFilterPolicy(const FilterPolicy* p) : user_policy_(p) {}
  124|       |  virtual const char* Name() const;
  125|       |  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const;
  126|       |  virtual bool KeyMayMatch(const Slice& key, const Slice& filter) const;
  127|       |};
  128|       |
  129|       |// Modules in this directory should keep internal keys wrapped inside
  130|       |// the following class instead of plain strings so that we do not
  131|       |// incorrectly use string comparisons instead of an InternalKeyComparator.
  132|       |class InternalKey {
  133|       | private:
  134|       |  std::string rep_;
  135|       |
  136|       | public:
  137|      0|  InternalKey() {}  // Leave rep_ as empty to indicate it is invalid
  138|      0|  InternalKey(const Slice& user_key, SequenceNumber s, ValueType t) {
  139|      0|    AppendInternalKey(&rep_, ParsedInternalKey(user_key, s, t));
  140|      0|  }
  141|       |
  142|      0|  void DecodeFrom(const Slice& s) { rep_.assign(s.data(), s.size()); }
  143|      0|  Slice Encode() const {
  144|      0|    assert(!rep_.empty());
  145|      0|    return rep_;
  146|      0|  }
  147|       |
  148|      0|  Slice user_key() const { return ExtractUserKey(rep_); }
  149|       |
  150|      0|  void SetFrom(const ParsedInternalKey& p) {
  151|      0|    rep_.clear();
  152|      0|    AppendInternalKey(&rep_, p);
  153|      0|  }
  154|       |
  155|      0|  void Clear() { rep_.clear(); }
  156|       |
  157|       |  std::string DebugString() const;
  158|       |};
  159|       |
  160|       |inline int InternalKeyComparator::Compare(const InternalKey& a,
  161|      0|                                          const InternalKey& b) const {
  162|      0|  return Compare(a.Encode(), b.Encode());
  163|      0|}
  164|       |
  165|       |inline bool ParseInternalKey(const Slice& internal_key,
  166|      0|                             ParsedInternalKey* result) {
  167|      0|  const size_t n = internal_key.size();
  168|      0|  if (n < 8) return false;
  169|      0|  uint64_t num = DecodeFixed64(internal_key.data() + n - 8);
  170|      0|  unsigned char c = num & 0xff;
  171|      0|  result->sequence = num >> 8;
  172|      0|  result->type = static_cast<ValueType>(c);
  173|      0|  result->user_key = Slice(internal_key.data(), n - 8);
  174|      0|  return (c <= static_cast<unsigned char>(kTypeValue));
  175|      0|}
  176|       |
  177|       |// A helper class useful for DBImpl::Get()
  178|       |class LookupKey {
  179|       | public:
  180|       |  // Initialize *this for looking up user_key at a snapshot with
  181|       |  // the specified sequence number.
  182|       |  LookupKey(const Slice& user_key, SequenceNumber sequence);
  183|       |
  184|       |  LookupKey(const LookupKey&) = delete;
  185|       |  LookupKey& operator=(const LookupKey&) = delete;
  186|       |
  187|       |  ~LookupKey();
  188|       |
  189|       |  // Return a key suitable for lookup in a MemTable.
  190|      0|  Slice memtable_key() const { return Slice(start_, end_ - start_); }
  191|       |
  192|       |  // Return an internal key (suitable for passing to an internal iterator)
  193|      0|  Slice internal_key() const { return Slice(kstart_, end_ - kstart_); }
  194|       |
  195|       |  // Return the user key
  196|      0|  Slice user_key() const { return Slice(kstart_, end_ - kstart_ - 8); }
  197|       |
  198|       | private:
  199|       |  // We construct a char array of the form:
  200|       |  //    klength  varint32               <-- start_
  201|       |  //    userkey  char[klength]          <-- kstart_
  202|       |  //    tag      uint64
  203|       |  //                                    <-- end_
  204|       |  // The array is a suitable MemTable key.
  205|       |  // The suffix starting with "userkey" can be used as an InternalKey.
  206|       |  const char* start_;
  207|       |  const char* kstart_;
  208|       |  const char* end_;
  209|       |  char space_[200];  // Avoid allocation for short keys
  210|       |};
  211|       |
  212|      0|inline LookupKey::~LookupKey() {
  213|      0|  if (start_ != space_) delete[] start_;
  214|      0|}
  215|       |
  216|       |}  // namespace leveldb
  217|       |
  218|       |#endif  // STORAGE_LEVELDB_DB_DBFORMAT_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/dumpfile.cc:
    1|       |// Copyright (c) 2012 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "leveldb/dumpfile.h"
    6|       |
    7|       |#include <stdio.h>
    8|       |
    9|       |#include "db/dbformat.h"
   10|       |#include "db/filename.h"
   11|       |#include "db/log_reader.h"
   12|       |#include "db/version_edit.h"
   13|       |#include "db/write_batch_internal.h"
   14|       |#include "leveldb/env.h"
   15|       |#include "leveldb/iterator.h"
   16|       |#include "leveldb/options.h"
   17|       |#include "leveldb/status.h"
   18|       |#include "leveldb/table.h"
   19|       |#include "leveldb/write_batch.h"
   20|       |#include "util/logging.h"
   21|       |
   22|       |namespace leveldb {
   23|       |
   24|       |namespace {
   25|       |
   26|      0|bool GuessType(const std::string& fname, FileType* type) {
   27|      0|  size_t pos = fname.rfind('/');
   28|      0|  std::string basename;
   29|      0|  if (pos == std::string::npos) {
   30|      0|    basename = fname;
   31|      0|  } else {
   32|      0|    basename = std::string(fname.data() + pos + 1, fname.size() - pos - 1);
   33|      0|  }
   34|      0|  uint64_t ignored;
   35|      0|  return ParseFileName(basename, &ignored, type);
   36|      0|}
   37|       |
   38|       |// Notified when log reader encounters corruption.
   39|       |class CorruptionReporter : public log::Reader::Reporter {
   40|       | public:
   41|      0|  virtual void Corruption(size_t bytes, const Status& status) {
   42|      0|    std::string r = "corruption: ";
   43|      0|    AppendNumberTo(&r, bytes);
   44|      0|    r += " bytes; ";
   45|      0|    r += status.ToString();
   46|      0|    r.push_back('\n');
   47|      0|    dst_->Append(r);
   48|      0|  }
   49|       |
   50|       |  WritableFile* dst_;
   51|       |};
   52|       |
   53|       |// Print contents of a log file. (*func)() is called on every record.
   54|       |Status PrintLogContents(Env* env, const std::string& fname,
   55|       |                        void (*func)(uint64_t, Slice, WritableFile*),
   56|      0|                        WritableFile* dst) {
   57|      0|  SequentialFile* file;
   58|      0|  Status s = env->NewSequentialFile(fname, &file);
   59|      0|  if (!s.ok()) {
   60|      0|    return s;
   61|      0|  }
   62|      0|  CorruptionReporter reporter;
   63|      0|  reporter.dst_ = dst;
   64|      0|  log::Reader reader(file, &reporter, true, 0);
   65|      0|  Slice record;
   66|      0|  std::string scratch;
   67|      0|  while (reader.ReadRecord(&record, &scratch)) {
   68|      0|    (*func)(reader.LastRecordOffset(), record, dst);
   69|      0|  }
   70|      0|  delete file;
   71|      0|  return Status::OK();
   72|      0|}
   73|       |
   74|       |// Called on every item found in a WriteBatch.
   75|       |class WriteBatchItemPrinter : public WriteBatch::Handler {
   76|       | public:
   77|      0|  virtual void Put(const Slice& key, const Slice& value) {
   78|      0|    std::string r = "  put '";
   79|      0|    AppendEscapedStringTo(&r, key);
   80|      0|    r += "' '";
   81|      0|    AppendEscapedStringTo(&r, value);
   82|      0|    r += "'\n";
   83|      0|    dst_->Append(r);
   84|      0|  }
   85|      0|  virtual void Delete(const Slice& key) {
   86|      0|    std::string r = "  del '";
   87|      0|    AppendEscapedStringTo(&r, key);
   88|      0|    r += "'\n";
   89|      0|    dst_->Append(r);
   90|      0|  }
   91|       |
   92|       |  WritableFile* dst_;
   93|       |};
   94|       |
   95|       |// Called on every log record (each one of which is a WriteBatch)
   96|       |// found in a kLogFile.
   97|      0|static void WriteBatchPrinter(uint64_t pos, Slice record, WritableFile* dst) {
   98|      0|  std::string r = "--- offset ";
   99|      0|  AppendNumberTo(&r, pos);
  100|      0|  r += "; ";
  101|      0|  if (record.size() < 12) {
  102|      0|    r += "log record length ";
  103|      0|    AppendNumberTo(&r, record.size());
  104|      0|    r += " is too small\n";
  105|      0|    dst->Append(r);
  106|      0|    return;
  107|      0|  }
  108|      0|  WriteBatch batch;
  109|      0|  WriteBatchInternal::SetContents(&batch, record);
  110|      0|  r += "sequence ";
  111|      0|  AppendNumberTo(&r, WriteBatchInternal::Sequence(&batch));
  112|      0|  r.push_back('\n');
  113|      0|  dst->Append(r);
  114|      0|  WriteBatchItemPrinter batch_item_printer;
  115|      0|  batch_item_printer.dst_ = dst;
  116|      0|  Status s = batch.Iterate(&batch_item_printer);
  117|      0|  if (!s.ok()) {
  118|      0|    dst->Append("  error: " + s.ToString() + "\n");
  119|      0|  }
  120|      0|}
  121|       |
  122|      0|Status DumpLog(Env* env, const std::string& fname, WritableFile* dst) {
  123|      0|  return PrintLogContents(env, fname, WriteBatchPrinter, dst);
  124|      0|}
  125|       |
  126|       |// Called on every log record (each one of which is a WriteBatch)
  127|       |// found in a kDescriptorFile.
  128|      0|static void VersionEditPrinter(uint64_t pos, Slice record, WritableFile* dst) {
  129|      0|  std::string r = "--- offset ";
  130|      0|  AppendNumberTo(&r, pos);
  131|      0|  r += "; ";
  132|      0|  VersionEdit edit;
  133|      0|  Status s = edit.DecodeFrom(record);
  134|      0|  if (!s.ok()) {
  135|      0|    r += s.ToString();
  136|      0|    r.push_back('\n');
  137|      0|  } else {
  138|      0|    r += edit.DebugString();
  139|      0|  }
  140|      0|  dst->Append(r);
  141|      0|}
  142|       |
  143|      0|Status DumpDescriptor(Env* env, const std::string& fname, WritableFile* dst) {
  144|      0|  return PrintLogContents(env, fname, VersionEditPrinter, dst);
  145|      0|}
  146|       |
  147|      0|Status DumpTable(Env* env, const std::string& fname, WritableFile* dst) {
  148|      0|  uint64_t file_size;
  149|      0|  RandomAccessFile* file = nullptr;
  150|      0|  Table* table = nullptr;
  151|      0|  Status s = env->GetFileSize(fname, &file_size);
  152|      0|  if (s.ok()) {
  153|      0|    s = env->NewRandomAccessFile(fname, &file);
  154|      0|  }
  155|      0|  if (s.ok()) {
  156|      0|    // We use the default comparator, which may or may not match the
  157|      0|    // comparator used in this database. However this should not cause
  158|      0|    // problems since we only use Table operations that do not require
  159|      0|    // any comparisons.  In particular, we do not call Seek or Prev.
  160|      0|    s = Table::Open(Options(), file, file_size, &table);
  161|      0|  }
  162|      0|  if (!s.ok()) {
  163|      0|    delete table;
  164|      0|    delete file;
  165|      0|    return s;
  166|      0|  }
  167|      0|
  168|      0|  ReadOptions ro;
  169|      0|  ro.fill_cache = false;
  170|      0|  Iterator* iter = table->NewIterator(ro);
  171|      0|  std::string r;
  172|      0|  for (iter->SeekToFirst(); iter->Valid(); iter->Next()) {
  173|      0|    r.clear();
  174|      0|    ParsedInternalKey key;
  175|      0|    if (!ParseInternalKey(iter->key(), &key)) {
  176|      0|      r = "badkey '";
  177|      0|      AppendEscapedStringTo(&r, iter->key());
  178|      0|      r += "' => '";
  179|      0|      AppendEscapedStringTo(&r, iter->value());
  180|      0|      r += "'\n";
  181|      0|      dst->Append(r);
  182|      0|    } else {
  183|      0|      r = "'";
  184|      0|      AppendEscapedStringTo(&r, key.user_key);
  185|      0|      r += "' @ ";
  186|      0|      AppendNumberTo(&r, key.sequence);
  187|      0|      r += " : ";
  188|      0|      if (key.type == kTypeDeletion) {
  189|      0|        r += "del";
  190|      0|      } else if (key.type == kTypeValue) {
  191|      0|        r += "val";
  192|      0|      } else {
  193|      0|        AppendNumberTo(&r, key.type);
  194|      0|      }
  195|      0|      r += " => '";
  196|      0|      AppendEscapedStringTo(&r, iter->value());
  197|      0|      r += "'\n";
  198|      0|      dst->Append(r);
  199|      0|    }
  200|      0|  }
  201|      0|  s = iter->status();
  202|      0|  if (!s.ok()) {
  203|      0|    dst->Append("iterator error: " + s.ToString() + "\n");
  204|      0|  }
  205|      0|
  206|      0|  delete iter;
  207|      0|  delete table;
  208|      0|  delete file;
  209|      0|  return Status::OK();
  210|      0|}
  211|       |
  212|       |}  // namespace
  213|       |
  214|      0|Status DumpFile(Env* env, const std::string& fname, WritableFile* dst) {
  215|      0|  FileType ftype;
  216|      0|  if (!GuessType(fname, &ftype)) {
  217|      0|    return Status::InvalidArgument(fname + ": unknown file type");
  218|      0|  }
  219|      0|  switch (ftype) {
  220|      0|    case kLogFile:
  221|      0|      return DumpLog(env, fname, dst);
  222|      0|    case kDescriptorFile:
  223|      0|      return DumpDescriptor(env, fname, dst);
  224|      0|    case kTableFile:
  225|      0|      return DumpTable(env, fname, dst);
  226|      0|    default:
  227|      0|      break;
  228|      0|  }
  229|      0|  return Status::InvalidArgument(fname + ": not a dump-able file type");
  230|      0|}
  231|       |
  232|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/filename.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/filename.h"
    6|       |
    7|       |#include <ctype.h>
    8|       |#include <stdio.h>
    9|       |
   10|       |#include "db/dbformat.h"
   11|       |#include "leveldb/env.h"
   12|       |#include "util/logging.h"
   13|       |
   14|       |namespace leveldb {
   15|       |
   16|       |// A utility routine: write "data" to the named file and Sync() it.
   17|       |Status WriteStringToFileSync(Env* env, const Slice& data,
   18|       |                             const std::string& fname);
   19|       |
   20|       |static std::string MakeFileName(const std::string& dbname, uint64_t number,
   21|      0|                                const char* suffix) {
   22|      0|  char buf[100];
   23|      0|  snprintf(buf, sizeof(buf), "/%06llu.%s",
   24|      0|           static_cast<unsigned long long>(number), suffix);
   25|      0|  return dbname + buf;
   26|      0|}
   27|       |
   28|      0|std::string LogFileName(const std::string& dbname, uint64_t number) {
   29|      0|  assert(number > 0);
   30|      0|  return MakeFileName(dbname, number, "log");
   31|      0|}
   32|       |
   33|      0|std::string TableFileName(const std::string& dbname, uint64_t number) {
   34|      0|  assert(number > 0);
   35|      0|  return MakeFileName(dbname, number, "ldb");
   36|      0|}
   37|       |
   38|      0|std::string SSTTableFileName(const std::string& dbname, uint64_t number) {
   39|      0|  assert(number > 0);
   40|      0|  return MakeFileName(dbname, number, "sst");
   41|      0|}
   42|       |
   43|      0|std::string DescriptorFileName(const std::string& dbname, uint64_t number) {
   44|      0|  assert(number > 0);
   45|      0|  char buf[100];
   46|      0|  snprintf(buf, sizeof(buf), "/MANIFEST-%06llu",
   47|      0|           static_cast<unsigned long long>(number));
   48|      0|  return dbname + buf;
   49|      0|}
   50|       |
   51|      0|std::string CurrentFileName(const std::string& dbname) {
   52|      0|  return dbname + "/CURRENT";
   53|      0|}
   54|       |
   55|      0|std::string LockFileName(const std::string& dbname) { return dbname + "/LOCK"; }
   56|       |
   57|      0|std::string TempFileName(const std::string& dbname, uint64_t number) {
   58|      0|  assert(number > 0);
   59|      0|  return MakeFileName(dbname, number, "dbtmp");
   60|      0|}
   61|       |
   62|      0|std::string InfoLogFileName(const std::string& dbname) {
   63|      0|  return dbname + "/LOG";
   64|      0|}
   65|       |
   66|       |// Return the name of the old info log file for "dbname".
   67|      0|std::string OldInfoLogFileName(const std::string& dbname) {
   68|      0|  return dbname + "/LOG.old";
   69|      0|}
   70|       |
   71|       |// Owned filenames have the form:
   72|       |//    dbname/CURRENT
   73|       |//    dbname/LOCK
   74|       |//    dbname/LOG
   75|       |//    dbname/LOG.old
   76|       |//    dbname/MANIFEST-[0-9]+
   77|       |//    dbname/[0-9]+.(log|sst|ldb)
   78|       |bool ParseFileName(const std::string& filename, uint64_t* number,
   79|      0|                   FileType* type) {
   80|      0|  Slice rest(filename);
   81|      0|  if (rest == "CURRENT") {
   82|      0|    *number = 0;
   83|      0|    *type = kCurrentFile;
   84|      0|  } else if (rest == "LOCK") {
   85|      0|    *number = 0;
   86|      0|    *type = kDBLockFile;
   87|      0|  } else if (rest == "LOG" || rest == "LOG.old") {
   88|      0|    *number = 0;
   89|      0|    *type = kInfoLogFile;
   90|      0|  } else if (rest.starts_with("MANIFEST-")) {
   91|      0|    rest.remove_prefix(strlen("MANIFEST-"));
   92|      0|    uint64_t num;
   93|      0|    if (!ConsumeDecimalNumber(&rest, &num)) {
   94|      0|      return false;
   95|      0|    }
   96|      0|    if (!rest.empty()) {
   97|      0|      return false;
   98|      0|    }
   99|      0|    *type = kDescriptorFile;
  100|      0|    *number = num;
  101|      0|  } else {
  102|      0|    // Avoid strtoull() to keep filename format independent of the
  103|      0|    // current locale
  104|      0|    uint64_t num;
  105|      0|    if (!ConsumeDecimalNumber(&rest, &num)) {
  106|      0|      return false;
  107|      0|    }
  108|      0|    Slice suffix = rest;
  109|      0|    if (suffix == Slice(".log")) {
  110|      0|      *type = kLogFile;
  111|      0|    } else if (suffix == Slice(".sst") || suffix == Slice(".ldb")) {
  112|      0|      *type = kTableFile;
  113|      0|    } else if (suffix == Slice(".dbtmp")) {
  114|      0|      *type = kTempFile;
  115|      0|    } else {
  116|      0|      return false;
  117|      0|    }
  118|      0|    *number = num;
  119|      0|  }
  120|      0|  return true;
  121|      0|}
  122|       |
  123|       |Status SetCurrentFile(Env* env, const std::string& dbname,
  124|      0|                      uint64_t descriptor_number) {
  125|      0|  // Remove leading "dbname/" and add newline to manifest file name
  126|      0|  std::string manifest = DescriptorFileName(dbname, descriptor_number);
  127|      0|  Slice contents = manifest;
  128|      0|  assert(contents.starts_with(dbname + "/"));
  129|      0|  contents.remove_prefix(dbname.size() + 1);
  130|      0|  std::string tmp = TempFileName(dbname, descriptor_number);
  131|      0|  Status s = WriteStringToFileSync(env, contents.ToString() + "\n", tmp);
  132|      0|  if (s.ok()) {
  133|      0|    s = env->RenameFile(tmp, CurrentFileName(dbname));
  134|      0|  }
  135|      0|  if (!s.ok()) {
  136|      0|    env->DeleteFile(tmp);
  137|      0|  }
  138|      0|  return s;
  139|      0|}
  140|       |
  141|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/log_reader.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/log_reader.h"
    6|       |
    7|       |#include <stdio.h>
    8|       |
    9|       |#include "leveldb/env.h"
   10|       |#include "util/coding.h"
   11|       |#include "util/crc32c.h"
   12|       |
   13|       |namespace leveldb {
   14|       |namespace log {
   15|       |
   16|      0|Reader::Reporter::~Reporter() {}
   17|       |
   18|       |Reader::Reader(SequentialFile* file, Reporter* reporter, bool checksum,
   19|       |               uint64_t initial_offset)
   20|       |    : file_(file),
   21|       |      reporter_(reporter),
   22|       |      checksum_(checksum),
   23|       |      backing_store_(new char[kBlockSize]),
   24|       |      buffer_(),
   25|       |      eof_(false),
   26|       |      last_record_offset_(0),
   27|       |      end_of_buffer_offset_(0),
   28|       |      initial_offset_(initial_offset),
   29|      0|      resyncing_(initial_offset > 0) {}
   30|       |
   31|      0|Reader::~Reader() { delete[] backing_store_; }
   32|       |
   33|      0|bool Reader::SkipToInitialBlock() {
   34|      0|  const size_t offset_in_block = initial_offset_ % kBlockSize;
   35|      0|  uint64_t block_start_location = initial_offset_ - offset_in_block;
   36|      0|
   37|      0|  // Don't search a block if we'd be in the trailer
   38|      0|  if (offset_in_block > kBlockSize - 6) {
   39|      0|    block_start_location += kBlockSize;
   40|      0|  }
   41|      0|
   42|      0|  end_of_buffer_offset_ = block_start_location;
   43|      0|
   44|      0|  // Skip to start of first block that can contain the initial record
   45|      0|  if (block_start_location > 0) {
   46|      0|    Status skip_status = file_->Skip(block_start_location);
   47|      0|    if (!skip_status.ok()) {
   48|      0|      ReportDrop(block_start_location, skip_status);
   49|      0|      return false;
   50|      0|    }
   51|      0|  }
   52|      0|
   53|      0|  return true;
   54|      0|}
   55|       |
   56|      0|bool Reader::ReadRecord(Slice* record, std::string* scratch) {
   57|      0|  if (last_record_offset_ < initial_offset_) {
   58|      0|    if (!SkipToInitialBlock()) {
   59|      0|      return false;
   60|      0|    }
   61|      0|  }
   62|      0|
   63|      0|  scratch->clear();
   64|      0|  record->clear();
   65|      0|  bool in_fragmented_record = false;
   66|      0|  // Record offset of the logical record that we're reading
   67|      0|  // 0 is a dummy value to make compilers happy
   68|      0|  uint64_t prospective_record_offset = 0;
   69|      0|
   70|      0|  Slice fragment;
   71|      0|  while (true) {
   72|      0|    const unsigned int record_type = ReadPhysicalRecord(&fragment);
   73|      0|
   74|      0|    // ReadPhysicalRecord may have only had an empty trailer remaining in its
   75|      0|    // internal buffer. Calculate the offset of the next physical record now
   76|      0|    // that it has returned, properly accounting for its header size.
   77|      0|    uint64_t physical_record_offset =
   78|      0|        end_of_buffer_offset_ - buffer_.size() - kHeaderSize - fragment.size();
   79|      0|
   80|      0|    if (resyncing_) {
   81|      0|      if (record_type == kMiddleType) {
   82|      0|        continue;
   83|      0|      } else if (record_type == kLastType) {
   84|      0|        resyncing_ = false;
   85|      0|        continue;
   86|      0|      } else {
   87|      0|        resyncing_ = false;
   88|      0|      }
   89|      0|    }
   90|      0|
   91|      0|    switch (record_type) {
   92|      0|      case kFullType:
   93|      0|        if (in_fragmented_record) {
   94|      0|          // Handle bug in earlier versions of log::Writer where
   95|      0|          // it could emit an empty kFirstType record at the tail end
   96|      0|          // of a block followed by a kFullType or kFirstType record
   97|      0|          // at the beginning of the next block.
   98|      0|          if (!scratch->empty()) {
   99|      0|            ReportCorruption(scratch->size(), "partial record without end(1)");
  100|      0|          }
  101|      0|        }
  102|      0|        prospective_record_offset = physical_record_offset;
  103|      0|        scratch->clear();
  104|      0|        *record = fragment;
  105|      0|        last_record_offset_ = prospective_record_offset;
  106|      0|        return true;
  107|      0|
  108|      0|      case kFirstType:
  109|      0|        if (in_fragmented_record) {
  110|      0|          // Handle bug in earlier versions of log::Writer where
  111|      0|          // it could emit an empty kFirstType record at the tail end
  112|      0|          // of a block followed by a kFullType or kFirstType record
  113|      0|          // at the beginning of the next block.
  114|      0|          if (!scratch->empty()) {
  115|      0|            ReportCorruption(scratch->size(), "partial record without end(2)");
  116|      0|          }
  117|      0|        }
  118|      0|        prospective_record_offset = physical_record_offset;
  119|      0|        scratch->assign(fragment.data(), fragment.size());
  120|      0|        in_fragmented_record = true;
  121|      0|        break;
  122|      0|
  123|      0|      case kMiddleType:
  124|      0|        if (!in_fragmented_record) {
  125|      0|          ReportCorruption(fragment.size(),
  126|      0|                           "missing start of fragmented record(1)");
  127|      0|        } else {
  128|      0|          scratch->append(fragment.data(), fragment.size());
  129|      0|        }
  130|      0|        break;
  131|      0|
  132|      0|      case kLastType:
  133|      0|        if (!in_fragmented_record) {
  134|      0|          ReportCorruption(fragment.size(),
  135|      0|                           "missing start of fragmented record(2)");
  136|      0|        } else {
  137|      0|          scratch->append(fragment.data(), fragment.size());
  138|      0|          *record = Slice(*scratch);
  139|      0|          last_record_offset_ = prospective_record_offset;
  140|      0|          return true;
  141|      0|        }
  142|      0|        break;
  143|      0|
  144|      0|      case kEof:
  145|      0|        if (in_fragmented_record) {
  146|      0|          // This can be caused by the writer dying immediately after
  147|      0|          // writing a physical record but before completing the next; don't
  148|      0|          // treat it as a corruption, just ignore the entire logical record.
  149|      0|          scratch->clear();
  150|      0|        }
  151|      0|        return false;
  152|      0|
  153|      0|      case kBadRecord:
  154|      0|        if (in_fragmented_record) {
  155|      0|          ReportCorruption(scratch->size(), "error in middle of record");
  156|      0|          in_fragmented_record = false;
  157|      0|          scratch->clear();
  158|      0|        }
  159|      0|        break;
  160|      0|
  161|      0|      default: {
  162|      0|        char buf[40];
  163|      0|        snprintf(buf, sizeof(buf), "unknown record type %u", record_type);
  164|      0|        ReportCorruption(
  165|      0|            (fragment.size() + (in_fragmented_record ? scratch->size() : 0)),
  166|      0|            buf);
  167|      0|        in_fragmented_record = false;
  168|      0|        scratch->clear();
  169|      0|        break;
  170|      0|      }
  171|      0|    }
  172|      0|  }
  173|      0|  return false;
  174|      0|}
  175|       |
  176|      0|uint64_t Reader::LastRecordOffset() { return last_record_offset_; }
  177|       |
  178|      0|void Reader::ReportCorruption(uint64_t bytes, const char* reason) {
  179|      0|  ReportDrop(bytes, Status::Corruption(reason));
  180|      0|}
  181|       |
  182|      0|void Reader::ReportDrop(uint64_t bytes, const Status& reason) {
  183|      0|  if (reporter_ != nullptr &&
  184|      0|      end_of_buffer_offset_ - buffer_.size() - bytes >= initial_offset_) {
  185|      0|    reporter_->Corruption(static_cast<size_t>(bytes), reason);
  186|      0|  }
  187|      0|}
  188|       |
  189|      0|unsigned int Reader::ReadPhysicalRecord(Slice* result) {
  190|      0|  while (true) {
  191|      0|    if (buffer_.size() < kHeaderSize) {
  192|      0|      if (!eof_) {
  193|      0|        // Last read was a full read, so this is a trailer to skip
  194|      0|        buffer_.clear();
  195|      0|        Status status = file_->Read(kBlockSize, &buffer_, backing_store_);
  196|      0|        end_of_buffer_offset_ += buffer_.size();
  197|      0|        if (!status.ok()) {
  198|      0|          buffer_.clear();
  199|      0|          ReportDrop(kBlockSize, status);
  200|      0|          eof_ = true;
  201|      0|          return kEof;
  202|      0|        } else if (buffer_.size() < kBlockSize) {
  203|      0|          eof_ = true;
  204|      0|        }
  205|      0|        continue;
  206|      0|      } else {
  207|      0|        // Note that if buffer_ is non-empty, we have a truncated header at the
  208|      0|        // end of the file, which can be caused by the writer crashing in the
  209|      0|        // middle of writing the header. Instead of considering this an error,
  210|      0|        // just report EOF.
  211|      0|        buffer_.clear();
  212|      0|        return kEof;
  213|      0|      }
  214|      0|    }
  215|      0|
  216|      0|    // Parse the header
  217|      0|    const char* header = buffer_.data();
  218|      0|    const uint32_t a = static_cast<uint32_t>(header[4]) & 0xff;
  219|      0|    const uint32_t b = static_cast<uint32_t>(header[5]) & 0xff;
  220|      0|    const unsigned int type = header[6];
  221|      0|    const uint32_t length = a | (b << 8);
  222|      0|    if (kHeaderSize + length > buffer_.size()) {
  223|      0|      size_t drop_size = buffer_.size();
  224|      0|      buffer_.clear();
  225|      0|      if (!eof_) {
  226|      0|        ReportCorruption(drop_size, "bad record length");
  227|      0|        return kBadRecord;
  228|      0|      }
  229|      0|      // If the end of the file has been reached without reading |length| bytes
  230|      0|      // of payload, assume the writer died in the middle of writing the record.
  231|      0|      // Don't report a corruption.
  232|      0|      return kEof;
  233|      0|    }
  234|      0|
  235|      0|    if (type == kZeroType && length == 0) {
  236|      0|      // Skip zero length record without reporting any drops since
  237|      0|      // such records are produced by the mmap based writing code in
  238|      0|      // env_posix.cc that preallocates file regions.
  239|      0|      buffer_.clear();
  240|      0|      return kBadRecord;
  241|      0|    }
  242|      0|
  243|      0|    // Check crc
  244|      0|    if (checksum_) {
  245|      0|      uint32_t expected_crc = crc32c::Unmask(DecodeFixed32(header));
  246|      0|      uint32_t actual_crc = crc32c::Value(header + 6, 1 + length);
  247|      0|      if (actual_crc != expected_crc) {
  248|      0|        // Drop the rest of the buffer since "length" itself may have
  249|      0|        // been corrupted and if we trust it, we could find some
  250|      0|        // fragment of a real log record that just happens to look
  251|      0|        // like a valid log record.
  252|      0|        size_t drop_size = buffer_.size();
  253|      0|        buffer_.clear();
  254|      0|        ReportCorruption(drop_size, "checksum mismatch");
  255|      0|        return kBadRecord;
  256|      0|      }
  257|      0|    }
  258|      0|
  259|      0|    buffer_.remove_prefix(kHeaderSize + length);
  260|      0|
  261|      0|    // Skip physical record that started before initial_offset_
  262|      0|    if (end_of_buffer_offset_ - buffer_.size() - kHeaderSize - length <
  263|      0|        initial_offset_) {
  264|      0|      result->clear();
  265|      0|      return kBadRecord;
  266|      0|    }
  267|      0|
  268|      0|    *result = Slice(header + kHeaderSize, length);
  269|      0|    return type;
  270|      0|  }
  271|      0|}
  272|       |
  273|       |}  // namespace log
  274|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/log_writer.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/log_writer.h"
    6|       |
    7|       |#include <stdint.h>
    8|       |
    9|       |#include "leveldb/env.h"
   10|       |#include "util/coding.h"
   11|       |#include "util/crc32c.h"
   12|       |
   13|       |namespace leveldb {
   14|       |namespace log {
   15|       |
   16|      0|static void InitTypeCrc(uint32_t* type_crc) {
   17|      0|  for (int i = 0; i <= kMaxRecordType; i++) {
   18|      0|    char t = static_cast<char>(i);
   19|      0|    type_crc[i] = crc32c::Value(&t, 1);
   20|      0|  }
   21|      0|}
   22|       |
   23|      0|Writer::Writer(WritableFile* dest) : dest_(dest), block_offset_(0) {
   24|      0|  InitTypeCrc(type_crc_);
   25|      0|}
   26|       |
   27|       |Writer::Writer(WritableFile* dest, uint64_t dest_length)
   28|      0|    : dest_(dest), block_offset_(dest_length % kBlockSize) {
   29|      0|  InitTypeCrc(type_crc_);
   30|      0|}
   31|       |
   32|      0|Writer::~Writer() {}
   33|       |
   34|      0|Status Writer::AddRecord(const Slice& slice) {
   35|      0|  const char* ptr = slice.data();
   36|      0|  size_t left = slice.size();
   37|      0|
   38|      0|  // Fragment the record if necessary and emit it.  Note that if slice
   39|      0|  // is empty, we still want to iterate once to emit a single
   40|      0|  // zero-length record
   41|      0|  Status s;
   42|      0|  bool begin = true;
   43|      0|  do {
   44|      0|    const int leftover = kBlockSize - block_offset_;
   45|      0|    assert(leftover >= 0);
   46|      0|    if (leftover < kHeaderSize) {
   47|      0|      // Switch to a new block
   48|      0|      if (leftover > 0) {
   49|      0|        // Fill the trailer (literal below relies on kHeaderSize being 7)
   50|      0|        static_assert(kHeaderSize == 7, "");
   51|      0|        dest_->Append(Slice("\x00\x00\x00\x00\x00\x00", leftover));
   52|      0|      }
   53|      0|      block_offset_ = 0;
   54|      0|    }
   55|      0|
   56|      0|    // Invariant: we never leave < kHeaderSize bytes in a block.
   57|      0|    assert(kBlockSize - block_offset_ - kHeaderSize >= 0);
   58|      0|
   59|      0|    const size_t avail = kBlockSize - block_offset_ - kHeaderSize;
   60|      0|    const size_t fragment_length = (left < avail) ? left : avail;
   61|      0|
   62|      0|    RecordType type;
   63|      0|    const bool end = (left == fragment_length);
   64|      0|    if (begin && end) {
   65|      0|      type = kFullType;
   66|      0|    } else if (begin) {
   67|      0|      type = kFirstType;
   68|      0|    } else if (end) {
   69|      0|      type = kLastType;
   70|      0|    } else {
   71|      0|      type = kMiddleType;
   72|      0|    }
   73|      0|
   74|      0|    s = EmitPhysicalRecord(type, ptr, fragment_length);
   75|      0|    ptr += fragment_length;
   76|      0|    left -= fragment_length;
   77|      0|    begin = false;
   78|      0|  } while (s.ok() && left > 0);
   79|      0|  return s;
   80|      0|}
   81|       |
   82|       |Status Writer::EmitPhysicalRecord(RecordType t, const char* ptr,
   83|      0|                                  size_t length) {
   84|      0|  assert(length <= 0xffff);  // Must fit in two bytes
   85|      0|  assert(block_offset_ + kHeaderSize + length <= kBlockSize);
   86|      0|
   87|      0|  // Format the header
   88|      0|  char buf[kHeaderSize];
   89|      0|  buf[4] = static_cast<char>(length & 0xff);
   90|      0|  buf[5] = static_cast<char>(length >> 8);
   91|      0|  buf[6] = static_cast<char>(t);
   92|      0|
   93|      0|  // Compute the crc of the record type and the payload.
   94|      0|  uint32_t crc = crc32c::Extend(type_crc_[t], ptr, length);
   95|      0|  crc = crc32c::Mask(crc);  // Adjust for storage
   96|      0|  EncodeFixed32(buf, crc);
   97|      0|
   98|      0|  // Write the header and the payload
   99|      0|  Status s = dest_->Append(Slice(buf, kHeaderSize));
  100|      0|  if (s.ok()) {
  101|      0|    s = dest_->Append(Slice(ptr, length));
  102|      0|    if (s.ok()) {
  103|      0|      s = dest_->Flush();
  104|      0|    }
  105|      0|  }
  106|      0|  block_offset_ += kHeaderSize + length;
  107|      0|  return s;
  108|      0|}
  109|       |
  110|       |}  // namespace log
  111|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/memtable.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/memtable.h"
    6|       |#include "db/dbformat.h"
    7|       |#include "leveldb/comparator.h"
    8|       |#include "leveldb/env.h"
    9|       |#include "leveldb/iterator.h"
   10|       |#include "util/coding.h"
   11|       |
   12|       |namespace leveldb {
   13|       |
   14|      0|static Slice GetLengthPrefixedSlice(const char* data) {
   15|      0|  uint32_t len;
   16|      0|  const char* p = data;
   17|      0|  p = GetVarint32Ptr(p, p + 5, &len);  // +5: we assume "p" is not corrupted
   18|      0|  return Slice(p, len);
   19|      0|}
   20|       |
   21|       |MemTable::MemTable(const InternalKeyComparator& comparator)
   22|      0|    : comparator_(comparator), refs_(0), table_(comparator_, &arena_) {}
   23|       |
   24|      0|MemTable::~MemTable() { assert(refs_ == 0); }
   25|       |
   26|      0|size_t MemTable::ApproximateMemoryUsage() { return arena_.MemoryUsage(); }
   27|       |
   28|       |int MemTable::KeyComparator::operator()(const char* aptr,
   29|      0|                                        const char* bptr) const {
   30|      0|  // Internal keys are encoded as length-prefixed strings.
   31|      0|  Slice a = GetLengthPrefixedSlice(aptr);
   32|      0|  Slice b = GetLengthPrefixedSlice(bptr);
   33|      0|  return comparator.Compare(a, b);
   34|      0|}
   35|       |
   36|       |// Encode a suitable internal key target for "target" and return it.
   37|       |// Uses *scratch as scratch space, and the returned pointer will point
   38|       |// into this scratch space.
   39|      0|static const char* EncodeKey(std::string* scratch, const Slice& target) {
   40|      0|  scratch->clear();
   41|      0|  PutVarint32(scratch, target.size());
   42|      0|  scratch->append(target.data(), target.size());
   43|      0|  return scratch->data();
   44|      0|}
   45|       |
   46|       |class MemTableIterator : public Iterator {
   47|       | public:
   48|      0|  explicit MemTableIterator(MemTable::Table* table) : iter_(table) {}
   49|       |
   50|      0|  virtual bool Valid() const { return iter_.Valid(); }
   51|      0|  virtual void Seek(const Slice& k) { iter_.Seek(EncodeKey(&tmp_, k)); }
   52|      0|  virtual void SeekToFirst() { iter_.SeekToFirst(); }
   53|      0|  virtual void SeekToLast() { iter_.SeekToLast(); }
   54|      0|  virtual void Next() { iter_.Next(); }
   55|      0|  virtual void Prev() { iter_.Prev(); }
   56|      0|  virtual Slice key() const { return GetLengthPrefixedSlice(iter_.key()); }
   57|      0|  virtual Slice value() const {
   58|      0|    Slice key_slice = GetLengthPrefixedSlice(iter_.key());
   59|      0|    return GetLengthPrefixedSlice(key_slice.data() + key_slice.size());
   60|      0|  }
   61|       |
   62|      0|  virtual Status status() const { return Status::OK(); }
   63|       |
   64|       | private:
   65|       |  MemTable::Table::Iterator iter_;
   66|       |  std::string tmp_;  // For passing to EncodeKey
   67|       |
   68|       |  // No copying allowed
   69|       |  MemTableIterator(const MemTableIterator&);
   70|       |  void operator=(const MemTableIterator&);
   71|       |};
   72|       |
   73|      0|Iterator* MemTable::NewIterator() { return new MemTableIterator(&table_); }
   74|       |
   75|       |void MemTable::Add(SequenceNumber s, ValueType type, const Slice& key,
   76|      0|                   const Slice& value) {
   77|      0|  // Format of an entry is concatenation of:
   78|      0|  //  key_size     : varint32 of internal_key.size()
   79|      0|  //  key bytes    : char[internal_key.size()]
   80|      0|  //  value_size   : varint32 of value.size()
   81|      0|  //  value bytes  : char[value.size()]
   82|      0|  size_t key_size = key.size();
   83|      0|  size_t val_size = value.size();
   84|      0|  size_t internal_key_size = key_size + 8;
   85|      0|  const size_t encoded_len = VarintLength(internal_key_size) +
   86|      0|                             internal_key_size + VarintLength(val_size) +
   87|      0|                             val_size;
   88|      0|  char* buf = arena_.Allocate(encoded_len);
   89|      0|  char* p = EncodeVarint32(buf, internal_key_size);
   90|      0|  memcpy(p, key.data(), key_size);
   91|      0|  p += key_size;
   92|      0|  EncodeFixed64(p, (s << 8) | type);
   93|      0|  p += 8;
   94|      0|  p = EncodeVarint32(p, val_size);
   95|      0|  memcpy(p, value.data(), val_size);
   96|      0|  assert(p + val_size == buf + encoded_len);
   97|      0|  table_.Insert(buf);
   98|      0|}
   99|       |
  100|      0|bool MemTable::Get(const LookupKey& key, std::string* value, Status* s) {
  101|      0|  Slice memkey = key.memtable_key();
  102|      0|  Table::Iterator iter(&table_);
  103|      0|  iter.Seek(memkey.data());
  104|      0|  if (iter.Valid()) {
  105|      0|    // entry format is:
  106|      0|    //    klength  varint32
  107|      0|    //    userkey  char[klength]
  108|      0|    //    tag      uint64
  109|      0|    //    vlength  varint32
  110|      0|    //    value    char[vlength]
  111|      0|    // Check that it belongs to same user key.  We do not check the
  112|      0|    // sequence number since the Seek() call above should have skipped
  113|      0|    // all entries with overly large sequence numbers.
  114|      0|    const char* entry = iter.key();
  115|      0|    uint32_t key_length;
  116|      0|    const char* key_ptr = GetVarint32Ptr(entry, entry + 5, &key_length);
  117|      0|    if (comparator_.comparator.user_comparator()->Compare(
  118|      0|            Slice(key_ptr, key_length - 8), key.user_key()) == 0) {
  119|      0|      // Correct user key
  120|      0|      const uint64_t tag = DecodeFixed64(key_ptr + key_length - 8);
  121|      0|      switch (static_cast<ValueType>(tag & 0xff)) {
  122|      0|        case kTypeValue: {
  123|      0|          Slice v = GetLengthPrefixedSlice(key_ptr + key_length);
  124|      0|          value->assign(v.data(), v.size());
  125|      0|          return true;
  126|      0|        }
  127|      0|        case kTypeDeletion:
  128|      0|          *s = Status::NotFound(Slice());
  129|      0|          return true;
  130|      0|      }
  131|      0|    }
  132|      0|  }
  133|      0|  return false;
  134|      0|}
  135|       |
  136|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/memtable.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_DB_MEMTABLE_H_
    6|       |#define STORAGE_LEVELDB_DB_MEMTABLE_H_
    7|       |
    8|       |#include <string>
    9|       |
   10|       |#include "db/dbformat.h"
   11|       |#include "db/skiplist.h"
   12|       |#include "leveldb/db.h"
   13|       |#include "util/arena.h"
   14|       |
   15|       |namespace leveldb {
   16|       |
   17|       |class InternalKeyComparator;
   18|       |class MemTableIterator;
   19|       |
   20|       |class MemTable {
   21|       | public:
   22|       |  // MemTables are reference counted.  The initial reference count
   23|       |  // is zero and the caller must call Ref() at least once.
   24|       |  explicit MemTable(const InternalKeyComparator& comparator);
   25|       |
   26|       |  MemTable(const MemTable&) = delete;
   27|       |  MemTable& operator=(const MemTable&) = delete;
   28|       |
   29|       |  // Increase reference count.
   30|      0|  void Ref() { ++refs_; }
   31|       |
   32|       |  // Drop reference count.  Delete if no more references exist.
   33|      0|  void Unref() {
   34|      0|    --refs_;
   35|      0|    assert(refs_ >= 0);
   36|      0|    if (refs_ <= 0) {
   37|      0|      delete this;
   38|      0|    }
   39|      0|  }
   40|       |
   41|       |  // Returns an estimate of the number of bytes of data in use by this
   42|       |  // data structure. It is safe to call when MemTable is being modified.
   43|       |  size_t ApproximateMemoryUsage();
   44|       |
   45|       |  // Return an iterator that yields the contents of the memtable.
   46|       |  //
   47|       |  // The caller must ensure that the underlying MemTable remains live
   48|       |  // while the returned iterator is live.  The keys returned by this
   49|       |  // iterator are internal keys encoded by AppendInternalKey in the
   50|       |  // db/format.{h,cc} module.
   51|       |  Iterator* NewIterator();
   52|       |
   53|       |  // Add an entry into memtable that maps key to value at the
   54|       |  // specified sequence number and with the specified type.
   55|       |  // Typically value will be empty if type==kTypeDeletion.
   56|       |  void Add(SequenceNumber seq, ValueType type, const Slice& key,
   57|       |           const Slice& value);
   58|       |
   59|       |  // If memtable contains a value for key, store it in *value and return true.
   60|       |  // If memtable contains a deletion for key, store a NotFound() error
   61|       |  // in *status and return true.
   62|       |  // Else, return false.
   63|       |  bool Get(const LookupKey& key, std::string* value, Status* s);
   64|       |
   65|       | private:
   66|       |  friend class MemTableIterator;
   67|       |  friend class MemTableBackwardIterator;
   68|       |
   69|       |  struct KeyComparator {
   70|       |    const InternalKeyComparator comparator;
   71|      0|    explicit KeyComparator(const InternalKeyComparator& c) : comparator(c) {}
   72|       |    int operator()(const char* a, const char* b) const;
   73|       |  };
   74|       |
   75|       |  typedef SkipList<const char*, KeyComparator> Table;
   76|       |
   77|       |  ~MemTable();  // Private since only Unref() should be used to delete it
   78|       |
   79|       |  KeyComparator comparator_;
   80|       |  int refs_;
   81|       |  Arena arena_;
   82|       |  Table table_;
   83|       |};
   84|       |
   85|       |}  // namespace leveldb
   86|       |
   87|       |#endif  // STORAGE_LEVELDB_DB_MEMTABLE_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/repair.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// We recover the contents of the descriptor from the other files we find.
    6|       |// (1) Any log files are first converted to tables
    7|       |// (2) We scan every table to compute
    8|       |//     (a) smallest/largest for the table
    9|       |//     (b) largest sequence number in the table
   10|       |// (3) We generate descriptor contents:
   11|       |//      - log number is set to zero
   12|       |//      - next-file-number is set to 1 + largest file number we found
   13|       |//      - last-sequence-number is set to largest sequence# found across
   14|       |//        all tables (see 2c)
   15|       |//      - compaction pointers are cleared
   16|       |//      - every table file is added at level 0
   17|       |//
   18|       |// Possible optimization 1:
   19|       |//   (a) Compute total size and use to pick appropriate max-level M
   20|       |//   (b) Sort tables by largest sequence# in the table
   21|       |//   (c) For each table: if it overlaps earlier table, place in level-0,
   22|       |//       else place in level-M.
   23|       |// Possible optimization 2:
   24|       |//   Store per-table metadata (smallest, largest, largest-seq#, ...)
   25|       |//   in the table's meta section to speed up ScanTable.
   26|       |
   27|       |#include "db/builder.h"
   28|       |#include "db/db_impl.h"
   29|       |#include "db/dbformat.h"
   30|       |#include "db/filename.h"
   31|       |#include "db/log_reader.h"
   32|       |#include "db/log_writer.h"
   33|       |#include "db/memtable.h"
   34|       |#include "db/table_cache.h"
   35|       |#include "db/version_edit.h"
   36|       |#include "db/write_batch_internal.h"
   37|       |#include "leveldb/comparator.h"
   38|       |#include "leveldb/db.h"
   39|       |#include "leveldb/env.h"
   40|       |
   41|       |namespace leveldb {
   42|       |
   43|       |namespace {
   44|       |
   45|       |class Repairer {
   46|       | public:
   47|       |  Repairer(const std::string& dbname, const Options& options)
   48|       |      : dbname_(dbname),
   49|       |        env_(options.env),
   50|       |        icmp_(options.comparator),
   51|       |        ipolicy_(options.filter_policy),
   52|       |        options_(SanitizeOptions(dbname, &icmp_, &ipolicy_, options)),
   53|       |        owns_info_log_(options_.info_log != options.info_log),
   54|       |        owns_cache_(options_.block_cache != options.block_cache),
   55|      0|        next_file_number_(1) {
   56|      0|    // TableCache can be small since we expect each table to be opened once.
   57|      0|    table_cache_ = new TableCache(dbname_, options_, 10);
   58|      0|  }
   59|       |
   60|      0|  ~Repairer() {
   61|      0|    delete table_cache_;
   62|      0|    if (owns_info_log_) {
   63|      0|      delete options_.info_log;
   64|      0|    }
   65|      0|    if (owns_cache_) {
   66|      0|      delete options_.block_cache;
   67|      0|    }
   68|      0|  }
   69|       |
   70|      0|  Status Run() {
   71|      0|    Status status = FindFiles();
   72|      0|    if (status.ok()) {
   73|      0|      ConvertLogFilesToTables();
   74|      0|      ExtractMetaData();
   75|      0|      status = WriteDescriptor();
   76|      0|    }
   77|      0|    if (status.ok()) {
   78|      0|      unsigned long long bytes = 0;
   79|      0|      for (size_t i = 0; i < tables_.size(); i++) {
   80|      0|        bytes += tables_[i].meta.file_size;
   81|      0|      }
   82|      0|      Log(options_.info_log,
   83|      0|          "**** Repaired leveldb %s; "
   84|      0|          "recovered %d files; %llu bytes. "
   85|      0|          "Some data may have been lost. "
   86|      0|          "****",
   87|      0|          dbname_.c_str(), static_cast<int>(tables_.size()), bytes);
   88|      0|    }
   89|      0|    return status;
   90|      0|  }
   91|       |
   92|       | private:
   93|       |  struct TableInfo {
   94|       |    FileMetaData meta;
   95|       |    SequenceNumber max_sequence;
   96|       |  };
   97|       |
   98|      0|  Status FindFiles() {
   99|      0|    std::vector<std::string> filenames;
  100|      0|    Status status = env_->GetChildren(dbname_, &filenames);
  101|      0|    if (!status.ok()) {
  102|      0|      return status;
  103|      0|    }
  104|      0|    if (filenames.empty()) {
  105|      0|      return Status::IOError(dbname_, "repair found no files");
  106|      0|    }
  107|      0|
  108|      0|    uint64_t number;
  109|      0|    FileType type;
  110|      0|    for (size_t i = 0; i < filenames.size(); i++) {
  111|      0|      if (ParseFileName(filenames[i], &number, &type)) {
  112|      0|        if (type == kDescriptorFile) {
  113|      0|          manifests_.push_back(filenames[i]);
  114|      0|        } else {
  115|      0|          if (number + 1 > next_file_number_) {
  116|      0|            next_file_number_ = number + 1;
  117|      0|          }
  118|      0|          if (type == kLogFile) {
  119|      0|            logs_.push_back(number);
  120|      0|          } else if (type == kTableFile) {
  121|      0|            table_numbers_.push_back(number);
  122|      0|          } else {
  123|      0|            // Ignore other files
  124|      0|          }
  125|      0|        }
  126|      0|      }
  127|      0|    }
  128|      0|    return status;
  129|      0|  }
  130|       |
  131|      0|  void ConvertLogFilesToTables() {
  132|      0|    for (size_t i = 0; i < logs_.size(); i++) {
  133|      0|      std::string logname = LogFileName(dbname_, logs_[i]);
  134|      0|      Status status = ConvertLogToTable(logs_[i]);
  135|      0|      if (!status.ok()) {
  136|      0|        Log(options_.info_log, "Log #%llu: ignoring conversion error: %s",
  137|      0|            (unsigned long long)logs_[i], status.ToString().c_str());
  138|      0|      }
  139|      0|      ArchiveFile(logname);
  140|      0|    }
  141|      0|  }
  142|       |
  143|      0|  Status ConvertLogToTable(uint64_t log) {
  144|      0|    struct LogReporter : public log::Reader::Reporter {
  145|      0|      Env* env;
  146|      0|      Logger* info_log;
  147|      0|      uint64_t lognum;
  148|      0|      virtual void Corruption(size_t bytes, const Status& s) {
  149|      0|        // We print error messages for corruption, but continue repairing.
  150|      0|        Log(info_log, "Log #%llu: dropping %d bytes; %s",
  151|      0|            (unsigned long long)lognum, static_cast<int>(bytes),
  152|      0|            s.ToString().c_str());
  153|      0|      }
  154|      0|    };
  155|      0|
  156|      0|    // Open the log file
  157|      0|    std::string logname = LogFileName(dbname_, log);
  158|      0|    SequentialFile* lfile;
  159|      0|    Status status = env_->NewSequentialFile(logname, &lfile);
  160|      0|    if (!status.ok()) {
  161|      0|      return status;
  162|      0|    }
  163|      0|
  164|      0|    // Create the log reader.
  165|      0|    LogReporter reporter;
  166|      0|    reporter.env = env_;
  167|      0|    reporter.info_log = options_.info_log;
  168|      0|    reporter.lognum = log;
  169|      0|    // We intentionally make log::Reader do checksumming so that
  170|      0|    // corruptions cause entire commits to be skipped instead of
  171|      0|    // propagating bad information (like overly large sequence
  172|      0|    // numbers).
  173|      0|    log::Reader reader(lfile, &reporter, false /*do not checksum*/,
  174|      0|                       0 /*initial_offset*/);
  175|      0|
  176|      0|    // Read all the records and add to a memtable
  177|      0|    std::string scratch;
  178|      0|    Slice record;
  179|      0|    WriteBatch batch;
  180|      0|    MemTable* mem = new MemTable(icmp_);
  181|      0|    mem->Ref();
  182|      0|    int counter = 0;
  183|      0|    while (reader.ReadRecord(&record, &scratch)) {
  184|      0|      if (record.size() < 12) {
  185|      0|        reporter.Corruption(record.size(),
  186|      0|                            Status::Corruption("log record too small"));
  187|      0|        continue;
  188|      0|      }
  189|      0|      WriteBatchInternal::SetContents(&batch, record);
  190|      0|      status = WriteBatchInternal::InsertInto(&batch, mem);
  191|      0|      if (status.ok()) {
  192|      0|        counter += WriteBatchInternal::Count(&batch);
  193|      0|      } else {
  194|      0|        Log(options_.info_log, "Log #%llu: ignoring %s",
  195|      0|            (unsigned long long)log, status.ToString().c_str());
  196|      0|        status = Status::OK();  // Keep going with rest of file
  197|      0|      }
  198|      0|    }
  199|      0|    delete lfile;
  200|      0|
  201|      0|    // Do not record a version edit for this conversion to a Table
  202|      0|    // since ExtractMetaData() will also generate edits.
  203|      0|    FileMetaData meta;
  204|      0|    meta.number = next_file_number_++;
  205|      0|    Iterator* iter = mem->NewIterator();
  206|      0|    status = BuildTable(dbname_, env_, options_, table_cache_, iter, &meta);
  207|      0|    delete iter;
  208|      0|    mem->Unref();
  209|      0|    mem = nullptr;
  210|      0|    if (status.ok()) {
  211|      0|      if (meta.file_size > 0) {
  212|      0|        table_numbers_.push_back(meta.number);
  213|      0|      }
  214|      0|    }
  215|      0|    Log(options_.info_log, "Log #%llu: %d ops saved to Table #%llu %s",
  216|      0|        (unsigned long long)log, counter, (unsigned long long)meta.number,
  217|      0|        status.ToString().c_str());
  218|      0|    return status;
  219|      0|  }
  220|       |
  221|      0|  void ExtractMetaData() {
  222|      0|    for (size_t i = 0; i < table_numbers_.size(); i++) {
  223|      0|      ScanTable(table_numbers_[i]);
  224|      0|    }
  225|      0|  }
  226|       |
  227|      0|  Iterator* NewTableIterator(const FileMetaData& meta) {
  228|      0|    // Same as compaction iterators: if paranoid_checks are on, turn
  229|      0|    // on checksum verification.
  230|      0|    ReadOptions r;
  231|      0|    r.verify_checksums = options_.paranoid_checks;
  232|      0|    return table_cache_->NewIterator(r, meta.number, meta.file_size);
  233|      0|  }
  234|       |
  235|      0|  void ScanTable(uint64_t number) {
  236|      0|    TableInfo t;
  237|      0|    t.meta.number = number;
  238|      0|    std::string fname = TableFileName(dbname_, number);
  239|      0|    Status status = env_->GetFileSize(fname, &t.meta.file_size);
  240|      0|    if (!status.ok()) {
  241|      0|      // Try alternate file name.
  242|      0|      fname = SSTTableFileName(dbname_, number);
  243|      0|      Status s2 = env_->GetFileSize(fname, &t.meta.file_size);
  244|      0|      if (s2.ok()) {
  245|      0|        status = Status::OK();
  246|      0|      }
  247|      0|    }
  248|      0|    if (!status.ok()) {
  249|      0|      ArchiveFile(TableFileName(dbname_, number));
  250|      0|      ArchiveFile(SSTTableFileName(dbname_, number));
  251|      0|      Log(options_.info_log, "Table #%llu: dropped: %s",
  252|      0|          (unsigned long long)t.meta.number, status.ToString().c_str());
  253|      0|      return;
  254|      0|    }
  255|      0|
  256|      0|    // Extract metadata by scanning through table.
  257|      0|    int counter = 0;
  258|      0|    Iterator* iter = NewTableIterator(t.meta);
  259|      0|    bool empty = true;
  260|      0|    ParsedInternalKey parsed;
  261|      0|    t.max_sequence = 0;
  262|      0|    for (iter->SeekToFirst(); iter->Valid(); iter->Next()) {
  263|      0|      Slice key = iter->key();
  264|      0|      if (!ParseInternalKey(key, &parsed)) {
  265|      0|        Log(options_.info_log, "Table #%llu: unparsable key %s",
  266|      0|            (unsigned long long)t.meta.number, EscapeString(key).c_str());
  267|      0|        continue;
  268|      0|      }
  269|      0|
  270|      0|      counter++;
  271|      0|      if (empty) {
  272|      0|        empty = false;
  273|      0|        t.meta.smallest.DecodeFrom(key);
  274|      0|      }
  275|      0|      t.meta.largest.DecodeFrom(key);
  276|      0|      if (parsed.sequence > t.max_sequence) {
  277|      0|        t.max_sequence = parsed.sequence;
  278|      0|      }
  279|      0|    }
  280|      0|    if (!iter->status().ok()) {
  281|      0|      status = iter->status();
  282|      0|    }
  283|      0|    delete iter;
  284|      0|    Log(options_.info_log, "Table #%llu: %d entries %s",
  285|      0|        (unsigned long long)t.meta.number, counter, status.ToString().c_str());
  286|      0|
  287|      0|    if (status.ok()) {
  288|      0|      tables_.push_back(t);
  289|      0|    } else {
  290|      0|      RepairTable(fname, t);  // RepairTable archives input file.
  291|      0|    }
  292|      0|  }
  293|       |
  294|      0|  void RepairTable(const std::string& src, TableInfo t) {
  295|      0|    // We will copy src contents to a new table and then rename the
  296|      0|    // new table over the source.
  297|      0|
  298|      0|    // Create builder.
  299|      0|    std::string copy = TableFileName(dbname_, next_file_number_++);
  300|      0|    WritableFile* file;
  301|      0|    Status s = env_->NewWritableFile(copy, &file);
  302|      0|    if (!s.ok()) {
  303|      0|      return;
  304|      0|    }
  305|      0|    TableBuilder* builder = new TableBuilder(options_, file);
  306|      0|
  307|      0|    // Copy data.
  308|      0|    Iterator* iter = NewTableIterator(t.meta);
  309|      0|    int counter = 0;
  310|      0|    for (iter->SeekToFirst(); iter->Valid(); iter->Next()) {
  311|      0|      builder->Add(iter->key(), iter->value());
  312|      0|      counter++;
  313|      0|    }
  314|      0|    delete iter;
  315|      0|
  316|      0|    ArchiveFile(src);
  317|      0|    if (counter == 0) {
  318|      0|      builder->Abandon();  // Nothing to save
  319|      0|    } else {
  320|      0|      s = builder->Finish();
  321|      0|      if (s.ok()) {
  322|      0|        t.meta.file_size = builder->FileSize();
  323|      0|      }
  324|      0|    }
  325|      0|    delete builder;
  326|      0|    builder = nullptr;
  327|      0|
  328|      0|    if (s.ok()) {
  329|      0|      s = file->Close();
  330|      0|    }
  331|      0|    delete file;
  332|      0|    file = nullptr;
  333|      0|
  334|      0|    if (counter > 0 && s.ok()) {
  335|      0|      std::string orig = TableFileName(dbname_, t.meta.number);
  336|      0|      s = env_->RenameFile(copy, orig);
  337|      0|      if (s.ok()) {
  338|      0|        Log(options_.info_log, "Table #%llu: %d entries repaired",
  339|      0|            (unsigned long long)t.meta.number, counter);
  340|      0|        tables_.push_back(t);
  341|      0|      }
  342|      0|    }
  343|      0|    if (!s.ok()) {
  344|      0|      env_->DeleteFile(copy);
  345|      0|    }
  346|      0|  }
  347|       |
  348|      0|  Status WriteDescriptor() {
  349|      0|    std::string tmp = TempFileName(dbname_, 1);
  350|      0|    WritableFile* file;
  351|      0|    Status status = env_->NewWritableFile(tmp, &file);
  352|      0|    if (!status.ok()) {
  353|      0|      return status;
  354|      0|    }
  355|      0|
  356|      0|    SequenceNumber max_sequence = 0;
  357|      0|    for (size_t i = 0; i < tables_.size(); i++) {
  358|      0|      if (max_sequence < tables_[i].max_sequence) {
  359|      0|        max_sequence = tables_[i].max_sequence;
  360|      0|      }
  361|      0|    }
  362|      0|
  363|      0|    edit_.SetComparatorName(icmp_.user_comparator()->Name());
  364|      0|    edit_.SetLogNumber(0);
  365|      0|    edit_.SetNextFile(next_file_number_);
  366|      0|    edit_.SetLastSequence(max_sequence);
  367|      0|
  368|      0|    for (size_t i = 0; i < tables_.size(); i++) {
  369|      0|      // TODO(opt): separate out into multiple levels
  370|      0|      const TableInfo& t = tables_[i];
  371|      0|      edit_.AddFile(0, t.meta.number, t.meta.file_size, t.meta.smallest,
  372|      0|                    t.meta.largest);
  373|      0|    }
  374|      0|
  375|      0|    // fprintf(stderr, "NewDescriptor:\n%s\n", edit_.DebugString().c_str());
  376|      0|    {
  377|      0|      log::Writer log(file);
  378|      0|      std::string record;
  379|      0|      edit_.EncodeTo(&record);
  380|      0|      status = log.AddRecord(record);
  381|      0|    }
  382|      0|    if (status.ok()) {
  383|      0|      status = file->Close();
  384|      0|    }
  385|      0|    delete file;
  386|      0|    file = nullptr;
  387|      0|
  388|      0|    if (!status.ok()) {
  389|      0|      env_->DeleteFile(tmp);
  390|      0|    } else {
  391|      0|      // Discard older manifests
  392|      0|      for (size_t i = 0; i < manifests_.size(); i++) {
  393|      0|        ArchiveFile(dbname_ + "/" + manifests_[i]);
  394|      0|      }
  395|      0|
  396|      0|      // Install new manifest
  397|      0|      status = env_->RenameFile(tmp, DescriptorFileName(dbname_, 1));
  398|      0|      if (status.ok()) {
  399|      0|        status = SetCurrentFile(env_, dbname_, 1);
  400|      0|      } else {
  401|      0|        env_->DeleteFile(tmp);
  402|      0|      }
  403|      0|    }
  404|      0|    return status;
  405|      0|  }
  406|       |
  407|      0|  void ArchiveFile(const std::string& fname) {
  408|      0|    // Move into another directory.  E.g., for
  409|      0|    //    dir/foo
  410|      0|    // rename to
  411|      0|    //    dir/lost/foo
  412|      0|    const char* slash = strrchr(fname.c_str(), '/');
  413|      0|    std::string new_dir;
  414|      0|    if (slash != nullptr) {
  415|      0|      new_dir.assign(fname.data(), slash - fname.data());
  416|      0|    }
  417|      0|    new_dir.append("/lost");
  418|      0|    env_->CreateDir(new_dir);  // Ignore error
  419|      0|    std::string new_file = new_dir;
  420|      0|    new_file.append("/");
  421|      0|    new_file.append((slash == nullptr) ? fname.c_str() : slash + 1);
  422|      0|    Status s = env_->RenameFile(fname, new_file);
  423|      0|    Log(options_.info_log, "Archiving %s: %s\n", fname.c_str(),
  424|      0|        s.ToString().c_str());
  425|      0|  }
  426|       |
  427|       |  const std::string dbname_;
  428|       |  Env* const env_;
  429|       |  InternalKeyComparator const icmp_;
  430|       |  InternalFilterPolicy const ipolicy_;
  431|       |  const Options options_;
  432|       |  bool owns_info_log_;
  433|       |  bool owns_cache_;
  434|       |  TableCache* table_cache_;
  435|       |  VersionEdit edit_;
  436|       |
  437|       |  std::vector<std::string> manifests_;
  438|       |  std::vector<uint64_t> table_numbers_;
  439|       |  std::vector<uint64_t> logs_;
  440|       |  std::vector<TableInfo> tables_;
  441|       |  uint64_t next_file_number_;
  442|       |};
  443|       |}  // namespace
  444|       |
  445|      0|Status RepairDB(const std::string& dbname, const Options& options) {
  446|      0|  Repairer repairer(dbname, options);
  447|      0|  return repairer.Run();
  448|      0|}
  449|       |
  450|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/skiplist.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_DB_SKIPLIST_H_
    6|       |#define STORAGE_LEVELDB_DB_SKIPLIST_H_
    7|       |
    8|       |// Thread safety
    9|       |// -------------
   10|       |//
   11|       |// Writes require external synchronization, most likely a mutex.
   12|       |// Reads require a guarantee that the SkipList will not be destroyed
   13|       |// while the read is in progress.  Apart from that, reads progress
   14|       |// without any internal locking or synchronization.
   15|       |//
   16|       |// Invariants:
   17|       |//
   18|       |// (1) Allocated nodes are never deleted until the SkipList is
   19|       |// destroyed.  This is trivially guaranteed by the code since we
   20|       |// never delete any skip list nodes.
   21|       |//
   22|       |// (2) The contents of a Node except for the next/prev pointers are
   23|       |// immutable after the Node has been linked into the SkipList.
   24|       |// Only Insert() modifies the list, and it is careful to initialize
   25|       |// a node and use release-stores to publish the nodes in one or
   26|       |// more lists.
   27|       |//
   28|       |// ... prev vs. next pointer ordering ...
   29|       |
   30|       |#include <atomic>
   31|       |#include <cassert>
   32|       |#include <cstdlib>
   33|       |
   34|       |#include "util/arena.h"
   35|       |#include "util/random.h"
   36|       |
   37|       |namespace leveldb {
   38|       |
   39|       |class Arena;
   40|       |
   41|       |template <typename Key, class Comparator>
   42|       |class SkipList {
   43|       | private:
   44|       |  struct Node;
   45|       |
   46|       | public:
   47|       |  // Create a new SkipList object that will use "cmp" for comparing keys,
   48|       |  // and will allocate memory using "*arena".  Objects allocated in the arena
   49|       |  // must remain allocated for the lifetime of the skiplist object.
   50|       |  explicit SkipList(Comparator cmp, Arena* arena);
   51|       |
   52|       |  SkipList(const SkipList&) = delete;
   53|       |  SkipList& operator=(const SkipList&) = delete;
   54|       |
   55|       |  // Insert key into the list.
   56|       |  // REQUIRES: nothing that compares equal to key is currently in the list.
   57|       |  void Insert(const Key& key);
   58|       |
   59|       |  // Returns true iff an entry that compares equal to key is in the list.
   60|       |  bool Contains(const Key& key) const;
   61|       |
   62|       |  // Iteration over the contents of a skip list
   63|       |  class Iterator {
   64|       |   public:
   65|       |    // Initialize an iterator over the specified list.
   66|       |    // The returned iterator is not valid.
   67|       |    explicit Iterator(const SkipList* list);
   68|       |
   69|       |    // Returns true iff the iterator is positioned at a valid node.
   70|       |    bool Valid() const;
   71|       |
   72|       |    // Returns the key at the current position.
   73|       |    // REQUIRES: Valid()
   74|       |    const Key& key() const;
   75|       |
   76|       |    // Advances to the next position.
   77|       |    // REQUIRES: Valid()
   78|       |    void Next();
   79|       |
   80|       |    // Advances to the previous position.
   81|       |    // REQUIRES: Valid()
   82|       |    void Prev();
   83|       |
   84|       |    // Advance to the first entry with a key >= target
   85|       |    void Seek(const Key& target);
   86|       |
   87|       |    // Position at the first entry in list.
   88|       |    // Final state of iterator is Valid() iff list is not empty.
   89|       |    void SeekToFirst();
   90|       |
   91|       |    // Position at the last entry in list.
   92|       |    // Final state of iterator is Valid() iff list is not empty.
   93|       |    void SeekToLast();
   94|       |
   95|       |   private:
   96|       |    const SkipList* list_;
   97|       |    Node* node_;
   98|       |    // Intentionally copyable
   99|       |  };
  100|       |
  101|       | private:
  102|       |  enum { kMaxHeight = 12 };
  103|       |
  104|      0|  inline int GetMaxHeight() const {
  105|      0|    return max_height_.load(std::memory_order_relaxed);
  106|      0|  }
  107|       |
  108|       |  Node* NewNode(const Key& key, int height);
  109|       |  int RandomHeight();
  110|      0|  bool Equal(const Key& a, const Key& b) const { return (compare_(a, b) == 0); }
  111|       |
  112|       |  // Return true if key is greater than the data stored in "n"
  113|       |  bool KeyIsAfterNode(const Key& key, Node* n) const;
  114|       |
  115|       |  // Return the earliest node that comes at or after key.
  116|       |  // Return nullptr if there is no such node.
  117|       |  //
  118|       |  // If prev is non-null, fills prev[level] with pointer to previous
  119|       |  // node at "level" for every level in [0..max_height_-1].
  120|       |  Node* FindGreaterOrEqual(const Key& key, Node** prev) const;
  121|       |
  122|       |  // Return the latest node with a key < key.
  123|       |  // Return head_ if there is no such node.
  124|       |  Node* FindLessThan(const Key& key) const;
  125|       |
  126|       |  // Return the last node in the list.
  127|       |  // Return head_ if list is empty.
  128|       |  Node* FindLast() const;
  129|       |
  130|       |  // Immutable after construction
  131|       |  Comparator const compare_;
  132|       |  Arena* const arena_;  // Arena used for allocations of nodes
  133|       |
  134|       |  Node* const head_;
  135|       |
  136|       |  // Modified only by Insert().  Read racily by readers, but stale
  137|       |  // values are ok.
  138|       |  std::atomic<int> max_height_;  // Height of the entire list
  139|       |
  140|       |  // Read/written only by Insert().
  141|       |  Random rnd_;
  142|       |};
  143|       |
  144|       |// Implementation details follow
  145|       |template <typename Key, class Comparator>
  146|       |struct SkipList<Key, Comparator>::Node {
  147|      0|  explicit Node(const Key& k) : key(k) {}
  148|       |
  149|       |  Key const key;
  150|       |
  151|       |  // Accessors/mutators for links.  Wrapped in methods so we can
  152|       |  // add the appropriate barriers as necessary.
  153|      0|  Node* Next(int n) {
  154|      0|    assert(n >= 0);
  155|      0|    // Use an 'acquire load' so that we observe a fully initialized
  156|      0|    // version of the returned Node.
  157|      0|    return next_[n].load(std::memory_order_acquire);
  158|      0|  }
  159|      0|  void SetNext(int n, Node* x) {
  160|      0|    assert(n >= 0);
  161|      0|    // Use a 'release store' so that anybody who reads through this
  162|      0|    // pointer observes a fully initialized version of the inserted node.
  163|      0|    next_[n].store(x, std::memory_order_release);
  164|      0|  }
  165|       |
  166|       |  // No-barrier variants that can be safely used in a few locations.
  167|      0|  Node* NoBarrier_Next(int n) {
  168|      0|    assert(n >= 0);
  169|      0|    return next_[n].load(std::memory_order_relaxed);
  170|      0|  }
  171|      0|  void NoBarrier_SetNext(int n, Node* x) {
  172|      0|    assert(n >= 0);
  173|      0|    next_[n].store(x, std::memory_order_relaxed);
  174|      0|  }
  175|       |
  176|       | private:
  177|       |  // Array of length equal to the node height.  next_[0] is lowest level link.
  178|       |  std::atomic<Node*> next_[1];
  179|       |};
  180|       |
  181|       |template <typename Key, class Comparator>
  182|       |typename SkipList<Key, Comparator>::Node* SkipList<Key, Comparator>::NewNode(
  183|      0|    const Key& key, int height) {
  184|      0|  char* const node_memory = arena_->AllocateAligned(
  185|      0|      sizeof(Node) + sizeof(std::atomic<Node*>) * (height - 1));
  186|      0|  return new (node_memory) Node(key);
  187|      0|}
  188|       |
  189|       |template <typename Key, class Comparator>
  190|      0|inline SkipList<Key, Comparator>::Iterator::Iterator(const SkipList* list) {
  191|      0|  list_ = list;
  192|      0|  node_ = nullptr;
  193|      0|}
  194|       |
  195|       |template <typename Key, class Comparator>
  196|      0|inline bool SkipList<Key, Comparator>::Iterator::Valid() const {
  197|      0|  return node_ != nullptr;
  198|      0|}
  199|       |
  200|       |template <typename Key, class Comparator>
  201|      0|inline const Key& SkipList<Key, Comparator>::Iterator::key() const {
  202|      0|  assert(Valid());
  203|      0|  return node_->key;
  204|      0|}
  205|       |
  206|       |template <typename Key, class Comparator>
  207|      0|inline void SkipList<Key, Comparator>::Iterator::Next() {
  208|      0|  assert(Valid());
  209|      0|  node_ = node_->Next(0);
  210|      0|}
  211|       |
  212|       |template <typename Key, class Comparator>
  213|      0|inline void SkipList<Key, Comparator>::Iterator::Prev() {
  214|      0|  // Instead of using explicit "prev" links, we just search for the
  215|      0|  // last node that falls before key.
  216|      0|  assert(Valid());
  217|      0|  node_ = list_->FindLessThan(node_->key);
  218|      0|  if (node_ == list_->head_) {
  219|      0|    node_ = nullptr;
  220|      0|  }
  221|      0|}
  222|       |
  223|       |template <typename Key, class Comparator>
  224|      0|inline void SkipList<Key, Comparator>::Iterator::Seek(const Key& target) {
  225|      0|  node_ = list_->FindGreaterOrEqual(target, nullptr);
  226|      0|}
  227|       |
  228|       |template <typename Key, class Comparator>
  229|      0|inline void SkipList<Key, Comparator>::Iterator::SeekToFirst() {
  230|      0|  node_ = list_->head_->Next(0);
  231|      0|}
  232|       |
  233|       |template <typename Key, class Comparator>
  234|      0|inline void SkipList<Key, Comparator>::Iterator::SeekToLast() {
  235|      0|  node_ = list_->FindLast();
  236|      0|  if (node_ == list_->head_) {
  237|      0|    node_ = nullptr;
  238|      0|  }
  239|      0|}
  240|       |
  241|       |template <typename Key, class Comparator>
  242|      0|int SkipList<Key, Comparator>::RandomHeight() {
  243|      0|  // Increase height with probability 1 in kBranching
  244|      0|  static const unsigned int kBranching = 4;
  245|      0|  int height = 1;
  246|      0|  while (height < kMaxHeight && ((rnd_.Next() % kBranching) == 0)) {
  247|      0|    height++;
  248|      0|  }
  249|      0|  assert(height > 0);
  250|      0|  assert(height <= kMaxHeight);
  251|      0|  return height;
  252|      0|}
  253|       |
  254|       |template <typename Key, class Comparator>
  255|      0|bool SkipList<Key, Comparator>::KeyIsAfterNode(const Key& key, Node* n) const {
  256|      0|  // null n is considered infinite
  257|      0|  return (n != nullptr) && (compare_(n->key, key) < 0);
  258|      0|}
  259|       |
  260|       |template <typename Key, class Comparator>
  261|       |typename SkipList<Key, Comparator>::Node*
  262|       |SkipList<Key, Comparator>::FindGreaterOrEqual(const Key& key,
  263|      0|                                              Node** prev) const {
  264|      0|  Node* x = head_;
  265|      0|  int level = GetMaxHeight() - 1;
  266|      0|  while (true) {
  267|      0|    Node* next = x->Next(level);
  268|      0|    if (KeyIsAfterNode(key, next)) {
  269|      0|      // Keep searching in this list
  270|      0|      x = next;
  271|      0|    } else {
  272|      0|      if (prev != nullptr) prev[level] = x;
  273|      0|      if (level == 0) {
  274|      0|        return next;
  275|      0|      } else {
  276|      0|        // Switch to next list
  277|      0|        level--;
  278|      0|      }
  279|      0|    }
  280|      0|  }
  281|      0|}
  282|       |
  283|       |template <typename Key, class Comparator>
  284|       |typename SkipList<Key, Comparator>::Node*
  285|      0|SkipList<Key, Comparator>::FindLessThan(const Key& key) const {
  286|      0|  Node* x = head_;
  287|      0|  int level = GetMaxHeight() - 1;
  288|      0|  while (true) {
  289|      0|    assert(x == head_ || compare_(x->key, key) < 0);
  290|      0|    Node* next = x->Next(level);
  291|      0|    if (next == nullptr || compare_(next->key, key) >= 0) {
  292|      0|      if (level == 0) {
  293|      0|        return x;
  294|      0|      } else {
  295|      0|        // Switch to next list
  296|      0|        level--;
  297|      0|      }
  298|      0|    } else {
  299|      0|      x = next;
  300|      0|    }
  301|      0|  }
  302|      0|}
  303|       |
  304|       |template <typename Key, class Comparator>
  305|       |typename SkipList<Key, Comparator>::Node* SkipList<Key, Comparator>::FindLast()
  306|      0|    const {
  307|      0|  Node* x = head_;
  308|      0|  int level = GetMaxHeight() - 1;
  309|      0|  while (true) {
  310|      0|    Node* next = x->Next(level);
  311|      0|    if (next == nullptr) {
  312|      0|      if (level == 0) {
  313|      0|        return x;
  314|      0|      } else {
  315|      0|        // Switch to next list
  316|      0|        level--;
  317|      0|      }
  318|      0|    } else {
  319|      0|      x = next;
  320|      0|    }
  321|      0|  }
  322|      0|}
  323|       |
  324|       |template <typename Key, class Comparator>
  325|       |SkipList<Key, Comparator>::SkipList(Comparator cmp, Arena* arena)
  326|       |    : compare_(cmp),
  327|       |      arena_(arena),
  328|       |      head_(NewNode(0 /* any key will do */, kMaxHeight)),
  329|       |      max_height_(1),
  330|      0|      rnd_(0xdeadbeef) {
  331|      0|  for (int i = 0; i < kMaxHeight; i++) {
  332|      0|    head_->SetNext(i, nullptr);
  333|      0|  }
  334|      0|}
  335|       |
  336|       |template <typename Key, class Comparator>
  337|      0|void SkipList<Key, Comparator>::Insert(const Key& key) {
  338|      0|  // TODO(opt): We can use a barrier-free variant of FindGreaterOrEqual()
  339|      0|  // here since Insert() is externally synchronized.
  340|      0|  Node* prev[kMaxHeight];
  341|      0|  Node* x = FindGreaterOrEqual(key, prev);
  342|      0|
  343|      0|  // Our data structure does not allow duplicate insertion
  344|      0|  assert(x == nullptr || !Equal(key, x->key));
  345|      0|
  346|      0|  int height = RandomHeight();
  347|      0|  if (height > GetMaxHeight()) {
  348|      0|    for (int i = GetMaxHeight(); i < height; i++) {
  349|      0|      prev[i] = head_;
  350|      0|    }
  351|      0|    // It is ok to mutate max_height_ without any synchronization
  352|      0|    // with concurrent readers.  A concurrent reader that observes
  353|      0|    // the new value of max_height_ will see either the old value of
  354|      0|    // new level pointers from head_ (nullptr), or a new value set in
  355|      0|    // the loop below.  In the former case the reader will
  356|      0|    // immediately drop to the next level since nullptr sorts after all
  357|      0|    // keys.  In the latter case the reader will use the new node.
  358|      0|    max_height_.store(height, std::memory_order_relaxed);
  359|      0|  }
  360|      0|
  361|      0|  x = NewNode(key, height);
  362|      0|  for (int i = 0; i < height; i++) {
  363|      0|    // NoBarrier_SetNext() suffices since we will add a barrier when
  364|      0|    // we publish a pointer to "x" in prev[i].
  365|      0|    x->NoBarrier_SetNext(i, prev[i]->NoBarrier_Next(i));
  366|      0|    prev[i]->SetNext(i, x);
  367|      0|  }
  368|      0|}
  369|       |
  370|       |template <typename Key, class Comparator>
  371|       |bool SkipList<Key, Comparator>::Contains(const Key& key) const {
  372|       |  Node* x = FindGreaterOrEqual(key, nullptr);
  373|       |  if (x != nullptr && Equal(key, x->key)) {
  374|       |    return true;
  375|       |  } else {
  376|       |    return false;
  377|       |  }
  378|       |}
  379|       |
  380|       |}  // namespace leveldb
  381|       |
  382|       |#endif  // STORAGE_LEVELDB_DB_SKIPLIST_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/snapshot.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_DB_SNAPSHOT_H_
    6|       |#define STORAGE_LEVELDB_DB_SNAPSHOT_H_
    7|       |
    8|       |#include "db/dbformat.h"
    9|       |#include "leveldb/db.h"
   10|       |
   11|       |namespace leveldb {
   12|       |
   13|       |class SnapshotList;
   14|       |
   15|       |// Snapshots are kept in a doubly-linked list in the DB.
   16|       |// Each SnapshotImpl corresponds to a particular sequence number.
   17|       |class SnapshotImpl : public Snapshot {
   18|       | public:
   19|       |  SnapshotImpl(SequenceNumber sequence_number)
   20|      0|      : sequence_number_(sequence_number) {}
   21|       |
   22|      0|  SequenceNumber sequence_number() const { return sequence_number_; }
   23|       |
   24|       | private:
   25|       |  friend class SnapshotList;
   26|       |
   27|       |  // SnapshotImpl is kept in a doubly-linked circular list. The SnapshotList
   28|       |  // implementation operates on the next/previous fields direcly.
   29|       |  SnapshotImpl* prev_;
   30|       |  SnapshotImpl* next_;
   31|       |
   32|       |  const SequenceNumber sequence_number_;
   33|       |
   34|       |#if !defined(NDEBUG)
   35|       |  SnapshotList* list_ = nullptr;
   36|       |#endif  // !defined(NDEBUG)
   37|       |};
   38|       |
   39|       |class SnapshotList {
   40|       | public:
   41|      0|  SnapshotList() : head_(0) {
   42|      0|    head_.prev_ = &head_;
   43|      0|    head_.next_ = &head_;
   44|      0|  }
   45|       |
   46|      0|  bool empty() const { return head_.next_ == &head_; }
   47|      0|  SnapshotImpl* oldest() const {
   48|      0|    assert(!empty());
   49|      0|    return head_.next_;
   50|      0|  }
   51|      0|  SnapshotImpl* newest() const {
   52|      0|    assert(!empty());
   53|      0|    return head_.prev_;
   54|      0|  }
   55|       |
   56|       |  // Creates a SnapshotImpl and appends it to the end of the list.
   57|      0|  SnapshotImpl* New(SequenceNumber sequence_number) {
   58|      0|    assert(empty() || newest()->sequence_number_ <= sequence_number);
   59|      0|
   60|      0|    SnapshotImpl* snapshot = new SnapshotImpl(sequence_number);
   61|      0|
   62|      0|#if !defined(NDEBUG)
   63|      0|    snapshot->list_ = this;
   64|      0|#endif  // !defined(NDEBUG)
   65|      0|    snapshot->next_ = &head_;
   66|      0|    snapshot->prev_ = head_.prev_;
   67|      0|    snapshot->prev_->next_ = snapshot;
   68|      0|    snapshot->next_->prev_ = snapshot;
   69|      0|    return snapshot;
   70|      0|  }
   71|       |
   72|       |  // Removes a SnapshotImpl from this list.
   73|       |  //
   74|       |  // The snapshot must have been created by calling New() on this list.
   75|       |  //
   76|       |  // The snapshot pointer should not be const, because its memory is
   77|       |  // deallocated. However, that would force us to change DB::ReleaseSnapshot(),
   78|       |  // which is in the API, and currently takes a const Snapshot.
   79|      0|  void Delete(const SnapshotImpl* snapshot) {
   80|      0|#if !defined(NDEBUG)
   81|      0|    assert(snapshot->list_ == this);
   82|      0|#endif  // !defined(NDEBUG)
   83|      0|    snapshot->prev_->next_ = snapshot->next_;
   84|      0|    snapshot->next_->prev_ = snapshot->prev_;
   85|      0|    delete snapshot;
   86|      0|  }
   87|       |
   88|       | private:
   89|       |  // Dummy head of doubly-linked list of snapshots
   90|       |  SnapshotImpl head_;
   91|       |};
   92|       |
   93|       |}  // namespace leveldb
   94|       |
   95|       |#endif  // STORAGE_LEVELDB_DB_SNAPSHOT_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/table_cache.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/table_cache.h"
    6|       |
    7|       |#include "db/filename.h"
    8|       |#include "leveldb/env.h"
    9|       |#include "leveldb/table.h"
   10|       |#include "util/coding.h"
   11|       |
   12|       |namespace leveldb {
   13|       |
   14|       |struct TableAndFile {
   15|       |  RandomAccessFile* file;
   16|       |  Table* table;
   17|       |};
   18|       |
   19|      0|static void DeleteEntry(const Slice& key, void* value) {
   20|      0|  TableAndFile* tf = reinterpret_cast<TableAndFile*>(value);
   21|      0|  delete tf->table;
   22|      0|  delete tf->file;
   23|      0|  delete tf;
   24|      0|}
   25|       |
   26|      0|static void UnrefEntry(void* arg1, void* arg2) {
   27|      0|  Cache* cache = reinterpret_cast<Cache*>(arg1);
   28|      0|  Cache::Handle* h = reinterpret_cast<Cache::Handle*>(arg2);
   29|      0|  cache->Release(h);
   30|      0|}
   31|       |
   32|       |TableCache::TableCache(const std::string& dbname, const Options& options,
   33|       |                       int entries)
   34|       |    : env_(options.env),
   35|       |      dbname_(dbname),
   36|       |      options_(options),
   37|      0|      cache_(NewLRUCache(entries)) {}
   38|       |
   39|      0|TableCache::~TableCache() { delete cache_; }
   40|       |
   41|       |Status TableCache::FindTable(uint64_t file_number, uint64_t file_size,
   42|      0|                             Cache::Handle** handle) {
   43|      0|  Status s;
   44|      0|  char buf[sizeof(file_number)];
   45|      0|  EncodeFixed64(buf, file_number);
   46|      0|  Slice key(buf, sizeof(buf));
   47|      0|  *handle = cache_->Lookup(key);
   48|      0|  if (*handle == nullptr) {
   49|      0|    std::string fname = TableFileName(dbname_, file_number);
   50|      0|    RandomAccessFile* file = nullptr;
   51|      0|    Table* table = nullptr;
   52|      0|    s = env_->NewRandomAccessFile(fname, &file);
   53|      0|    if (!s.ok()) {
   54|      0|      std::string old_fname = SSTTableFileName(dbname_, file_number);
   55|      0|      if (env_->NewRandomAccessFile(old_fname, &file).ok()) {
   56|      0|        s = Status::OK();
   57|      0|      }
   58|      0|    }
   59|      0|    if (s.ok()) {
   60|      0|      s = Table::Open(options_, file, file_size, &table);
   61|      0|    }
   62|      0|
   63|      0|    if (!s.ok()) {
   64|      0|      assert(table == nullptr);
   65|      0|      delete file;
   66|      0|      // We do not cache error results so that if the error is transient,
   67|      0|      // or somebody repairs the file, we recover automatically.
   68|      0|    } else {
   69|      0|      TableAndFile* tf = new TableAndFile;
   70|      0|      tf->file = file;
   71|      0|      tf->table = table;
   72|      0|      *handle = cache_->Insert(key, tf, 1, &DeleteEntry);
   73|      0|    }
   74|      0|  }
   75|      0|  return s;
   76|      0|}
   77|       |
   78|       |Iterator* TableCache::NewIterator(const ReadOptions& options,
   79|       |                                  uint64_t file_number, uint64_t file_size,
   80|      0|                                  Table** tableptr) {
   81|      0|  if (tableptr != nullptr) {
   82|      0|    *tableptr = nullptr;
   83|      0|  }
   84|      0|
   85|      0|  Cache::Handle* handle = nullptr;
   86|      0|  Status s = FindTable(file_number, file_size, &handle);
   87|      0|  if (!s.ok()) {
   88|      0|    return NewErrorIterator(s);
   89|      0|  }
   90|      0|
   91|      0|  Table* table = reinterpret_cast<TableAndFile*>(cache_->Value(handle))->table;
   92|      0|  Iterator* result = table->NewIterator(options);
   93|      0|  result->RegisterCleanup(&UnrefEntry, cache_, handle);
   94|      0|  if (tableptr != nullptr) {
   95|      0|    *tableptr = table;
   96|      0|  }
   97|      0|  return result;
   98|      0|}
   99|       |
  100|       |Status TableCache::Get(const ReadOptions& options, uint64_t file_number,
  101|       |                       uint64_t file_size, const Slice& k, void* arg,
  102|       |                       void (*handle_result)(void*, const Slice&,
  103|      0|                                             const Slice&)) {
  104|      0|  Cache::Handle* handle = nullptr;
  105|      0|  Status s = FindTable(file_number, file_size, &handle);
  106|      0|  if (s.ok()) {
  107|      0|    Table* t = reinterpret_cast<TableAndFile*>(cache_->Value(handle))->table;
  108|      0|    s = t->InternalGet(options, k, arg, handle_result);
  109|      0|    cache_->Release(handle);
  110|      0|  }
  111|      0|  return s;
  112|      0|}
  113|       |
  114|      0|void TableCache::Evict(uint64_t file_number) {
  115|      0|  char buf[sizeof(file_number)];
  116|      0|  EncodeFixed64(buf, file_number);
  117|      0|  cache_->Erase(Slice(buf, sizeof(buf)));
  118|      0|}
  119|       |
  120|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/version_edit.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/version_edit.h"
    6|       |
    7|       |#include "db/version_set.h"
    8|       |#include "util/coding.h"
    9|       |
   10|       |namespace leveldb {
   11|       |
   12|       |// Tag numbers for serialized VersionEdit.  These numbers are written to
   13|       |// disk and should not be changed.
   14|       |enum Tag {
   15|       |  kComparator = 1,
   16|       |  kLogNumber = 2,
   17|       |  kNextFileNumber = 3,
   18|       |  kLastSequence = 4,
   19|       |  kCompactPointer = 5,
   20|       |  kDeletedFile = 6,
   21|       |  kNewFile = 7,
   22|       |  // 8 was used for large value refs
   23|       |  kPrevLogNumber = 9
   24|       |};
   25|       |
   26|      0|void VersionEdit::Clear() {
   27|      0|  comparator_.clear();
   28|      0|  log_number_ = 0;
   29|      0|  prev_log_number_ = 0;
   30|      0|  last_sequence_ = 0;
   31|      0|  next_file_number_ = 0;
   32|      0|  has_comparator_ = false;
   33|      0|  has_log_number_ = false;
   34|      0|  has_prev_log_number_ = false;
   35|      0|  has_next_file_number_ = false;
   36|      0|  has_last_sequence_ = false;
   37|      0|  deleted_files_.clear();
   38|      0|  new_files_.clear();
   39|      0|}
   40|       |
   41|      0|void VersionEdit::EncodeTo(std::string* dst) const {
   42|      0|  if (has_comparator_) {
   43|      0|    PutVarint32(dst, kComparator);
   44|      0|    PutLengthPrefixedSlice(dst, comparator_);
   45|      0|  }
   46|      0|  if (has_log_number_) {
   47|      0|    PutVarint32(dst, kLogNumber);
   48|      0|    PutVarint64(dst, log_number_);
   49|      0|  }
   50|      0|  if (has_prev_log_number_) {
   51|      0|    PutVarint32(dst, kPrevLogNumber);
   52|      0|    PutVarint64(dst, prev_log_number_);
   53|      0|  }
   54|      0|  if (has_next_file_number_) {
   55|      0|    PutVarint32(dst, kNextFileNumber);
   56|      0|    PutVarint64(dst, next_file_number_);
   57|      0|  }
   58|      0|  if (has_last_sequence_) {
   59|      0|    PutVarint32(dst, kLastSequence);
   60|      0|    PutVarint64(dst, last_sequence_);
   61|      0|  }
   62|      0|
   63|      0|  for (size_t i = 0; i < compact_pointers_.size(); i++) {
   64|      0|    PutVarint32(dst, kCompactPointer);
   65|      0|    PutVarint32(dst, compact_pointers_[i].first);  // level
   66|      0|    PutLengthPrefixedSlice(dst, compact_pointers_[i].second.Encode());
   67|      0|  }
   68|      0|
   69|      0|  for (DeletedFileSet::const_iterator iter = deleted_files_.begin();
   70|      0|       iter != deleted_files_.end(); ++iter) {
   71|      0|    PutVarint32(dst, kDeletedFile);
   72|      0|    PutVarint32(dst, iter->first);   // level
   73|      0|    PutVarint64(dst, iter->second);  // file number
   74|      0|  }
   75|      0|
   76|      0|  for (size_t i = 0; i < new_files_.size(); i++) {
   77|      0|    const FileMetaData& f = new_files_[i].second;
   78|      0|    PutVarint32(dst, kNewFile);
   79|      0|    PutVarint32(dst, new_files_[i].first);  // level
   80|      0|    PutVarint64(dst, f.number);
   81|      0|    PutVarint64(dst, f.file_size);
   82|      0|    PutLengthPrefixedSlice(dst, f.smallest.Encode());
   83|      0|    PutLengthPrefixedSlice(dst, f.largest.Encode());
   84|      0|  }
   85|      0|}
   86|       |
   87|      0|static bool GetInternalKey(Slice* input, InternalKey* dst) {
   88|      0|  Slice str;
   89|      0|  if (GetLengthPrefixedSlice(input, &str)) {
   90|      0|    dst->DecodeFrom(str);
   91|      0|    return true;
   92|      0|  } else {
   93|      0|    return false;
   94|      0|  }
   95|      0|}
   96|       |
   97|      0|static bool GetLevel(Slice* input, int* level) {
   98|      0|  uint32_t v;
   99|      0|  if (GetVarint32(input, &v) && v < config::kNumLevels) {
  100|      0|    *level = v;
  101|      0|    return true;
  102|      0|  } else {
  103|      0|    return false;
  104|      0|  }
  105|      0|}
  106|       |
  107|      0|Status VersionEdit::DecodeFrom(const Slice& src) {
  108|      0|  Clear();
  109|      0|  Slice input = src;
  110|      0|  const char* msg = nullptr;
  111|      0|  uint32_t tag;
  112|      0|
  113|      0|  // Temporary storage for parsing
  114|      0|  int level;
  115|      0|  uint64_t number;
  116|      0|  FileMetaData f;
  117|      0|  Slice str;
  118|      0|  InternalKey key;
  119|      0|
  120|      0|  while (msg == nullptr && GetVarint32(&input, &tag)) {
  121|      0|    switch (tag) {
  122|      0|      case kComparator:
  123|      0|        if (GetLengthPrefixedSlice(&input, &str)) {
  124|      0|          comparator_ = str.ToString();
  125|      0|          has_comparator_ = true;
  126|      0|        } else {
  127|      0|          msg = "comparator name";
  128|      0|        }
  129|      0|        break;
  130|      0|
  131|      0|      case kLogNumber:
  132|      0|        if (GetVarint64(&input, &log_number_)) {
  133|      0|          has_log_number_ = true;
  134|      0|        } else {
  135|      0|          msg = "log number";
  136|      0|        }
  137|      0|        break;
  138|      0|
  139|      0|      case kPrevLogNumber:
  140|      0|        if (GetVarint64(&input, &prev_log_number_)) {
  141|      0|          has_prev_log_number_ = true;
  142|      0|        } else {
  143|      0|          msg = "previous log number";
  144|      0|        }
  145|      0|        break;
  146|      0|
  147|      0|      case kNextFileNumber:
  148|      0|        if (GetVarint64(&input, &next_file_number_)) {
  149|      0|          has_next_file_number_ = true;
  150|      0|        } else {
  151|      0|          msg = "next file number";
  152|      0|        }
  153|      0|        break;
  154|      0|
  155|      0|      case kLastSequence:
  156|      0|        if (GetVarint64(&input, &last_sequence_)) {
  157|      0|          has_last_sequence_ = true;
  158|      0|        } else {
  159|      0|          msg = "last sequence number";
  160|      0|        }
  161|      0|        break;
  162|      0|
  163|      0|      case kCompactPointer:
  164|      0|        if (GetLevel(&input, &level) && GetInternalKey(&input, &key)) {
  165|      0|          compact_pointers_.push_back(std::make_pair(level, key));
  166|      0|        } else {
  167|      0|          msg = "compaction pointer";
  168|      0|        }
  169|      0|        break;
  170|      0|
  171|      0|      case kDeletedFile:
  172|      0|        if (GetLevel(&input, &level) && GetVarint64(&input, &number)) {
  173|      0|          deleted_files_.insert(std::make_pair(level, number));
  174|      0|        } else {
  175|      0|          msg = "deleted file";
  176|      0|        }
  177|      0|        break;
  178|      0|
  179|      0|      case kNewFile:
  180|      0|        if (GetLevel(&input, &level) && GetVarint64(&input, &f.number) &&
  181|      0|            GetVarint64(&input, &f.file_size) &&
  182|      0|            GetInternalKey(&input, &f.smallest) &&
  183|      0|            GetInternalKey(&input, &f.largest)) {
  184|      0|          new_files_.push_back(std::make_pair(level, f));
  185|      0|        } else {
  186|      0|          msg = "new-file entry";
  187|      0|        }
  188|      0|        break;
  189|      0|
  190|      0|      default:
  191|      0|        msg = "unknown tag";
  192|      0|        break;
  193|      0|    }
  194|      0|  }
  195|      0|
  196|      0|  if (msg == nullptr && !input.empty()) {
  197|      0|    msg = "invalid tag";
  198|      0|  }
  199|      0|
  200|      0|  Status result;
  201|      0|  if (msg != nullptr) {
  202|      0|    result = Status::Corruption("VersionEdit", msg);
  203|      0|  }
  204|      0|  return result;
  205|      0|}
  206|       |
  207|      0|std::string VersionEdit::DebugString() const {
  208|      0|  std::string r;
  209|      0|  r.append("VersionEdit {");
  210|      0|  if (has_comparator_) {
  211|      0|    r.append("\n  Comparator: ");
  212|      0|    r.append(comparator_);
  213|      0|  }
  214|      0|  if (has_log_number_) {
  215|      0|    r.append("\n  LogNumber: ");
  216|      0|    AppendNumberTo(&r, log_number_);
  217|      0|  }
  218|      0|  if (has_prev_log_number_) {
  219|      0|    r.append("\n  PrevLogNumber: ");
  220|      0|    AppendNumberTo(&r, prev_log_number_);
  221|      0|  }
  222|      0|  if (has_next_file_number_) {
  223|      0|    r.append("\n  NextFile: ");
  224|      0|    AppendNumberTo(&r, next_file_number_);
  225|      0|  }
  226|      0|  if (has_last_sequence_) {
  227|      0|    r.append("\n  LastSeq: ");
  228|      0|    AppendNumberTo(&r, last_sequence_);
  229|      0|  }
  230|      0|  for (size_t i = 0; i < compact_pointers_.size(); i++) {
  231|      0|    r.append("\n  CompactPointer: ");
  232|      0|    AppendNumberTo(&r, compact_pointers_[i].first);
  233|      0|    r.append(" ");
  234|      0|    r.append(compact_pointers_[i].second.DebugString());
  235|      0|  }
  236|      0|  for (DeletedFileSet::const_iterator iter = deleted_files_.begin();
  237|      0|       iter != deleted_files_.end(); ++iter) {
  238|      0|    r.append("\n  DeleteFile: ");
  239|      0|    AppendNumberTo(&r, iter->first);
  240|      0|    r.append(" ");
  241|      0|    AppendNumberTo(&r, iter->second);
  242|      0|  }
  243|      0|  for (size_t i = 0; i < new_files_.size(); i++) {
  244|      0|    const FileMetaData& f = new_files_[i].second;
  245|      0|    r.append("\n  AddFile: ");
  246|      0|    AppendNumberTo(&r, new_files_[i].first);
  247|      0|    r.append(" ");
  248|      0|    AppendNumberTo(&r, f.number);
  249|      0|    r.append(" ");
  250|      0|    AppendNumberTo(&r, f.file_size);
  251|      0|    r.append(" ");
  252|      0|    r.append(f.smallest.DebugString());
  253|      0|    r.append(" .. ");
  254|      0|    r.append(f.largest.DebugString());
  255|      0|  }
  256|      0|  r.append("\n}\n");
  257|      0|  return r;
  258|      0|}
  259|       |
  260|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/version_edit.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_DB_VERSION_EDIT_H_
    6|       |#define STORAGE_LEVELDB_DB_VERSION_EDIT_H_
    7|       |
    8|       |#include <set>
    9|       |#include <utility>
   10|       |#include <vector>
   11|       |
   12|       |#include "db/dbformat.h"
   13|       |
   14|       |namespace leveldb {
   15|       |
   16|       |class VersionSet;
   17|       |
   18|       |struct FileMetaData {
   19|      0|  FileMetaData() : refs(0), allowed_seeks(1 << 30), file_size(0) {}
   20|       |
   21|       |  int refs;
   22|       |  int allowed_seeks;  // Seeks allowed until compaction
   23|       |  uint64_t number;
   24|       |  uint64_t file_size;    // File size in bytes
   25|       |  InternalKey smallest;  // Smallest internal key served by table
   26|       |  InternalKey largest;   // Largest internal key served by table
   27|       |};
   28|       |
   29|       |class VersionEdit {
   30|       | public:
   31|      0|  VersionEdit() { Clear(); }
   32|      0|  ~VersionEdit() {}
   33|       |
   34|       |  void Clear();
   35|       |
   36|      0|  void SetComparatorName(const Slice& name) {
   37|      0|    has_comparator_ = true;
   38|      0|    comparator_ = name.ToString();
   39|      0|  }
   40|      0|  void SetLogNumber(uint64_t num) {
   41|      0|    has_log_number_ = true;
   42|      0|    log_number_ = num;
   43|      0|  }
   44|      0|  void SetPrevLogNumber(uint64_t num) {
   45|      0|    has_prev_log_number_ = true;
   46|      0|    prev_log_number_ = num;
   47|      0|  }
   48|      0|  void SetNextFile(uint64_t num) {
   49|      0|    has_next_file_number_ = true;
   50|      0|    next_file_number_ = num;
   51|      0|  }
   52|      0|  void SetLastSequence(SequenceNumber seq) {
   53|      0|    has_last_sequence_ = true;
   54|      0|    last_sequence_ = seq;
   55|      0|  }
   56|      0|  void SetCompactPointer(int level, const InternalKey& key) {
   57|      0|    compact_pointers_.push_back(std::make_pair(level, key));
   58|      0|  }
   59|       |
   60|       |  // Add the specified file at the specified number.
   61|       |  // REQUIRES: This version has not been saved (see VersionSet::SaveTo)
   62|       |  // REQUIRES: "smallest" and "largest" are smallest and largest keys in file
   63|       |  void AddFile(int level, uint64_t file, uint64_t file_size,
   64|      0|               const InternalKey& smallest, const InternalKey& largest) {
   65|      0|    FileMetaData f;
   66|      0|    f.number = file;
   67|      0|    f.file_size = file_size;
   68|      0|    f.smallest = smallest;
   69|      0|    f.largest = largest;
   70|      0|    new_files_.push_back(std::make_pair(level, f));
   71|      0|  }
   72|       |
   73|       |  // Delete the specified "file" from the specified "level".
   74|      0|  void DeleteFile(int level, uint64_t file) {
   75|      0|    deleted_files_.insert(std::make_pair(level, file));
   76|      0|  }
   77|       |
   78|       |  void EncodeTo(std::string* dst) const;
   79|       |  Status DecodeFrom(const Slice& src);
   80|       |
   81|       |  std::string DebugString() const;
   82|       |
   83|       | private:
   84|       |  friend class VersionSet;
   85|       |
   86|       |  typedef std::set<std::pair<int, uint64_t> > DeletedFileSet;
   87|       |
   88|       |  std::string comparator_;
   89|       |  uint64_t log_number_;
   90|       |  uint64_t prev_log_number_;
   91|       |  uint64_t next_file_number_;
   92|       |  SequenceNumber last_sequence_;
   93|       |  bool has_comparator_;
   94|       |  bool has_log_number_;
   95|       |  bool has_prev_log_number_;
   96|       |  bool has_next_file_number_;
   97|       |  bool has_last_sequence_;
   98|       |
   99|       |  std::vector<std::pair<int, InternalKey> > compact_pointers_;
  100|       |  DeletedFileSet deleted_files_;
  101|       |  std::vector<std::pair<int, FileMetaData> > new_files_;
  102|       |};
  103|       |
  104|       |}  // namespace leveldb
  105|       |
  106|       |#endif  // STORAGE_LEVELDB_DB_VERSION_EDIT_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/version_set.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "db/version_set.h"
    6|       |
    7|       |#include <stdio.h>
    8|       |
    9|       |#include <algorithm>
   10|       |
   11|       |#include "db/filename.h"
   12|       |#include "db/log_reader.h"
   13|       |#include "db/log_writer.h"
   14|       |#include "db/memtable.h"
   15|       |#include "db/table_cache.h"
   16|       |#include "leveldb/env.h"
   17|       |#include "leveldb/table_builder.h"
   18|       |#include "table/merger.h"
   19|       |#include "table/two_level_iterator.h"
   20|       |#include "util/coding.h"
   21|       |#include "util/logging.h"
   22|       |
   23|       |namespace leveldb {
   24|       |
   25|      0|static size_t TargetFileSize(const Options* options) {
   26|      0|  return options->max_file_size;
   27|      0|}
   28|       |
   29|       |// Maximum bytes of overlaps in grandparent (i.e., level+2) before we
   30|       |// stop building a single file in a level->level+1 compaction.
   31|      0|static int64_t MaxGrandParentOverlapBytes(const Options* options) {
   32|      0|  return 10 * TargetFileSize(options);
   33|      0|}
   34|       |
   35|       |// Maximum number of bytes in all compacted files.  We avoid expanding
   36|       |// the lower level file set of a compaction if it would make the
   37|       |// total compaction cover more than this many bytes.
   38|      0|static int64_t ExpandedCompactionByteSizeLimit(const Options* options) {
   39|      0|  return 25 * TargetFileSize(options);
   40|      0|}
   41|       |
   42|      0|static double MaxBytesForLevel(const Options* options, int level) {
   43|      0|  // Note: the result for level zero is not really used since we set
   44|      0|  // the level-0 compaction threshold based on number of files.
   45|      0|
   46|      0|  // Result for both level-0 and level-1
   47|      0|  double result = 10. * 1048576.0;
   48|      0|  while (level > 1) {
   49|      0|    result *= 10;
   50|      0|    level--;
   51|      0|  }
   52|      0|  return result;
   53|      0|}
   54|       |
   55|      0|static uint64_t MaxFileSizeForLevel(const Options* options, int level) {
   56|      0|  // We could vary per level to reduce number of files?
   57|      0|  return TargetFileSize(options);
   58|      0|}
   59|       |
   60|      0|static int64_t TotalFileSize(const std::vector<FileMetaData*>& files) {
   61|      0|  int64_t sum = 0;
   62|      0|  for (size_t i = 0; i < files.size(); i++) {
   63|      0|    sum += files[i]->file_size;
   64|      0|  }
   65|      0|  return sum;
   66|      0|}
   67|       |
   68|      0|Version::~Version() {
   69|      0|  assert(refs_ == 0);
   70|      0|
   71|      0|  // Remove from linked list
   72|      0|  prev_->next_ = next_;
   73|      0|  next_->prev_ = prev_;
   74|      0|
   75|      0|  // Drop references to files
   76|      0|  for (int level = 0; level < config::kNumLevels; level++) {
   77|      0|    for (size_t i = 0; i < files_[level].size(); i++) {
   78|      0|      FileMetaData* f = files_[level][i];
   79|      0|      assert(f->refs > 0);
   80|      0|      f->refs--;
   81|      0|      if (f->refs <= 0) {
   82|      0|        delete f;
   83|      0|      }
   84|      0|    }
   85|      0|  }
   86|      0|}
   87|       |
   88|       |int FindFile(const InternalKeyComparator& icmp,
   89|      0|             const std::vector<FileMetaData*>& files, const Slice& key) {
   90|      0|  uint32_t left = 0;
   91|      0|  uint32_t right = files.size();
   92|      0|  while (left < right) {
   93|      0|    uint32_t mid = (left + right) / 2;
   94|      0|    const FileMetaData* f = files[mid];
   95|      0|    if (icmp.InternalKeyComparator::Compare(f->largest.Encode(), key) < 0) {
   96|      0|      // Key at "mid.largest" is < "target".  Therefore all
   97|      0|      // files at or before "mid" are uninteresting.
   98|      0|      left = mid + 1;
   99|      0|    } else {
  100|      0|      // Key at "mid.largest" is >= "target".  Therefore all files
  101|      0|      // after "mid" are uninteresting.
  102|      0|      right = mid;
  103|      0|    }
  104|      0|  }
  105|      0|  return right;
  106|      0|}
  107|       |
  108|       |static bool AfterFile(const Comparator* ucmp, const Slice* user_key,
  109|      0|                      const FileMetaData* f) {
  110|      0|  // null user_key occurs before all keys and is therefore never after *f
  111|      0|  return (user_key != nullptr &&
  112|      0|          ucmp->Compare(*user_key, f->largest.user_key()) > 0);
  113|      0|}
  114|       |
  115|       |static bool BeforeFile(const Comparator* ucmp, const Slice* user_key,
  116|      0|                       const FileMetaData* f) {
  117|      0|  // null user_key occurs after all keys and is therefore never before *f
  118|      0|  return (user_key != nullptr &&
  119|      0|          ucmp->Compare(*user_key, f->smallest.user_key()) < 0);
  120|      0|}
  121|       |
  122|       |bool SomeFileOverlapsRange(const InternalKeyComparator& icmp,
  123|       |                           bool disjoint_sorted_files,
  124|       |                           const std::vector<FileMetaData*>& files,
  125|       |                           const Slice* smallest_user_key,
  126|      0|                           const Slice* largest_user_key) {
  127|      0|  const Comparator* ucmp = icmp.user_comparator();
  128|      0|  if (!disjoint_sorted_files) {
  129|      0|    // Need to check against all files
  130|      0|    for (size_t i = 0; i < files.size(); i++) {
  131|      0|      const FileMetaData* f = files[i];
  132|      0|      if (AfterFile(ucmp, smallest_user_key, f) ||
  133|      0|          BeforeFile(ucmp, largest_user_key, f)) {
  134|      0|        // No overlap
  135|      0|      } else {
  136|      0|        return true;  // Overlap
  137|      0|      }
  138|      0|    }
  139|      0|    return false;
  140|      0|  }
  141|      0|
  142|      0|  // Binary search over file list
  143|      0|  uint32_t index = 0;
  144|      0|  if (smallest_user_key != nullptr) {
  145|      0|    // Find the earliest possible internal key for smallest_user_key
  146|      0|    InternalKey small_key(*smallest_user_key, kMaxSequenceNumber,
  147|      0|                          kValueTypeForSeek);
  148|      0|    index = FindFile(icmp, files, small_key.Encode());
  149|      0|  }
  150|      0|
  151|      0|  if (index >= files.size()) {
  152|      0|    // beginning of range is after all files, so no overlap.
  153|      0|    return false;
  154|      0|  }
  155|      0|
  156|      0|  return !BeforeFile(ucmp, largest_user_key, files[index]);
  157|      0|}
  158|       |
  159|       |// An internal iterator.  For a given version/level pair, yields
  160|       |// information about the files in the level.  For a given entry, key()
  161|       |// is the largest key that occurs in the file, and value() is an
  162|       |// 16-byte value containing the file number and file size, both
  163|       |// encoded using EncodeFixed64.
  164|       |class Version::LevelFileNumIterator : public Iterator {
  165|       | public:
  166|       |  LevelFileNumIterator(const InternalKeyComparator& icmp,
  167|       |                       const std::vector<FileMetaData*>* flist)
  168|      0|      : icmp_(icmp), flist_(flist), index_(flist->size()) {  // Marks as invalid
  169|      0|  }
  170|      0|  virtual bool Valid() const { return index_ < flist_->size(); }
  171|      0|  virtual void Seek(const Slice& target) {
  172|      0|    index_ = FindFile(icmp_, *flist_, target);
  173|      0|  }
  174|      0|  virtual void SeekToFirst() { index_ = 0; }
  175|      0|  virtual void SeekToLast() {
  176|      0|    index_ = flist_->empty() ? 0 : flist_->size() - 1;
  177|      0|  }
  178|      0|  virtual void Next() {
  179|      0|    assert(Valid());
  180|      0|    index_++;
  181|      0|  }
  182|      0|  virtual void Prev() {
  183|      0|    assert(Valid());
  184|      0|    if (index_ == 0) {
  185|      0|      index_ = flist_->size();  // Marks as invalid
  186|      0|    } else {
  187|      0|      index_--;
  188|      0|    }
  189|      0|  }
  190|      0|  Slice key() const {
  191|      0|    assert(Valid());
  192|      0|    return (*flist_)[index_]->largest.Encode();
  193|      0|  }
  194|      0|  Slice value() const {
  195|      0|    assert(Valid());
  196|      0|    EncodeFixed64(value_buf_, (*flist_)[index_]->number);
  197|      0|    EncodeFixed64(value_buf_ + 8, (*flist_)[index_]->file_size);
  198|      0|    return Slice(value_buf_, sizeof(value_buf_));
  199|      0|  }
  200|      0|  virtual Status status() const { return Status::OK(); }
  201|       |
  202|       | private:
  203|       |  const InternalKeyComparator icmp_;
  204|       |  const std::vector<FileMetaData*>* const flist_;
  205|       |  uint32_t index_;
  206|       |
  207|       |  // Backing store for value().  Holds the file number and size.
  208|       |  mutable char value_buf_[16];
  209|       |};
  210|       |
  211|       |static Iterator* GetFileIterator(void* arg, const ReadOptions& options,
  212|      0|                                 const Slice& file_value) {
  213|      0|  TableCache* cache = reinterpret_cast<TableCache*>(arg);
  214|      0|  if (file_value.size() != 16) {
  215|      0|    return NewErrorIterator(
  216|      0|        Status::Corruption("FileReader invoked with unexpected value"));
  217|      0|  } else {
  218|      0|    return cache->NewIterator(options, DecodeFixed64(file_value.data()),
  219|      0|                              DecodeFixed64(file_value.data() + 8));
  220|      0|  }
  221|      0|}
  222|       |
  223|       |Iterator* Version::NewConcatenatingIterator(const ReadOptions& options,
  224|      0|                                            int level) const {
  225|      0|  return NewTwoLevelIterator(
  226|      0|      new LevelFileNumIterator(vset_->icmp_, &files_[level]), &GetFileIterator,
  227|      0|      vset_->table_cache_, options);
  228|      0|}
  229|       |
  230|       |void Version::AddIterators(const ReadOptions& options,
  231|      0|                           std::vector<Iterator*>* iters) {
  232|      0|  // Merge all level zero files together since they may overlap
  233|      0|  for (size_t i = 0; i < files_[0].size(); i++) {
  234|      0|    iters->push_back(vset_->table_cache_->NewIterator(
  235|      0|        options, files_[0][i]->number, files_[0][i]->file_size));
  236|      0|  }
  237|      0|
  238|      0|  // For levels > 0, we can use a concatenating iterator that sequentially
  239|      0|  // walks through the non-overlapping files in the level, opening them
  240|      0|  // lazily.
  241|      0|  for (int level = 1; level < config::kNumLevels; level++) {
  242|      0|    if (!files_[level].empty()) {
  243|      0|      iters->push_back(NewConcatenatingIterator(options, level));
  244|      0|    }
  245|      0|  }
  246|      0|}
  247|       |
  248|       |// Callback from TableCache::Get()
  249|       |namespace {
  250|       |enum SaverState {
  251|       |  kNotFound,
  252|       |  kFound,
  253|       |  kDeleted,
  254|       |  kCorrupt,
  255|       |};
  256|       |struct Saver {
  257|       |  SaverState state;
  258|       |  const Comparator* ucmp;
  259|       |  Slice user_key;
  260|       |  std::string* value;
  261|       |};
  262|       |}  // namespace
  263|      0|static void SaveValue(void* arg, const Slice& ikey, const Slice& v) {
  264|      0|  Saver* s = reinterpret_cast<Saver*>(arg);
  265|      0|  ParsedInternalKey parsed_key;
  266|      0|  if (!ParseInternalKey(ikey, &parsed_key)) {
  267|      0|    s->state = kCorrupt;
  268|      0|  } else {
  269|      0|    if (s->ucmp->Compare(parsed_key.user_key, s->user_key) == 0) {
  270|      0|      s->state = (parsed_key.type == kTypeValue) ? kFound : kDeleted;
  271|      0|      if (s->state == kFound) {
  272|      0|        s->value->assign(v.data(), v.size());
  273|      0|      }
  274|      0|    }
  275|      0|  }
  276|      0|}
  277|       |
  278|      0|static bool NewestFirst(FileMetaData* a, FileMetaData* b) {
  279|      0|  return a->number > b->number;
  280|      0|}
  281|       |
  282|       |void Version::ForEachOverlapping(Slice user_key, Slice internal_key, void* arg,
  283|      0|                                 bool (*func)(void*, int, FileMetaData*)) {
  284|      0|  // TODO(sanjay): Change Version::Get() to use this function.
  285|      0|  const Comparator* ucmp = vset_->icmp_.user_comparator();
  286|      0|
  287|      0|  // Search level-0 in order from newest to oldest.
  288|      0|  std::vector<FileMetaData*> tmp;
  289|      0|  tmp.reserve(files_[0].size());
  290|      0|  for (uint32_t i = 0; i < files_[0].size(); i++) {
  291|      0|    FileMetaData* f = files_[0][i];
  292|      0|    if (ucmp->Compare(user_key, f->smallest.user_key()) >= 0 &&
  293|      0|        ucmp->Compare(user_key, f->largest.user_key()) <= 0) {
  294|      0|      tmp.push_back(f);
  295|      0|    }
  296|      0|  }
  297|      0|  if (!tmp.empty()) {
  298|      0|    std::sort(tmp.begin(), tmp.end(), NewestFirst);
  299|      0|    for (uint32_t i = 0; i < tmp.size(); i++) {
  300|      0|      if (!(*func)(arg, 0, tmp[i])) {
  301|      0|        return;
  302|      0|      }
  303|      0|    }
  304|      0|  }
  305|      0|
  306|      0|  // Search other levels.
  307|      0|  for (int level = 1; level < config::kNumLevels; level++) {
  308|      0|    size_t num_files = files_[level].size();
  309|      0|    if (num_files == 0) continue;
  310|      0|
  311|      0|    // Binary search to find earliest index whose largest key >= internal_key.
  312|      0|    uint32_t index = FindFile(vset_->icmp_, files_[level], internal_key);
  313|      0|    if (index < num_files) {
  314|      0|      FileMetaData* f = files_[level][index];
  315|      0|      if (ucmp->Compare(user_key, f->smallest.user_key()) < 0) {
  316|      0|        // All of "f" is past any data for user_key
  317|      0|      } else {
  318|      0|        if (!(*func)(arg, level, f)) {
  319|      0|          return;
  320|      0|        }
  321|      0|      }
  322|      0|    }
  323|      0|  }
  324|      0|}
  325|       |
  326|       |Status Version::Get(const ReadOptions& options, const LookupKey& k,
  327|      0|                    std::string* value, GetStats* stats) {
  328|      0|  Slice ikey = k.internal_key();
  329|      0|  Slice user_key = k.user_key();
  330|      0|  const Comparator* ucmp = vset_->icmp_.user_comparator();
  331|      0|  Status s;
  332|      0|
  333|      0|  stats->seek_file = nullptr;
  334|      0|  stats->seek_file_level = -1;
  335|      0|  FileMetaData* last_file_read = nullptr;
  336|      0|  int last_file_read_level = -1;
  337|      0|
  338|      0|  // We can search level-by-level since entries never hop across
  339|      0|  // levels.  Therefore we are guaranteed that if we find data
  340|      0|  // in a smaller level, later levels are irrelevant.
  341|      0|  std::vector<FileMetaData*> tmp;
  342|      0|  FileMetaData* tmp2;
  343|      0|  for (int level = 0; level < config::kNumLevels; level++) {
  344|      0|    size_t num_files = files_[level].size();
  345|      0|    if (num_files == 0) continue;
  346|      0|
  347|      0|    // Get the list of files to search in this level
  348|      0|    FileMetaData* const* files = &files_[level][0];
  349|      0|    if (level == 0) {
  350|      0|      // Level-0 files may overlap each other.  Find all files that
  351|      0|      // overlap user_key and process them in order from newest to oldest.
  352|      0|      tmp.reserve(num_files);
  353|      0|      for (uint32_t i = 0; i < num_files; i++) {
  354|      0|        FileMetaData* f = files[i];
  355|      0|        if (ucmp->Compare(user_key, f->smallest.user_key()) >= 0 &&
  356|      0|            ucmp->Compare(user_key, f->largest.user_key()) <= 0) {
  357|      0|          tmp.push_back(f);
  358|      0|        }
  359|      0|      }
  360|      0|      if (tmp.empty()) continue;
  361|      0|
  362|      0|      std::sort(tmp.begin(), tmp.end(), NewestFirst);
  363|      0|      files = &tmp[0];
  364|      0|      num_files = tmp.size();
  365|      0|    } else {
  366|      0|      // Binary search to find earliest index whose largest key >= ikey.
  367|      0|      uint32_t index = FindFile(vset_->icmp_, files_[level], ikey);
  368|      0|      if (index >= num_files) {
  369|      0|        files = nullptr;
  370|      0|        num_files = 0;
  371|      0|      } else {
  372|      0|        tmp2 = files[index];
  373|      0|        if (ucmp->Compare(user_key, tmp2->smallest.user_key()) < 0) {
  374|      0|          // All of "tmp2" is past any data for user_key
  375|      0|          files = nullptr;
  376|      0|          num_files = 0;
  377|      0|        } else {
  378|      0|          files = &tmp2;
  379|      0|          num_files = 1;
  380|      0|        }
  381|      0|      }
  382|      0|    }
  383|      0|
  384|      0|    for (uint32_t i = 0; i < num_files; ++i) {
  385|      0|      if (last_file_read != nullptr && stats->seek_file == nullptr) {
  386|      0|        // We have had more than one seek for this read.  Charge the 1st file.
  387|      0|        stats->seek_file = last_file_read;
  388|      0|        stats->seek_file_level = last_file_read_level;
  389|      0|      }
  390|      0|
  391|      0|      FileMetaData* f = files[i];
  392|      0|      last_file_read = f;
  393|      0|      last_file_read_level = level;
  394|      0|
  395|      0|      Saver saver;
  396|      0|      saver.state = kNotFound;
  397|      0|      saver.ucmp = ucmp;
  398|      0|      saver.user_key = user_key;
  399|      0|      saver.value = value;
  400|      0|      s = vset_->table_cache_->Get(options, f->number, f->file_size, ikey,
  401|      0|                                   &saver, SaveValue);
  402|      0|      if (!s.ok()) {
  403|      0|        return s;
  404|      0|      }
  405|      0|      switch (saver.state) {
  406|      0|        case kNotFound:
  407|      0|          break;  // Keep searching in other files
  408|      0|        case kFound:
  409|      0|          return s;
  410|      0|        case kDeleted:
  411|      0|          s = Status::NotFound(Slice());  // Use empty error message for speed
  412|      0|          return s;
  413|      0|        case kCorrupt:
  414|      0|          s = Status::Corruption("corrupted key for ", user_key);
  415|      0|          return s;
  416|      0|      }
  417|      0|    }
  418|      0|  }
  419|      0|
  420|      0|  return Status::NotFound(Slice());  // Use an empty error message for speed
  421|      0|}
  422|       |
  423|      0|bool Version::UpdateStats(const GetStats& stats) {
  424|      0|  FileMetaData* f = stats.seek_file;
  425|      0|  if (f != nullptr) {
  426|      0|    f->allowed_seeks--;
  427|      0|    if (f->allowed_seeks <= 0 && file_to_compact_ == nullptr) {
  428|      0|      file_to_compact_ = f;
  429|      0|      file_to_compact_level_ = stats.seek_file_level;
  430|      0|      return true;
  431|      0|    }
  432|      0|  }
  433|      0|  return false;
  434|      0|}
  435|       |
  436|      0|bool Version::RecordReadSample(Slice internal_key) {
  437|      0|  ParsedInternalKey ikey;
  438|      0|  if (!ParseInternalKey(internal_key, &ikey)) {
  439|      0|    return false;
  440|      0|  }
  441|      0|
  442|      0|  struct State {
  443|      0|    GetStats stats;  // Holds first matching file
  444|      0|    int matches;
  445|      0|
  446|      0|    static bool Match(void* arg, int level, FileMetaData* f) {
  447|      0|      State* state = reinterpret_cast<State*>(arg);
  448|      0|      state->matches++;
  449|      0|      if (state->matches == 1) {
  450|      0|        // Remember first match.
  451|      0|        state->stats.seek_file = f;
  452|      0|        state->stats.seek_file_level = level;
  453|      0|      }
  454|      0|      // We can stop iterating once we have a second match.
  455|      0|      return state->matches < 2;
  456|      0|    }
  457|      0|  };
  458|      0|
  459|      0|  State state;
  460|      0|  state.matches = 0;
  461|      0|  ForEachOverlapping(ikey.user_key, internal_key, &state, &State::Match);
  462|      0|
  463|      0|  // Must have at least two matches since we want to merge across
  464|      0|  // files. But what if we have a single file that contains many
  465|      0|  // overwrites and deletions?  Should we have another mechanism for
  466|      0|  // finding such files?
  467|      0|  if (state.matches >= 2) {
  468|      0|    // 1MB cost is about 1 seek (see comment in Builder::Apply).
  469|      0|    return UpdateStats(state.stats);
  470|      0|  }
  471|      0|  return false;
  472|      0|}
  473|       |
  474|      0|void Version::Ref() { ++refs_; }
  475|       |
  476|      0|void Version::Unref() {
  477|      0|  assert(this != &vset_->dummy_versions_);
  478|      0|  assert(refs_ >= 1);
  479|      0|  --refs_;
  480|      0|  if (refs_ == 0) {
  481|      0|    delete this;
  482|      0|  }
  483|      0|}
  484|       |
  485|       |bool Version::OverlapInLevel(int level, const Slice* smallest_user_key,
  486|      0|                             const Slice* largest_user_key) {
  487|      0|  return SomeFileOverlapsRange(vset_->icmp_, (level > 0), files_[level],
  488|      0|                               smallest_user_key, largest_user_key);
  489|      0|}
  490|       |
  491|       |int Version::PickLevelForMemTableOutput(const Slice& smallest_user_key,
  492|      0|                                        const Slice& largest_user_key) {
  493|      0|  int level = 0;
  494|      0|  if (!OverlapInLevel(0, &smallest_user_key, &largest_user_key)) {
  495|      0|    // Push to next level if there is no overlap in next level,
  496|      0|    // and the #bytes overlapping in the level after that are limited.
  497|      0|    InternalKey start(smallest_user_key, kMaxSequenceNumber, kValueTypeForSeek);
  498|      0|    InternalKey limit(largest_user_key, 0, static_cast<ValueType>(0));
  499|      0|    std::vector<FileMetaData*> overlaps;
  500|      0|    while (level < config::kMaxMemCompactLevel) {
  501|      0|      if (OverlapInLevel(level + 1, &smallest_user_key, &largest_user_key)) {
  502|      0|        break;
  503|      0|      }
  504|      0|      if (level + 2 < config::kNumLevels) {
  505|      0|        // Check that file does not overlap too many grandparent bytes.
  506|      0|        GetOverlappingInputs(level + 2, &start, &limit, &overlaps);
  507|      0|        const int64_t sum = TotalFileSize(overlaps);
  508|      0|        if (sum > MaxGrandParentOverlapBytes(vset_->options_)) {
  509|      0|          break;
  510|      0|        }
  511|      0|      }
  512|      0|      level++;
  513|      0|    }
  514|      0|  }
  515|      0|  return level;
  516|      0|}
  517|       |
  518|       |// Store in "*inputs" all files in "level" that overlap [begin,end]
  519|       |void Version::GetOverlappingInputs(int level, const InternalKey* begin,
  520|       |                                   const InternalKey* end,
  521|      0|                                   std::vector<FileMetaData*>* inputs) {
  522|      0|  assert(level >= 0);
  523|      0|  assert(level < config::kNumLevels);
  524|      0|  inputs->clear();
  525|      0|  Slice user_begin, user_end;
  526|      0|  if (begin != nullptr) {
  527|      0|    user_begin = begin->user_key();
  528|      0|  }
  529|      0|  if (end != nullptr) {
  530|      0|    user_end = end->user_key();
  531|      0|  }
  532|      0|  const Comparator* user_cmp = vset_->icmp_.user_comparator();
  533|      0|  for (size_t i = 0; i < files_[level].size();) {
  534|      0|    FileMetaData* f = files_[level][i++];
  535|      0|    const Slice file_start = f->smallest.user_key();
  536|      0|    const Slice file_limit = f->largest.user_key();
  537|      0|    if (begin != nullptr && user_cmp->Compare(file_limit, user_begin) < 0) {
  538|      0|      // "f" is completely before specified range; skip it
  539|      0|    } else if (end != nullptr && user_cmp->Compare(file_start, user_end) > 0) {
  540|      0|      // "f" is completely after specified range; skip it
  541|      0|    } else {
  542|      0|      inputs->push_back(f);
  543|      0|      if (level == 0) {
  544|      0|        // Level-0 files may overlap each other.  So check if the newly
  545|      0|        // added file has expanded the range.  If so, restart search.
  546|      0|        if (begin != nullptr && user_cmp->Compare(file_start, user_begin) < 0) {
  547|      0|          user_begin = file_start;
  548|      0|          inputs->clear();
  549|      0|          i = 0;
  550|      0|        } else if (end != nullptr &&
  551|      0|                   user_cmp->Compare(file_limit, user_end) > 0) {
  552|      0|          user_end = file_limit;
  553|      0|          inputs->clear();
  554|      0|          i = 0;
  555|      0|        }
  556|      0|      }
  557|      0|    }
  558|      0|  }
  559|      0|}
  560|       |
  561|      0|std::string Version::DebugString() const {
  562|      0|  std::string r;
  563|      0|  for (int level = 0; level < config::kNumLevels; level++) {
  564|      0|    // E.g.,
  565|      0|    //   --- level 1 ---
  566|      0|    //   17:123['a' .. 'd']
  567|      0|    //   20:43['e' .. 'g']
  568|      0|    r.append("--- level ");
  569|      0|    AppendNumberTo(&r, level);
  570|      0|    r.append(" ---\n");
  571|      0|    const std::vector<FileMetaData*>& files = files_[level];
  572|      0|    for (size_t i = 0; i < files.size(); i++) {
  573|      0|      r.push_back(' ');
  574|      0|      AppendNumberTo(&r, files[i]->number);
  575|      0|      r.push_back(':');
  576|      0|      AppendNumberTo(&r, files[i]->file_size);
  577|      0|      r.append("[");
  578|      0|      r.append(files[i]->smallest.DebugString());
  579|      0|      r.append(" .. ");
  580|      0|      r.append(files[i]->largest.DebugString());
  581|      0|      r.append("]\n");
  582|      0|    }
  583|      0|  }
  584|      0|  return r;
  585|      0|}
  586|       |
  587|       |// A helper class so we can efficiently apply a whole sequence
  588|       |// of edits to a particular state without creating intermediate
  589|       |// Versions that contain full copies of the intermediate state.
  590|       |class VersionSet::Builder {
  591|       | private:
  592|       |  // Helper to sort by v->files_[file_number].smallest
  593|       |  struct BySmallestKey {
  594|       |    const InternalKeyComparator* internal_comparator;
  595|       |
  596|      0|    bool operator()(FileMetaData* f1, FileMetaData* f2) const {
  597|      0|      int r = internal_comparator->Compare(f1->smallest, f2->smallest);
  598|      0|      if (r != 0) {
  599|      0|        return (r < 0);
  600|      0|      } else {
  601|      0|        // Break ties by file number
  602|      0|        return (f1->number < f2->number);
  603|      0|      }
  604|      0|    }
  605|       |  };
  606|       |
  607|       |  typedef std::set<FileMetaData*, BySmallestKey> FileSet;
  608|       |  struct LevelState {
  609|       |    std::set<uint64_t> deleted_files;
  610|       |    FileSet* added_files;
  611|       |  };
  612|       |
  613|       |  VersionSet* vset_;
  614|       |  Version* base_;
  615|       |  LevelState levels_[config::kNumLevels];
  616|       |
  617|       | public:
  618|       |  // Initialize a builder with the files from *base and other info from *vset
  619|      0|  Builder(VersionSet* vset, Version* base) : vset_(vset), base_(base) {
  620|      0|    base_->Ref();
  621|      0|    BySmallestKey cmp;
  622|      0|    cmp.internal_comparator = &vset_->icmp_;
  623|      0|    for (int level = 0; level < config::kNumLevels; level++) {
  624|      0|      levels_[level].added_files = new FileSet(cmp);
  625|      0|    }
  626|      0|  }
  627|       |
  628|      0|  ~Builder() {
  629|      0|    for (int level = 0; level < config::kNumLevels; level++) {
  630|      0|      const FileSet* added = levels_[level].added_files;
  631|      0|      std::vector<FileMetaData*> to_unref;
  632|      0|      to_unref.reserve(added->size());
  633|      0|      for (FileSet::const_iterator it = added->begin(); it != added->end();
  634|      0|           ++it) {
  635|      0|        to_unref.push_back(*it);
  636|      0|      }
  637|      0|      delete added;
  638|      0|      for (uint32_t i = 0; i < to_unref.size(); i++) {
  639|      0|        FileMetaData* f = to_unref[i];
  640|      0|        f->refs--;
  641|      0|        if (f->refs <= 0) {
  642|      0|          delete f;
  643|      0|        }
  644|      0|      }
  645|      0|    }
  646|      0|    base_->Unref();
  647|      0|  }
  648|       |
  649|       |  // Apply all of the edits in *edit to the current state.
  650|      0|  void Apply(VersionEdit* edit) {
  651|      0|    // Update compaction pointers
  652|      0|    for (size_t i = 0; i < edit->compact_pointers_.size(); i++) {
  653|      0|      const int level = edit->compact_pointers_[i].first;
  654|      0|      vset_->compact_pointer_[level] =
  655|      0|          edit->compact_pointers_[i].second.Encode().ToString();
  656|      0|    }
  657|      0|
  658|      0|    // Delete files
  659|      0|    const VersionEdit::DeletedFileSet& del = edit->deleted_files_;
  660|      0|    for (VersionEdit::DeletedFileSet::const_iterator iter = del.begin();
  661|      0|         iter != del.end(); ++iter) {
  662|      0|      const int level = iter->first;
  663|      0|      const uint64_t number = iter->second;
  664|      0|      levels_[level].deleted_files.insert(number);
  665|      0|    }
  666|      0|
  667|      0|    // Add new files
  668|      0|    for (size_t i = 0; i < edit->new_files_.size(); i++) {
  669|      0|      const int level = edit->new_files_[i].first;
  670|      0|      FileMetaData* f = new FileMetaData(edit->new_files_[i].second);
  671|      0|      f->refs = 1;
  672|      0|
  673|      0|      // We arrange to automatically compact this file after
  674|      0|      // a certain number of seeks.  Let's assume:
  675|      0|      //   (1) One seek costs 10ms
  676|      0|      //   (2) Writing or reading 1MB costs 10ms (100MB/s)
  677|      0|      //   (3) A compaction of 1MB does 25MB of IO:
  678|      0|      //         1MB read from this level
  679|      0|      //         10-12MB read from next level (boundaries may be misaligned)
  680|      0|      //         10-12MB written to next level
  681|      0|      // This implies that 25 seeks cost the same as the compaction
  682|      0|      // of 1MB of data.  I.e., one seek costs approximately the
  683|      0|      // same as the compaction of 40KB of data.  We are a little
  684|      0|      // conservative and allow approximately one seek for every 16KB
  685|      0|      // of data before triggering a compaction.
  686|      0|      f->allowed_seeks = static_cast<int>((f->file_size / 16384U));
  687|      0|      if (f->allowed_seeks < 100) f->allowed_seeks = 100;
  688|      0|
  689|      0|      levels_[level].deleted_files.erase(f->number);
  690|      0|      levels_[level].added_files->insert(f);
  691|      0|    }
  692|      0|  }
  693|       |
  694|       |  // Save the current state in *v.
  695|      0|  void SaveTo(Version* v) {
  696|      0|    BySmallestKey cmp;
  697|      0|    cmp.internal_comparator = &vset_->icmp_;
  698|      0|    for (int level = 0; level < config::kNumLevels; level++) {
  699|      0|      // Merge the set of added files with the set of pre-existing files.
  700|      0|      // Drop any deleted files.  Store the result in *v.
  701|      0|      const std::vector<FileMetaData*>& base_files = base_->files_[level];
  702|      0|      std::vector<FileMetaData*>::const_iterator base_iter = base_files.begin();
  703|      0|      std::vector<FileMetaData*>::const_iterator base_end = base_files.end();
  704|      0|      const FileSet* added = levels_[level].added_files;
  705|      0|      v->files_[level].reserve(base_files.size() + added->size());
  706|      0|      for (FileSet::const_iterator added_iter = added->begin();
  707|      0|           added_iter != added->end(); ++added_iter) {
  708|      0|        // Add all smaller files listed in base_
  709|      0|        for (std::vector<FileMetaData*>::const_iterator bpos =
  710|      0|                 std::upper_bound(base_iter, base_end, *added_iter, cmp);
  711|      0|             base_iter != bpos; ++base_iter) {
  712|      0|          MaybeAddFile(v, level, *base_iter);
  713|      0|        }
  714|      0|
  715|      0|        MaybeAddFile(v, level, *added_iter);
  716|      0|      }
  717|      0|
  718|      0|      // Add remaining base files
  719|      0|      for (; base_iter != base_end; ++base_iter) {
  720|      0|        MaybeAddFile(v, level, *base_iter);
  721|      0|      }
  722|      0|
  723|      0|#ifndef NDEBUG
  724|      0|      // Make sure there is no overlap in levels > 0
  725|      0|      if (level > 0) {
  726|      0|        for (uint32_t i = 1; i < v->files_[level].size(); i++) {
  727|      0|          const InternalKey& prev_end = v->files_[level][i - 1]->largest;
  728|      0|          const InternalKey& this_begin = v->files_[level][i]->smallest;
  729|      0|          if (vset_->icmp_.Compare(prev_end, this_begin) >= 0) {
  730|      0|            fprintf(stderr, "overlapping ranges in same level %s vs. %s\n",
  731|      0|                    prev_end.DebugString().c_str(),
  732|      0|                    this_begin.DebugString().c_str());
  733|      0|            abort();
  734|      0|          }
  735|      0|        }
  736|      0|      }
  737|      0|#endif
  738|      0|    }
  739|      0|  }
  740|       |
  741|      0|  void MaybeAddFile(Version* v, int level, FileMetaData* f) {
  742|      0|    if (levels_[level].deleted_files.count(f->number) > 0) {
  743|      0|      // File is deleted: do nothing
  744|      0|    } else {
  745|      0|      std::vector<FileMetaData*>* files = &v->files_[level];
  746|      0|      if (level > 0 && !files->empty()) {
  747|      0|        // Must not overlap
  748|      0|        assert(vset_->icmp_.Compare((*files)[files->size() - 1]->largest,
  749|      0|                                    f->smallest) < 0);
  750|      0|      }
  751|      0|      f->refs++;
  752|      0|      files->push_back(f);
  753|      0|    }
  754|      0|  }
  755|       |};
  756|       |
  757|       |VersionSet::VersionSet(const std::string& dbname, const Options* options,
  758|       |                       TableCache* table_cache,
  759|       |                       const InternalKeyComparator* cmp)
  760|       |    : env_(options->env),
  761|       |      dbname_(dbname),
  762|       |      options_(options),
  763|       |      table_cache_(table_cache),
  764|       |      icmp_(*cmp),
  765|       |      next_file_number_(2),
  766|       |      manifest_file_number_(0),  // Filled by Recover()
  767|       |      last_sequence_(0),
  768|       |      log_number_(0),
  769|       |      prev_log_number_(0),
  770|       |      descriptor_file_(nullptr),
  771|       |      descriptor_log_(nullptr),
  772|       |      dummy_versions_(this),
  773|      0|      current_(nullptr) {
  774|      0|  AppendVersion(new Version(this));
  775|      0|}
  776|       |
  777|      0|VersionSet::~VersionSet() {
  778|      0|  current_->Unref();
  779|      0|  assert(dummy_versions_.next_ == &dummy_versions_);  // List must be empty
  780|      0|  delete descriptor_log_;
  781|      0|  delete descriptor_file_;
  782|      0|}
  783|       |
  784|      0|void VersionSet::AppendVersion(Version* v) {
  785|      0|  // Make "v" current
  786|      0|  assert(v->refs_ == 0);
  787|      0|  assert(v != current_);
  788|      0|  if (current_ != nullptr) {
  789|      0|    current_->Unref();
  790|      0|  }
  791|      0|  current_ = v;
  792|      0|  v->Ref();
  793|      0|
  794|      0|  // Append to linked list
  795|      0|  v->prev_ = dummy_versions_.prev_;
  796|      0|  v->next_ = &dummy_versions_;
  797|      0|  v->prev_->next_ = v;
  798|      0|  v->next_->prev_ = v;
  799|      0|}
  800|       |
  801|      0|Status VersionSet::LogAndApply(VersionEdit* edit, port::Mutex* mu) {
  802|      0|  if (edit->has_log_number_) {
  803|      0|    assert(edit->log_number_ >= log_number_);
  804|      0|    assert(edit->log_number_ < next_file_number_);
  805|      0|  } else {
  806|      0|    edit->SetLogNumber(log_number_);
  807|      0|  }
  808|      0|
  809|      0|  if (!edit->has_prev_log_number_) {
  810|      0|    edit->SetPrevLogNumber(prev_log_number_);
  811|      0|  }
  812|      0|
  813|      0|  edit->SetNextFile(next_file_number_);
  814|      0|  edit->SetLastSequence(last_sequence_);
  815|      0|
  816|      0|  Version* v = new Version(this);
  817|      0|  {
  818|      0|    Builder builder(this, current_);
  819|      0|    builder.Apply(edit);
  820|      0|    builder.SaveTo(v);
  821|      0|  }
  822|      0|  Finalize(v);
  823|      0|
  824|      0|  // Initialize new descriptor log file if necessary by creating
  825|      0|  // a temporary file that contains a snapshot of the current version.
  826|      0|  std::string new_manifest_file;
  827|      0|  Status s;
  828|      0|  if (descriptor_log_ == nullptr) {
  829|      0|    // No reason to unlock *mu here since we only hit this path in the
  830|      0|    // first call to LogAndApply (when opening the database).
  831|      0|    assert(descriptor_file_ == nullptr);
  832|      0|    new_manifest_file = DescriptorFileName(dbname_, manifest_file_number_);
  833|      0|    edit->SetNextFile(next_file_number_);
  834|      0|    s = env_->NewWritableFile(new_manifest_file, &descriptor_file_);
  835|      0|    if (s.ok()) {
  836|      0|      descriptor_log_ = new log::Writer(descriptor_file_);
  837|      0|      s = WriteSnapshot(descriptor_log_);
  838|      0|    }
  839|      0|  }
  840|      0|
  841|      0|  // Unlock during expensive MANIFEST log write
  842|      0|  {
  843|      0|    mu->Unlock();
  844|      0|
  845|      0|    // Write new record to MANIFEST log
  846|      0|    if (s.ok()) {
  847|      0|      std::string record;
  848|      0|      edit->EncodeTo(&record);
  849|      0|      s = descriptor_log_->AddRecord(record);
  850|      0|      if (s.ok()) {
  851|      0|        s = descriptor_file_->Sync();
  852|      0|      }
  853|      0|      if (!s.ok()) {
  854|      0|        Log(options_->info_log, "MANIFEST write: %s\n", s.ToString().c_str());
  855|      0|      }
  856|      0|    }
  857|      0|
  858|      0|    // If we just created a new descriptor file, install it by writing a
  859|      0|    // new CURRENT file that points to it.
  860|      0|    if (s.ok() && !new_manifest_file.empty()) {
  861|      0|      s = SetCurrentFile(env_, dbname_, manifest_file_number_);
  862|      0|    }
  863|      0|
  864|      0|    mu->Lock();
  865|      0|  }
  866|      0|
  867|      0|  // Install the new version
  868|      0|  if (s.ok()) {
  869|      0|    AppendVersion(v);
  870|      0|    log_number_ = edit->log_number_;
  871|      0|    prev_log_number_ = edit->prev_log_number_;
  872|      0|  } else {
  873|      0|    delete v;
  874|      0|    if (!new_manifest_file.empty()) {
  875|      0|      delete descriptor_log_;
  876|      0|      delete descriptor_file_;
  877|      0|      descriptor_log_ = nullptr;
  878|      0|      descriptor_file_ = nullptr;
  879|      0|      env_->DeleteFile(new_manifest_file);
  880|      0|    }
  881|      0|  }
  882|      0|
  883|      0|  return s;
  884|      0|}
  885|       |
  886|      0|Status VersionSet::Recover(bool* save_manifest) {
  887|      0|  struct LogReporter : public log::Reader::Reporter {
  888|      0|    Status* status;
  889|      0|    virtual void Corruption(size_t bytes, const Status& s) {
  890|      0|      if (this->status->ok()) *this->status = s;
  891|      0|    }
  892|      0|  };
  893|      0|
  894|      0|  // Read "CURRENT" file, which contains a pointer to the current manifest file
  895|      0|  std::string current;
  896|      0|  Status s = ReadFileToString(env_, CurrentFileName(dbname_), &current);
  897|      0|  if (!s.ok()) {
  898|      0|    return s;
  899|      0|  }
  900|      0|  if (current.empty() || current[current.size() - 1] != '\n') {
  901|      0|    return Status::Corruption("CURRENT file does not end with newline");
  902|      0|  }
  903|      0|  current.resize(current.size() - 1);
  904|      0|
  905|      0|  std::string dscname = dbname_ + "/" + current;
  906|      0|  SequentialFile* file;
  907|      0|  s = env_->NewSequentialFile(dscname, &file);
  908|      0|  if (!s.ok()) {
  909|      0|    if (s.IsNotFound()) {
  910|      0|      return Status::Corruption("CURRENT points to a non-existent file",
  911|      0|                                s.ToString());
  912|      0|    }
  913|      0|    return s;
  914|      0|  }
  915|      0|
  916|      0|  bool have_log_number = false;
  917|      0|  bool have_prev_log_number = false;
  918|      0|  bool have_next_file = false;
  919|      0|  bool have_last_sequence = false;
  920|      0|  uint64_t next_file = 0;
  921|      0|  uint64_t last_sequence = 0;
  922|      0|  uint64_t log_number = 0;
  923|      0|  uint64_t prev_log_number = 0;
  924|      0|  Builder builder(this, current_);
  925|      0|
  926|      0|  {
  927|      0|    LogReporter reporter;
  928|      0|    reporter.status = &s;
  929|      0|    log::Reader reader(file, &reporter, true /*checksum*/,
  930|      0|                       0 /*initial_offset*/);
  931|      0|    Slice record;
  932|      0|    std::string scratch;
  933|      0|    while (reader.ReadRecord(&record, &scratch) && s.ok()) {
  934|      0|      VersionEdit edit;
  935|      0|      s = edit.DecodeFrom(record);
  936|      0|      if (s.ok()) {
  937|      0|        if (edit.has_comparator_ &&
  938|      0|            edit.comparator_ != icmp_.user_comparator()->Name()) {
  939|      0|          s = Status::InvalidArgument(
  940|      0|              edit.comparator_ + " does not match existing comparator ",
  941|      0|              icmp_.user_comparator()->Name());
  942|      0|        }
  943|      0|      }
  944|      0|
  945|      0|      if (s.ok()) {
  946|      0|        builder.Apply(&edit);
  947|      0|      }
  948|      0|
  949|      0|      if (edit.has_log_number_) {
  950|      0|        log_number = edit.log_number_;
  951|      0|        have_log_number = true;
  952|      0|      }
  953|      0|
  954|      0|      if (edit.has_prev_log_number_) {
  955|      0|        prev_log_number = edit.prev_log_number_;
  956|      0|        have_prev_log_number = true;
  957|      0|      }
  958|      0|
  959|      0|      if (edit.has_next_file_number_) {
  960|      0|        next_file = edit.next_file_number_;
  961|      0|        have_next_file = true;
  962|      0|      }
  963|      0|
  964|      0|      if (edit.has_last_sequence_) {
  965|      0|        last_sequence = edit.last_sequence_;
  966|      0|        have_last_sequence = true;
  967|      0|      }
  968|      0|    }
  969|      0|  }
  970|      0|  delete file;
  971|      0|  file = nullptr;
  972|      0|
  973|      0|  if (s.ok()) {
  974|      0|    if (!have_next_file) {
  975|      0|      s = Status::Corruption("no meta-nextfile entry in descriptor");
  976|      0|    } else if (!have_log_number) {
  977|      0|      s = Status::Corruption("no meta-lognumber entry in descriptor");
  978|      0|    } else if (!have_last_sequence) {
  979|      0|      s = Status::Corruption("no last-sequence-number entry in descriptor");
  980|      0|    }
  981|      0|
  982|      0|    if (!have_prev_log_number) {
  983|      0|      prev_log_number = 0;
  984|      0|    }
  985|      0|
  986|      0|    MarkFileNumberUsed(prev_log_number);
  987|      0|    MarkFileNumberUsed(log_number);
  988|      0|  }
  989|      0|
  990|      0|  if (s.ok()) {
  991|      0|    Version* v = new Version(this);
  992|      0|    builder.SaveTo(v);
  993|      0|    // Install recovered version
  994|      0|    Finalize(v);
  995|      0|    AppendVersion(v);
  996|      0|    manifest_file_number_ = next_file;
  997|      0|    next_file_number_ = next_file + 1;
  998|      0|    last_sequence_ = last_sequence;
  999|      0|    log_number_ = log_number;
 1000|      0|    prev_log_number_ = prev_log_number;
 1001|      0|
 1002|      0|    // See if we can reuse the existing MANIFEST file.
 1003|      0|    if (ReuseManifest(dscname, current)) {
 1004|      0|      // No need to save new manifest
 1005|      0|    } else {
 1006|      0|      *save_manifest = true;
 1007|      0|    }
 1008|      0|  }
 1009|      0|
 1010|      0|  return s;
 1011|      0|}
 1012|       |
 1013|       |bool VersionSet::ReuseManifest(const std::string& dscname,
 1014|      0|                               const std::string& dscbase) {
 1015|      0|  if (!options_->reuse_logs) {
 1016|      0|    return false;
 1017|      0|  }
 1018|      0|  FileType manifest_type;
 1019|      0|  uint64_t manifest_number;
 1020|      0|  uint64_t manifest_size;
 1021|      0|  if (!ParseFileName(dscbase, &manifest_number, &manifest_type) ||
 1022|      0|      manifest_type != kDescriptorFile ||
 1023|      0|      !env_->GetFileSize(dscname, &manifest_size).ok() ||
 1024|      0|      // Make new compacted MANIFEST if old one is too big
 1025|      0|      manifest_size >= TargetFileSize(options_)) {
 1026|      0|    return false;
 1027|      0|  }
 1028|      0|
 1029|      0|  assert(descriptor_file_ == nullptr);
 1030|      0|  assert(descriptor_log_ == nullptr);
 1031|      0|  Status r = env_->NewAppendableFile(dscname, &descriptor_file_);
 1032|      0|  if (!r.ok()) {
 1033|      0|    Log(options_->info_log, "Reuse MANIFEST: %s\n", r.ToString().c_str());
 1034|      0|    assert(descriptor_file_ == nullptr);
 1035|      0|    return false;
 1036|      0|  }
 1037|      0|
 1038|      0|  Log(options_->info_log, "Reusing MANIFEST %s\n", dscname.c_str());
 1039|      0|  descriptor_log_ = new log::Writer(descriptor_file_, manifest_size);
 1040|      0|  manifest_file_number_ = manifest_number;
 1041|      0|  return true;
 1042|      0|}
 1043|       |
 1044|      0|void VersionSet::MarkFileNumberUsed(uint64_t number) {
 1045|      0|  if (next_file_number_ <= number) {
 1046|      0|    next_file_number_ = number + 1;
 1047|      0|  }
 1048|      0|}
 1049|       |
 1050|      0|void VersionSet::Finalize(Version* v) {
 1051|      0|  // Precomputed best level for next compaction
 1052|      0|  int best_level = -1;
 1053|      0|  double best_score = -1;
 1054|      0|
 1055|      0|  for (int level = 0; level < config::kNumLevels - 1; level++) {
 1056|      0|    double score;
 1057|      0|    if (level == 0) {
 1058|      0|      // We treat level-0 specially by bounding the number of files
 1059|      0|      // instead of number of bytes for two reasons:
 1060|      0|      //
 1061|      0|      // (1) With larger write-buffer sizes, it is nice not to do too
 1062|      0|      // many level-0 compactions.
 1063|      0|      //
 1064|      0|      // (2) The files in level-0 are merged on every read and
 1065|      0|      // therefore we wish to avoid too many files when the individual
 1066|      0|      // file size is small (perhaps because of a small write-buffer
 1067|      0|      // setting, or very high compression ratios, or lots of
 1068|      0|      // overwrites/deletions).
 1069|      0|      score = v->files_[level].size() /
 1070|      0|              static_cast<double>(config::kL0_CompactionTrigger);
 1071|      0|    } else {
 1072|      0|      // Compute the ratio of current size to size limit.
 1073|      0|      const uint64_t level_bytes = TotalFileSize(v->files_[level]);
 1074|      0|      score =
 1075|      0|          static_cast<double>(level_bytes) / MaxBytesForLevel(options_, level);
 1076|      0|    }
 1077|      0|
 1078|      0|    if (score > best_score) {
 1079|      0|      best_level = level;
 1080|      0|      best_score = score;
 1081|      0|    }
 1082|      0|  }
 1083|      0|
 1084|      0|  v->compaction_level_ = best_level;
 1085|      0|  v->compaction_score_ = best_score;
 1086|      0|}
 1087|       |
 1088|      0|Status VersionSet::WriteSnapshot(log::Writer* log) {
 1089|      0|  // TODO: Break up into multiple records to reduce memory usage on recovery?
 1090|      0|
 1091|      0|  // Save metadata
 1092|      0|  VersionEdit edit;
 1093|      0|  edit.SetComparatorName(icmp_.user_comparator()->Name());
 1094|      0|
 1095|      0|  // Save compaction pointers
 1096|      0|  for (int level = 0; level < config::kNumLevels; level++) {
 1097|      0|    if (!compact_pointer_[level].empty()) {
 1098|      0|      InternalKey key;
 1099|      0|      key.DecodeFrom(compact_pointer_[level]);
 1100|      0|      edit.SetCompactPointer(level, key);
 1101|      0|    }
 1102|      0|  }
 1103|      0|
 1104|      0|  // Save files
 1105|      0|  for (int level = 0; level < config::kNumLevels; level++) {
 1106|      0|    const std::vector<FileMetaData*>& files = current_->files_[level];
 1107|      0|    for (size_t i = 0; i < files.size(); i++) {
 1108|      0|      const FileMetaData* f = files[i];
 1109|      0|      edit.AddFile(level, f->number, f->file_size, f->smallest, f->largest);
 1110|      0|    }
 1111|      0|  }
 1112|      0|
 1113|      0|  std::string record;
 1114|      0|  edit.EncodeTo(&record);
 1115|      0|  return log->AddRecord(record);
 1116|      0|}
 1117|       |
 1118|      0|int VersionSet::NumLevelFiles(int level) const {
 1119|      0|  assert(level >= 0);
 1120|      0|  assert(level < config::kNumLevels);
 1121|      0|  return current_->files_[level].size();
 1122|      0|}
 1123|       |
 1124|      0|const char* VersionSet::LevelSummary(LevelSummaryStorage* scratch) const {
 1125|      0|  // Update code if kNumLevels changes
 1126|      0|  static_assert(config::kNumLevels == 7, "");
 1127|      0|  snprintf(scratch->buffer, sizeof(scratch->buffer),
 1128|      0|           "files[ %d %d %d %d %d %d %d ]", int(current_->files_[0].size()),
 1129|      0|           int(current_->files_[1].size()), int(current_->files_[2].size()),
 1130|      0|           int(current_->files_[3].size()), int(current_->files_[4].size()),
 1131|      0|           int(current_->files_[5].size()), int(current_->files_[6].size()));
 1132|      0|  return scratch->buffer;
 1133|      0|}
 1134|       |
 1135|      0|uint64_t VersionSet::ApproximateOffsetOf(Version* v, const InternalKey& ikey) {
 1136|      0|  uint64_t result = 0;
 1137|      0|  for (int level = 0; level < config::kNumLevels; level++) {
 1138|      0|    const std::vector<FileMetaData*>& files = v->files_[level];
 1139|      0|    for (size_t i = 0; i < files.size(); i++) {
 1140|      0|      if (icmp_.Compare(files[i]->largest, ikey) <= 0) {
 1141|      0|        // Entire file is before "ikey", so just add the file size
 1142|      0|        result += files[i]->file_size;
 1143|      0|      } else if (icmp_.Compare(files[i]->smallest, ikey) > 0) {
 1144|      0|        // Entire file is after "ikey", so ignore
 1145|      0|        if (level > 0) {
 1146|      0|          // Files other than level 0 are sorted by meta->smallest, so
 1147|      0|          // no further files in this level will contain data for
 1148|      0|          // "ikey".
 1149|      0|          break;
 1150|      0|        }
 1151|      0|      } else {
 1152|      0|        // "ikey" falls in the range for this table.  Add the
 1153|      0|        // approximate offset of "ikey" within the table.
 1154|      0|        Table* tableptr;
 1155|      0|        Iterator* iter = table_cache_->NewIterator(
 1156|      0|            ReadOptions(), files[i]->number, files[i]->file_size, &tableptr);
 1157|      0|        if (tableptr != nullptr) {
 1158|      0|          result += tableptr->ApproximateOffsetOf(ikey.Encode());
 1159|      0|        }
 1160|      0|        delete iter;
 1161|      0|      }
 1162|      0|    }
 1163|      0|  }
 1164|      0|  return result;
 1165|      0|}
 1166|       |
 1167|      0|void VersionSet::AddLiveFiles(std::set<uint64_t>* live) {
 1168|      0|  for (Version* v = dummy_versions_.next_; v != &dummy_versions_;
 1169|      0|       v = v->next_) {
 1170|      0|    for (int level = 0; level < config::kNumLevels; level++) {
 1171|      0|      const std::vector<FileMetaData*>& files = v->files_[level];
 1172|      0|      for (size_t i = 0; i < files.size(); i++) {
 1173|      0|        live->insert(files[i]->number);
 1174|      0|      }
 1175|      0|    }
 1176|      0|  }
 1177|      0|}
 1178|       |
 1179|      0|int64_t VersionSet::NumLevelBytes(int level) const {
 1180|      0|  assert(level >= 0);
 1181|      0|  assert(level < config::kNumLevels);
 1182|      0|  return TotalFileSize(current_->files_[level]);
 1183|      0|}
 1184|       |
 1185|      0|int64_t VersionSet::MaxNextLevelOverlappingBytes() {
 1186|      0|  int64_t result = 0;
 1187|      0|  std::vector<FileMetaData*> overlaps;
 1188|      0|  for (int level = 1; level < config::kNumLevels - 1; level++) {
 1189|      0|    for (size_t i = 0; i < current_->files_[level].size(); i++) {
 1190|      0|      const FileMetaData* f = current_->files_[level][i];
 1191|      0|      current_->GetOverlappingInputs(level + 1, &f->smallest, &f->largest,
 1192|      0|                                     &overlaps);
 1193|      0|      const int64_t sum = TotalFileSize(overlaps);
 1194|      0|      if (sum > result) {
 1195|      0|        result = sum;
 1196|      0|      }
 1197|      0|    }
 1198|      0|  }
 1199|      0|  return result;
 1200|      0|}
 1201|       |
 1202|       |// Stores the minimal range that covers all entries in inputs in
 1203|       |// *smallest, *largest.
 1204|       |// REQUIRES: inputs is not empty
 1205|       |void VersionSet::GetRange(const std::vector<FileMetaData*>& inputs,
 1206|      0|                          InternalKey* smallest, InternalKey* largest) {
 1207|      0|  assert(!inputs.empty());
 1208|      0|  smallest->Clear();
 1209|      0|  largest->Clear();
 1210|      0|  for (size_t i = 0; i < inputs.size(); i++) {
 1211|      0|    FileMetaData* f = inputs[i];
 1212|      0|    if (i == 0) {
 1213|      0|      *smallest = f->smallest;
 1214|      0|      *largest = f->largest;
 1215|      0|    } else {
 1216|      0|      if (icmp_.Compare(f->smallest, *smallest) < 0) {
 1217|      0|        *smallest = f->smallest;
 1218|      0|      }
 1219|      0|      if (icmp_.Compare(f->largest, *largest) > 0) {
 1220|      0|        *largest = f->largest;
 1221|      0|      }
 1222|      0|    }
 1223|      0|  }
 1224|      0|}
 1225|       |
 1226|       |// Stores the minimal range that covers all entries in inputs1 and inputs2
 1227|       |// in *smallest, *largest.
 1228|       |// REQUIRES: inputs is not empty
 1229|       |void VersionSet::GetRange2(const std::vector<FileMetaData*>& inputs1,
 1230|       |                           const std::vector<FileMetaData*>& inputs2,
 1231|      0|                           InternalKey* smallest, InternalKey* largest) {
 1232|      0|  std::vector<FileMetaData*> all = inputs1;
 1233|      0|  all.insert(all.end(), inputs2.begin(), inputs2.end());
 1234|      0|  GetRange(all, smallest, largest);
 1235|      0|}
 1236|       |
 1237|      0|Iterator* VersionSet::MakeInputIterator(Compaction* c) {
 1238|      0|  ReadOptions options;
 1239|      0|  options.verify_checksums = options_->paranoid_checks;
 1240|      0|  options.fill_cache = false;
 1241|      0|
 1242|      0|  // Level-0 files have to be merged together.  For other levels,
 1243|      0|  // we will make a concatenating iterator per level.
 1244|      0|  // TODO(opt): use concatenating iterator for level-0 if there is no overlap
 1245|      0|  const int space = (c->level() == 0 ? c->inputs_[0].size() + 1 : 2);
 1246|      0|  Iterator** list = new Iterator*[space];
 1247|      0|  int num = 0;
 1248|      0|  for (int which = 0; which < 2; which++) {
 1249|      0|    if (!c->inputs_[which].empty()) {
 1250|      0|      if (c->level() + which == 0) {
 1251|      0|        const std::vector<FileMetaData*>& files = c->inputs_[which];
 1252|      0|        for (size_t i = 0; i < files.size(); i++) {
 1253|      0|          list[num++] = table_cache_->NewIterator(options, files[i]->number,
 1254|      0|                                                  files[i]->file_size);
 1255|      0|        }
 1256|      0|      } else {
 1257|      0|        // Create concatenating iterator for the files from this level
 1258|      0|        list[num++] = NewTwoLevelIterator(
 1259|      0|            new Version::LevelFileNumIterator(icmp_, &c->inputs_[which]),
 1260|      0|            &GetFileIterator, table_cache_, options);
 1261|      0|      }
 1262|      0|    }
 1263|      0|  }
 1264|      0|  assert(num <= space);
 1265|      0|  Iterator* result = NewMergingIterator(&icmp_, list, num);
 1266|      0|  delete[] list;
 1267|      0|  return result;
 1268|      0|}
 1269|       |
 1270|      0|Compaction* VersionSet::PickCompaction() {
 1271|      0|  Compaction* c;
 1272|      0|  int level;
 1273|      0|
 1274|      0|  // We prefer compactions triggered by too much data in a level over
 1275|      0|  // the compactions triggered by seeks.
 1276|      0|  const bool size_compaction = (current_->compaction_score_ >= 1);
 1277|      0|  const bool seek_compaction = (current_->file_to_compact_ != nullptr);
 1278|      0|  if (size_compaction) {
 1279|      0|    level = current_->compaction_level_;
 1280|      0|    assert(level >= 0);
 1281|      0|    assert(level + 1 < config::kNumLevels);
 1282|      0|    c = new Compaction(options_, level);
 1283|      0|
 1284|      0|    // Pick the first file that comes after compact_pointer_[level]
 1285|      0|    for (size_t i = 0; i < current_->files_[level].size(); i++) {
 1286|      0|      FileMetaData* f = current_->files_[level][i];
 1287|      0|      if (compact_pointer_[level].empty() ||
 1288|      0|          icmp_.Compare(f->largest.Encode(), compact_pointer_[level]) > 0) {
 1289|      0|        c->inputs_[0].push_back(f);
 1290|      0|        break;
 1291|      0|      }
 1292|      0|    }
 1293|      0|    if (c->inputs_[0].empty()) {
 1294|      0|      // Wrap-around to the beginning of the key space
 1295|      0|      c->inputs_[0].push_back(current_->files_[level][0]);
 1296|      0|    }
 1297|      0|  } else if (seek_compaction) {
 1298|      0|    level = current_->file_to_compact_level_;
 1299|      0|    c = new Compaction(options_, level);
 1300|      0|    c->inputs_[0].push_back(current_->file_to_compact_);
 1301|      0|  } else {
 1302|      0|    return nullptr;
 1303|      0|  }
 1304|      0|
 1305|      0|  c->input_version_ = current_;
 1306|      0|  c->input_version_->Ref();
 1307|      0|
 1308|      0|  // Files in level 0 may overlap each other, so pick up all overlapping ones
 1309|      0|  if (level == 0) {
 1310|      0|    InternalKey smallest, largest;
 1311|      0|    GetRange(c->inputs_[0], &smallest, &largest);
 1312|      0|    // Note that the next call will discard the file we placed in
 1313|      0|    // c->inputs_[0] earlier and replace it with an overlapping set
 1314|      0|    // which will include the picked file.
 1315|      0|    current_->GetOverlappingInputs(0, &smallest, &largest, &c->inputs_[0]);
 1316|      0|    assert(!c->inputs_[0].empty());
 1317|      0|  }
 1318|      0|
 1319|      0|  SetupOtherInputs(c);
 1320|      0|
 1321|      0|  return c;
 1322|      0|}
 1323|       |
 1324|       |// Finds the largest key in a vector of files. Returns true if files it not
 1325|       |// empty.
 1326|       |bool FindLargestKey(const InternalKeyComparator& icmp,
 1327|       |                    const std::vector<FileMetaData*>& files,
 1328|      0|                    InternalKey* largest_key) {
 1329|      0|  if (files.empty()) {
 1330|      0|    return false;
 1331|      0|  }
 1332|      0|  *largest_key = files[0]->largest;
 1333|      0|  for (size_t i = 1; i < files.size(); ++i) {
 1334|      0|    FileMetaData* f = files[i];
 1335|      0|    if (icmp.Compare(f->largest, *largest_key) > 0) {
 1336|      0|      *largest_key = f->largest;
 1337|      0|    }
 1338|      0|  }
 1339|      0|  return true;
 1340|      0|}
 1341|       |
 1342|       |// Finds minimum file b2=(l2, u2) in level file for which l2 > u1 and
 1343|       |// user_key(l2) = user_key(u1)
 1344|       |FileMetaData* FindSmallestBoundaryFile(
 1345|       |    const InternalKeyComparator& icmp,
 1346|       |    const std::vector<FileMetaData*>& level_files,
 1347|      0|    const InternalKey& largest_key) {
 1348|      0|  const Comparator* user_cmp = icmp.user_comparator();
 1349|      0|  FileMetaData* smallest_boundary_file = nullptr;
 1350|      0|  for (size_t i = 0; i < level_files.size(); ++i) {
 1351|      0|    FileMetaData* f = level_files[i];
 1352|      0|    if (icmp.Compare(f->smallest, largest_key) > 0 &&
 1353|      0|        user_cmp->Compare(f->smallest.user_key(), largest_key.user_key()) ==
 1354|      0|            0) {
 1355|      0|      if (smallest_boundary_file == nullptr ||
 1356|      0|          icmp.Compare(f->smallest, smallest_boundary_file->smallest) < 0) {
 1357|      0|        smallest_boundary_file = f;
 1358|      0|      }
 1359|      0|    }
 1360|      0|  }
 1361|      0|  return smallest_boundary_file;
 1362|      0|}
 1363|       |
 1364|       |// Extracts the largest file b1 from |compaction_files| and then searches for a
 1365|       |// b2 in |level_files| for which user_key(u1) = user_key(l2). If it finds such a
 1366|       |// file b2 (known as a boundary file) it adds it to |compaction_files| and then
 1367|       |// searches again using this new upper bound.
 1368|       |//
 1369|       |// If there are two blocks, b1=(l1, u1) and b2=(l2, u2) and
 1370|       |// user_key(u1) = user_key(l2), and if we compact b1 but not b2 then a
 1371|       |// subsequent get operation will yield an incorrect result because it will
 1372|       |// return the record from b2 in level i rather than from b1 because it searches
 1373|       |// level by level for records matching the supplied user key.
 1374|       |//
 1375|       |// parameters:
 1376|       |//   in     level_files:      List of files to search for boundary files.
 1377|       |//   in/out compaction_files: List of files to extend by adding boundary files.
 1378|       |void AddBoundaryInputs(const InternalKeyComparator& icmp,
 1379|       |                       const std::vector<FileMetaData*>& level_files,
 1380|      0|                       std::vector<FileMetaData*>* compaction_files) {
 1381|      0|  InternalKey largest_key;
 1382|      0|
 1383|      0|  // Quick return if compaction_files is empty.
 1384|      0|  if (!FindLargestKey(icmp, *compaction_files, &largest_key)) {
 1385|      0|    return;
 1386|      0|  }
 1387|      0|
 1388|      0|  bool continue_searching = true;
 1389|      0|  while (continue_searching) {
 1390|      0|    FileMetaData* smallest_boundary_file =
 1391|      0|        FindSmallestBoundaryFile(icmp, level_files, largest_key);
 1392|      0|
 1393|      0|    // If a boundary file was found advance largest_key, otherwise we're done.
 1394|      0|    if (smallest_boundary_file != NULL) {
 1395|      0|      compaction_files->push_back(smallest_boundary_file);
 1396|      0|      largest_key = smallest_boundary_file->largest;
 1397|      0|    } else {
 1398|      0|      continue_searching = false;
 1399|      0|    }
 1400|      0|  }
 1401|      0|}
 1402|       |
 1403|      0|void VersionSet::SetupOtherInputs(Compaction* c) {
 1404|      0|  const int level = c->level();
 1405|      0|  InternalKey smallest, largest;
 1406|      0|
 1407|      0|  AddBoundaryInputs(icmp_, current_->files_[level], &c->inputs_[0]);
 1408|      0|  GetRange(c->inputs_[0], &smallest, &largest);
 1409|      0|
 1410|      0|  current_->GetOverlappingInputs(level + 1, &smallest, &largest,
 1411|      0|                                 &c->inputs_[1]);
 1412|      0|
 1413|      0|  // Get entire range covered by compaction
 1414|      0|  InternalKey all_start, all_limit;
 1415|      0|  GetRange2(c->inputs_[0], c->inputs_[1], &all_start, &all_limit);
 1416|      0|
 1417|      0|  // See if we can grow the number of inputs in "level" without
 1418|      0|  // changing the number of "level+1" files we pick up.
 1419|      0|  if (!c->inputs_[1].empty()) {
 1420|      0|    std::vector<FileMetaData*> expanded0;
 1421|      0|    current_->GetOverlappingInputs(level, &all_start, &all_limit, &expanded0);
 1422|      0|    AddBoundaryInputs(icmp_, current_->files_[level], &expanded0);
 1423|      0|    const int64_t inputs0_size = TotalFileSize(c->inputs_[0]);
 1424|      0|    const int64_t inputs1_size = TotalFileSize(c->inputs_[1]);
 1425|      0|    const int64_t expanded0_size = TotalFileSize(expanded0);
 1426|      0|    if (expanded0.size() > c->inputs_[0].size() &&
 1427|      0|        inputs1_size + expanded0_size <
 1428|      0|            ExpandedCompactionByteSizeLimit(options_)) {
 1429|      0|      InternalKey new_start, new_limit;
 1430|      0|      GetRange(expanded0, &new_start, &new_limit);
 1431|      0|      std::vector<FileMetaData*> expanded1;
 1432|      0|      current_->GetOverlappingInputs(level + 1, &new_start, &new_limit,
 1433|      0|                                     &expanded1);
 1434|      0|      if (expanded1.size() == c->inputs_[1].size()) {
 1435|      0|        Log(options_->info_log,
 1436|      0|            "Expanding@%d %d+%d (%ld+%ld bytes) to %d+%d (%ld+%ld bytes)\n",
 1437|      0|            level, int(c->inputs_[0].size()), int(c->inputs_[1].size()),
 1438|      0|            long(inputs0_size), long(inputs1_size), int(expanded0.size()),
 1439|      0|            int(expanded1.size()), long(expanded0_size), long(inputs1_size));
 1440|      0|        smallest = new_start;
 1441|      0|        largest = new_limit;
 1442|      0|        c->inputs_[0] = expanded0;
 1443|      0|        c->inputs_[1] = expanded1;
 1444|      0|        GetRange2(c->inputs_[0], c->inputs_[1], &all_start, &all_limit);
 1445|      0|      }
 1446|      0|    }
 1447|      0|  }
 1448|      0|
 1449|      0|  // Compute the set of grandparent files that overlap this compaction
 1450|      0|  // (parent == level+1; grandparent == level+2)
 1451|      0|  if (level + 2 < config::kNumLevels) {
 1452|      0|    current_->GetOverlappingInputs(level + 2, &all_start, &all_limit,
 1453|      0|                                   &c->grandparents_);
 1454|      0|  }
 1455|      0|
 1456|      0|  // Update the place where we will do the next compaction for this level.
 1457|      0|  // We update this immediately instead of waiting for the VersionEdit
 1458|      0|  // to be applied so that if the compaction fails, we will try a different
 1459|      0|  // key range next time.
 1460|      0|  compact_pointer_[level] = largest.Encode().ToString();
 1461|      0|  c->edit_.SetCompactPointer(level, largest);
 1462|      0|}
 1463|       |
 1464|       |Compaction* VersionSet::CompactRange(int level, const InternalKey* begin,
 1465|      0|                                     const InternalKey* end) {
 1466|      0|  std::vector<FileMetaData*> inputs;
 1467|      0|  current_->GetOverlappingInputs(level, begin, end, &inputs);
 1468|      0|  if (inputs.empty()) {
 1469|      0|    return nullptr;
 1470|      0|  }
 1471|      0|
 1472|      0|  // Avoid compacting too much in one shot in case the range is large.
 1473|      0|  // But we cannot do this for level-0 since level-0 files can overlap
 1474|      0|  // and we must not pick one file and drop another older file if the
 1475|      0|  // two files overlap.
 1476|      0|  if (level > 0) {
 1477|      0|    const uint64_t limit = MaxFileSizeForLevel(options_, level);
 1478|      0|    uint64_t total = 0;
 1479|      0|    for (size_t i = 0; i < inputs.size(); i++) {
 1480|      0|      uint64_t s = inputs[i]->file_size;
 1481|      0|      total += s;
 1482|      0|      if (total >= limit) {
 1483|      0|        inputs.resize(i + 1);
 1484|      0|        break;
 1485|      0|      }
 1486|      0|    }
 1487|      0|  }
 1488|      0|
 1489|      0|  Compaction* c = new Compaction(options_, level);
 1490|      0|  c->input_version_ = current_;
 1491|      0|  c->input_version_->Ref();
 1492|      0|  c->inputs_[0] = inputs;
 1493|      0|  SetupOtherInputs(c);
 1494|      0|  return c;
 1495|      0|}
 1496|       |
 1497|       |Compaction::Compaction(const Options* options, int level)
 1498|       |    : level_(level),
 1499|       |      max_output_file_size_(MaxFileSizeForLevel(options, level)),
 1500|       |      input_version_(nullptr),
 1501|       |      grandparent_index_(0),
 1502|       |      seen_key_(false),
 1503|      0|      overlapped_bytes_(0) {
 1504|      0|  for (int i = 0; i < config::kNumLevels; i++) {
 1505|      0|    level_ptrs_[i] = 0;
 1506|      0|  }
 1507|      0|}
 1508|       |
 1509|      0|Compaction::~Compaction() {
 1510|      0|  if (input_version_ != nullptr) {
 1511|      0|    input_version_->Unref();
 1512|      0|  }
 1513|      0|}
 1514|       |
 1515|      0|bool Compaction::IsTrivialMove() const {
 1516|      0|  const VersionSet* vset = input_version_->vset_;
 1517|      0|  // Avoid a move if there is lots of overlapping grandparent data.
 1518|      0|  // Otherwise, the move could create a parent file that will require
 1519|      0|  // a very expensive merge later on.
 1520|      0|  return (num_input_files(0) == 1 && num_input_files(1) == 0 &&
 1521|      0|          TotalFileSize(grandparents_) <=
 1522|      0|              MaxGrandParentOverlapBytes(vset->options_));
 1523|      0|}
 1524|       |
 1525|      0|void Compaction::AddInputDeletions(VersionEdit* edit) {
 1526|      0|  for (int which = 0; which < 2; which++) {
 1527|      0|    for (size_t i = 0; i < inputs_[which].size(); i++) {
 1528|      0|      edit->DeleteFile(level_ + which, inputs_[which][i]->number);
 1529|      0|    }
 1530|      0|  }
 1531|      0|}
 1532|       |
 1533|      0|bool Compaction::IsBaseLevelForKey(const Slice& user_key) {
 1534|      0|  // Maybe use binary search to find right entry instead of linear search?
 1535|      0|  const Comparator* user_cmp = input_version_->vset_->icmp_.user_comparator();
 1536|      0|  for (int lvl = level_ + 2; lvl < config::kNumLevels; lvl++) {
 1537|      0|    const std::vector<FileMetaData*>& files = input_version_->files_[lvl];
 1538|      0|    for (; level_ptrs_[lvl] < files.size();) {
 1539|      0|      FileMetaData* f = files[level_ptrs_[lvl]];
 1540|      0|      if (user_cmp->Compare(user_key, f->largest.user_key()) <= 0) {
 1541|      0|        // We've advanced far enough
 1542|      0|        if (user_cmp->Compare(user_key, f->smallest.user_key()) >= 0) {
 1543|      0|          // Key falls in this file's range, so definitely not base level
 1544|      0|          return false;
 1545|      0|        }
 1546|      0|        break;
 1547|      0|      }
 1548|      0|      level_ptrs_[lvl]++;
 1549|      0|    }
 1550|      0|  }
 1551|      0|  return true;
 1552|      0|}
 1553|       |
 1554|      0|bool Compaction::ShouldStopBefore(const Slice& internal_key) {
 1555|      0|  const VersionSet* vset = input_version_->vset_;
 1556|      0|  // Scan to find earliest grandparent file that contains key.
 1557|      0|  const InternalKeyComparator* icmp = &vset->icmp_;
 1558|      0|  while (grandparent_index_ < grandparents_.size() &&
 1559|      0|         icmp->Compare(internal_key,
 1560|      0|                       grandparents_[grandparent_index_]->largest.Encode()) >
 1561|      0|             0) {
 1562|      0|    if (seen_key_) {
 1563|      0|      overlapped_bytes_ += grandparents_[grandparent_index_]->file_size;
 1564|      0|    }
 1565|      0|    grandparent_index_++;
 1566|      0|  }
 1567|      0|  seen_key_ = true;
 1568|      0|
 1569|      0|  if (overlapped_bytes_ > MaxGrandParentOverlapBytes(vset->options_)) {
 1570|      0|    // Too much overlap for current output; start new output
 1571|      0|    overlapped_bytes_ = 0;
 1572|      0|    return true;
 1573|      0|  } else {
 1574|      0|    return false;
 1575|      0|  }
 1576|      0|}
 1577|       |
 1578|      0|void Compaction::ReleaseInputs() {
 1579|      0|  if (input_version_ != nullptr) {
 1580|      0|    input_version_->Unref();
 1581|      0|    input_version_ = nullptr;
 1582|      0|  }
 1583|      0|}
 1584|       |
 1585|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/version_set.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// The representation of a DBImpl consists of a set of Versions.  The
    6|       |// newest version is called "current".  Older versions may be kept
    7|       |// around to provide a consistent view to live iterators.
    8|       |//
    9|       |// Each Version keeps track of a set of Table files per level.  The
   10|       |// entire set of versions is maintained in a VersionSet.
   11|       |//
   12|       |// Version,VersionSet are thread-compatible, but require external
   13|       |// synchronization on all accesses.
   14|       |
   15|       |#ifndef STORAGE_LEVELDB_DB_VERSION_SET_H_
   16|       |#define STORAGE_LEVELDB_DB_VERSION_SET_H_
   17|       |
   18|       |#include <map>
   19|       |#include <set>
   20|       |#include <vector>
   21|       |
   22|       |#include "db/dbformat.h"
   23|       |#include "db/version_edit.h"
   24|       |#include "port/port.h"
   25|       |#include "port/thread_annotations.h"
   26|       |
   27|       |namespace leveldb {
   28|       |
   29|       |namespace log {
   30|       |class Writer;
   31|       |}
   32|       |
   33|       |class Compaction;
   34|       |class Iterator;
   35|       |class MemTable;
   36|       |class TableBuilder;
   37|       |class TableCache;
   38|       |class Version;
   39|       |class VersionSet;
   40|       |class WritableFile;
   41|       |
   42|       |// Return the smallest index i such that files[i]->largest >= key.
   43|       |// Return files.size() if there is no such file.
   44|       |// REQUIRES: "files" contains a sorted list of non-overlapping files.
   45|       |int FindFile(const InternalKeyComparator& icmp,
   46|       |             const std::vector<FileMetaData*>& files, const Slice& key);
   47|       |
   48|       |// Returns true iff some file in "files" overlaps the user key range
   49|       |// [*smallest,*largest].
   50|       |// smallest==nullptr represents a key smaller than all keys in the DB.
   51|       |// largest==nullptr represents a key largest than all keys in the DB.
   52|       |// REQUIRES: If disjoint_sorted_files, files[] contains disjoint ranges
   53|       |//           in sorted order.
   54|       |bool SomeFileOverlapsRange(const InternalKeyComparator& icmp,
   55|       |                           bool disjoint_sorted_files,
   56|       |                           const std::vector<FileMetaData*>& files,
   57|       |                           const Slice* smallest_user_key,
   58|       |                           const Slice* largest_user_key);
   59|       |
   60|       |class Version {
   61|       | public:
   62|       |  // Lookup the value for key.  If found, store it in *val and
   63|       |  // return OK.  Else return a non-OK status.  Fills *stats.
   64|       |  // REQUIRES: lock is not held
   65|       |  struct GetStats {
   66|       |    FileMetaData* seek_file;
   67|       |    int seek_file_level;
   68|       |  };
   69|       |
   70|       |  // Append to *iters a sequence of iterators that will
   71|       |  // yield the contents of this Version when merged together.
   72|       |  // REQUIRES: This version has been saved (see VersionSet::SaveTo)
   73|       |  void AddIterators(const ReadOptions&, std::vector<Iterator*>* iters);
   74|       |
   75|       |  Status Get(const ReadOptions&, const LookupKey& key, std::string* val,
   76|       |             GetStats* stats);
   77|       |
   78|       |  // Adds "stats" into the current state.  Returns true if a new
   79|       |  // compaction may need to be triggered, false otherwise.
   80|       |  // REQUIRES: lock is held
   81|       |  bool UpdateStats(const GetStats& stats);
   82|       |
   83|       |  // Record a sample of bytes read at the specified internal key.
   84|       |  // Samples are taken approximately once every config::kReadBytesPeriod
   85|       |  // bytes.  Returns true if a new compaction may need to be triggered.
   86|       |  // REQUIRES: lock is held
   87|       |  bool RecordReadSample(Slice key);
   88|       |
   89|       |  // Reference count management (so Versions do not disappear out from
   90|       |  // under live iterators)
   91|       |  void Ref();
   92|       |  void Unref();
   93|       |
   94|       |  void GetOverlappingInputs(
   95|       |      int level,
   96|       |      const InternalKey* begin,  // nullptr means before all keys
   97|       |      const InternalKey* end,    // nullptr means after all keys
   98|       |      std::vector<FileMetaData*>* inputs);
   99|       |
  100|       |  // Returns true iff some file in the specified level overlaps
  101|       |  // some part of [*smallest_user_key,*largest_user_key].
  102|       |  // smallest_user_key==nullptr represents a key smaller than all the DB's keys.
  103|       |  // largest_user_key==nullptr represents a key largest than all the DB's keys.
  104|       |  bool OverlapInLevel(int level, const Slice* smallest_user_key,
  105|       |                      const Slice* largest_user_key);
  106|       |
  107|       |  // Return the level at which we should place a new memtable compaction
  108|       |  // result that covers the range [smallest_user_key,largest_user_key].
  109|       |  int PickLevelForMemTableOutput(const Slice& smallest_user_key,
  110|       |                                 const Slice& largest_user_key);
  111|       |
  112|      0|  int NumFiles(int level) const { return files_[level].size(); }
  113|       |
  114|       |  // Return a human readable string that describes this version's contents.
  115|       |  std::string DebugString() const;
  116|       |
  117|       | private:
  118|       |  friend class Compaction;
  119|       |  friend class VersionSet;
  120|       |
  121|       |  class LevelFileNumIterator;
  122|       |
  123|       |  explicit Version(VersionSet* vset)
  124|       |      : vset_(vset),
  125|       |        next_(this),
  126|       |        prev_(this),
  127|       |        refs_(0),
  128|       |        file_to_compact_(nullptr),
  129|       |        file_to_compact_level_(-1),
  130|       |        compaction_score_(-1),
  131|      0|        compaction_level_(-1) {}
  132|       |
  133|       |  Version(const Version&) = delete;
  134|       |  Version& operator=(const Version&) = delete;
  135|       |
  136|       |  ~Version();
  137|       |
  138|       |  Iterator* NewConcatenatingIterator(const ReadOptions&, int level) const;
  139|       |
  140|       |  // Call func(arg, level, f) for every file that overlaps user_key in
  141|       |  // order from newest to oldest.  If an invocation of func returns
  142|       |  // false, makes no more calls.
  143|       |  //
  144|       |  // REQUIRES: user portion of internal_key == user_key.
  145|       |  void ForEachOverlapping(Slice user_key, Slice internal_key, void* arg,
  146|       |                          bool (*func)(void*, int, FileMetaData*));
  147|       |
  148|       |  VersionSet* vset_;  // VersionSet to which this Version belongs
  149|       |  Version* next_;     // Next version in linked list
  150|       |  Version* prev_;     // Previous version in linked list
  151|       |  int refs_;          // Number of live refs to this version
  152|       |
  153|       |  // List of files per level
  154|       |  std::vector<FileMetaData*> files_[config::kNumLevels];
  155|       |
  156|       |  // Next file to compact based on seek stats.
  157|       |  FileMetaData* file_to_compact_;
  158|       |  int file_to_compact_level_;
  159|       |
  160|       |  // Level that should be compacted next and its compaction score.
  161|       |  // Score < 1 means compaction is not strictly needed.  These fields
  162|       |  // are initialized by Finalize().
  163|       |  double compaction_score_;
  164|       |  int compaction_level_;
  165|       |};
  166|       |
  167|       |class VersionSet {
  168|       | public:
  169|       |  VersionSet(const std::string& dbname, const Options* options,
  170|       |             TableCache* table_cache, const InternalKeyComparator*);
  171|       |  VersionSet(const VersionSet&) = delete;
  172|       |  VersionSet& operator=(const VersionSet&) = delete;
  173|       |
  174|       |  ~VersionSet();
  175|       |
  176|       |  // Apply *edit to the current version to form a new descriptor that
  177|       |  // is both saved to persistent state and installed as the new
  178|       |  // current version.  Will release *mu while actually writing to the file.
  179|       |  // REQUIRES: *mu is held on entry.
  180|       |  // REQUIRES: no other thread concurrently calls LogAndApply()
  181|       |  Status LogAndApply(VersionEdit* edit, port::Mutex* mu)
  182|       |      EXCLUSIVE_LOCKS_REQUIRED(mu);
  183|       |
  184|       |  // Recover the last saved descriptor from persistent storage.
  185|       |  Status Recover(bool* save_manifest);
  186|       |
  187|       |  // Return the current version.
  188|      0|  Version* current() const { return current_; }
  189|       |
  190|       |  // Return the current manifest file number
  191|      0|  uint64_t ManifestFileNumber() const { return manifest_file_number_; }
  192|       |
  193|       |  // Allocate and return a new file number
  194|      0|  uint64_t NewFileNumber() { return next_file_number_++; }
  195|       |
  196|       |  // Arrange to reuse "file_number" unless a newer file number has
  197|       |  // already been allocated.
  198|       |  // REQUIRES: "file_number" was returned by a call to NewFileNumber().
  199|      0|  void ReuseFileNumber(uint64_t file_number) {
  200|      0|    if (next_file_number_ == file_number + 1) {
  201|      0|      next_file_number_ = file_number;
  202|      0|    }
  203|      0|  }
  204|       |
  205|       |  // Return the number of Table files at the specified level.
  206|       |  int NumLevelFiles(int level) const;
  207|       |
  208|       |  // Return the combined file size of all files at the specified level.
  209|       |  int64_t NumLevelBytes(int level) const;
  210|       |
  211|       |  // Return the last sequence number.
  212|      0|  uint64_t LastSequence() const { return last_sequence_; }
  213|       |
  214|       |  // Set the last sequence number to s.
  215|      0|  void SetLastSequence(uint64_t s) {
  216|      0|    assert(s >= last_sequence_);
  217|      0|    last_sequence_ = s;
  218|      0|  }
  219|       |
  220|       |  // Mark the specified file number as used.
  221|       |  void MarkFileNumberUsed(uint64_t number);
  222|       |
  223|       |  // Return the current log file number.
  224|      0|  uint64_t LogNumber() const { return log_number_; }
  225|       |
  226|       |  // Return the log file number for the log file that is currently
  227|       |  // being compacted, or zero if there is no such log file.
  228|      0|  uint64_t PrevLogNumber() const { return prev_log_number_; }
  229|       |
  230|       |  // Pick level and inputs for a new compaction.
  231|       |  // Returns nullptr if there is no compaction to be done.
  232|       |  // Otherwise returns a pointer to a heap-allocated object that
  233|       |  // describes the compaction.  Caller should delete the result.
  234|       |  Compaction* PickCompaction();
  235|       |
  236|       |  // Return a compaction object for compacting the range [begin,end] in
  237|       |  // the specified level.  Returns nullptr if there is nothing in that
  238|       |  // level that overlaps the specified range.  Caller should delete
  239|       |  // the result.
  240|       |  Compaction* CompactRange(int level, const InternalKey* begin,
  241|       |                           const InternalKey* end);
  242|       |
  243|       |  // Return the maximum overlapping data (in bytes) at next level for any
  244|       |  // file at a level >= 1.
  245|       |  int64_t MaxNextLevelOverlappingBytes();
  246|       |
  247|       |  // Create an iterator that reads over the compaction inputs for "*c".
  248|       |  // The caller should delete the iterator when no longer needed.
  249|       |  Iterator* MakeInputIterator(Compaction* c);
  250|       |
  251|       |  // Returns true iff some level needs a compaction.
  252|      0|  bool NeedsCompaction() const {
  253|      0|    Version* v = current_;
  254|      0|    return (v->compaction_score_ >= 1) || (v->file_to_compact_ != nullptr);
  255|      0|  }
  256|       |
  257|       |  // Add all files listed in any live version to *live.
  258|       |  // May also mutate some internal state.
  259|       |  void AddLiveFiles(std::set<uint64_t>* live);
  260|       |
  261|       |  // Return the approximate offset in the database of the data for
  262|       |  // "key" as of version "v".
  263|       |  uint64_t ApproximateOffsetOf(Version* v, const InternalKey& key);
  264|       |
  265|       |  // Return a human-readable short (single-line) summary of the number
  266|       |  // of files per level.  Uses *scratch as backing store.
  267|       |  struct LevelSummaryStorage {
  268|       |    char buffer[100];
  269|       |  };
  270|       |  const char* LevelSummary(LevelSummaryStorage* scratch) const;
  271|       |
  272|       | private:
  273|       |  class Builder;
  274|       |
  275|       |  friend class Compaction;
  276|       |  friend class Version;
  277|       |
  278|       |  bool ReuseManifest(const std::string& dscname, const std::string& dscbase);
  279|       |
  280|       |  void Finalize(Version* v);
  281|       |
  282|       |  void GetRange(const std::vector<FileMetaData*>& inputs, InternalKey* smallest,
  283|       |                InternalKey* largest);
  284|       |
  285|       |  void GetRange2(const std::vector<FileMetaData*>& inputs1,
  286|       |                 const std::vector<FileMetaData*>& inputs2,
  287|       |                 InternalKey* smallest, InternalKey* largest);
  288|       |
  289|       |  void SetupOtherInputs(Compaction* c);
  290|       |
  291|       |  // Save current contents to *log
  292|       |  Status WriteSnapshot(log::Writer* log);
  293|       |
  294|       |  void AppendVersion(Version* v);
  295|       |
  296|       |  Env* const env_;
  297|       |  const std::string dbname_;
  298|       |  const Options* const options_;
  299|       |  TableCache* const table_cache_;
  300|       |  const InternalKeyComparator icmp_;
  301|       |  uint64_t next_file_number_;
  302|       |  uint64_t manifest_file_number_;
  303|       |  uint64_t last_sequence_;
  304|       |  uint64_t log_number_;
  305|       |  uint64_t prev_log_number_;  // 0 or backing store for memtable being compacted
  306|       |
  307|       |  // Opened lazily
  308|       |  WritableFile* descriptor_file_;
  309|       |  log::Writer* descriptor_log_;
  310|       |  Version dummy_versions_;  // Head of circular doubly-linked list of versions.
  311|       |  Version* current_;        // == dummy_versions_.prev_
  312|       |
  313|       |  // Per-level key at which the next compaction at that level should start.
  314|       |  // Either an empty string, or a valid InternalKey.
  315|       |  std::string compact_pointer_[config::kNumLevels];
  316|       |};
  317|       |
  318|       |// A Compaction encapsulates information about a compaction.
  319|       |class Compaction {
  320|       | public:
  321|       |  ~Compaction();
  322|       |
  323|       |  // Return the level that is being compacted.  Inputs from "level"
  324|       |  // and "level+1" will be merged to produce a set of "level+1" files.
  325|      0|  int level() const { return level_; }
  326|       |
  327|       |  // Return the object that holds the edits to the descriptor done
  328|       |  // by this compaction.
  329|      0|  VersionEdit* edit() { return &edit_; }
  330|       |
  331|       |  // "which" must be either 0 or 1
  332|      0|  int num_input_files(int which) const { return inputs_[which].size(); }
  333|       |
  334|       |  // Return the ith input file at "level()+which" ("which" must be 0 or 1).
  335|      0|  FileMetaData* input(int which, int i) const { return inputs_[which][i]; }
  336|       |
  337|       |  // Maximum size of files to build during this compaction.
  338|      0|  uint64_t MaxOutputFileSize() const { return max_output_file_size_; }
  339|       |
  340|       |  // Is this a trivial compaction that can be implemented by just
  341|       |  // moving a single input file to the next level (no merging or splitting)
  342|       |  bool IsTrivialMove() const;
  343|       |
  344|       |  // Add all inputs to this compaction as delete operations to *edit.
  345|       |  void AddInputDeletions(VersionEdit* edit);
  346|       |
  347|       |  // Returns true if the information we have available guarantees that
  348|       |  // the compaction is producing data in "level+1" for which no data exists
  349|       |  // in levels greater than "level+1".
  350|       |  bool IsBaseLevelForKey(const Slice& user_key);
  351|       |
  352|       |  // Returns true iff we should stop building the current output
  353|       |  // before processing "internal_key".
  354|       |  bool ShouldStopBefore(const Slice& internal_key);
  355|       |
  356|       |  // Release the input version for the compaction, once the compaction
  357|       |  // is successful.
  358|       |  void ReleaseInputs();
  359|       |
  360|       | private:
  361|       |  friend class Version;
  362|       |  friend class VersionSet;
  363|       |
  364|       |  Compaction(const Options* options, int level);
  365|       |
  366|       |  int level_;
  367|       |  uint64_t max_output_file_size_;
  368|       |  Version* input_version_;
  369|       |  VersionEdit edit_;
  370|       |
  371|       |  // Each compaction reads inputs from "level_" and "level_+1"
  372|       |  std::vector<FileMetaData*> inputs_[2];  // The two sets of inputs
  373|       |
  374|       |  // State used to check for number of overlapping grandparent files
  375|       |  // (parent == level_ + 1, grandparent == level_ + 2)
  376|       |  std::vector<FileMetaData*> grandparents_;
  377|       |  size_t grandparent_index_;  // Index in grandparent_starts_
  378|       |  bool seen_key_;             // Some output key has been seen
  379|       |  int64_t overlapped_bytes_;  // Bytes of overlap between current output
  380|       |                              // and grandparent files
  381|       |
  382|       |  // State for implementing IsBaseLevelForKey
  383|       |
  384|       |  // level_ptrs_ holds indices into input_version_->levels_: our state
  385|       |  // is that we are positioned at one of the file ranges for each
  386|       |  // higher level than the ones involved in this compaction (i.e. for
  387|       |  // all L >= level_ + 2).
  388|       |  size_t level_ptrs_[config::kNumLevels];
  389|       |};
  390|       |
  391|       |}  // namespace leveldb
  392|       |
  393|       |#endif  // STORAGE_LEVELDB_DB_VERSION_SET_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/write_batch.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// WriteBatch::rep_ :=
    6|       |//    sequence: fixed64
    7|       |//    count: fixed32
    8|       |//    data: record[count]
    9|       |// record :=
   10|       |//    kTypeValue varstring varstring         |
   11|       |//    kTypeDeletion varstring
   12|       |// varstring :=
   13|       |//    len: varint32
   14|       |//    data: uint8[len]
   15|       |
   16|       |#include "leveldb/write_batch.h"
   17|       |
   18|       |#include "db/dbformat.h"
   19|       |#include "db/memtable.h"
   20|       |#include "db/write_batch_internal.h"
   21|       |#include "leveldb/db.h"
   22|       |#include "util/coding.h"
   23|       |
   24|       |namespace leveldb {
   25|       |
   26|       |// WriteBatch header has an 8-byte sequence number followed by a 4-byte count.
   27|       |static const size_t kHeader = 12;
   28|       |
   29|      0|WriteBatch::WriteBatch() { Clear(); }
   30|       |
   31|      0|WriteBatch::~WriteBatch() {}
   32|       |
   33|      0|WriteBatch::Handler::~Handler() {}
   34|       |
   35|      0|void WriteBatch::Clear() {
   36|      0|  rep_.clear();
   37|      0|  rep_.resize(kHeader);
   38|      0|}
   39|       |
   40|      0|size_t WriteBatch::ApproximateSize() const { return rep_.size(); }
   41|       |
   42|      0|Status WriteBatch::Iterate(Handler* handler) const {
   43|      0|  Slice input(rep_);
   44|      0|  if (input.size() < kHeader) {
   45|      0|    return Status::Corruption("malformed WriteBatch (too small)");
   46|      0|  }
   47|      0|
   48|      0|  input.remove_prefix(kHeader);
   49|      0|  Slice key, value;
   50|      0|  int found = 0;
   51|      0|  while (!input.empty()) {
   52|      0|    found++;
   53|      0|    char tag = input[0];
   54|      0|    input.remove_prefix(1);
   55|      0|    switch (tag) {
   56|      0|      case kTypeValue:
   57|      0|        if (GetLengthPrefixedSlice(&input, &key) &&
   58|      0|            GetLengthPrefixedSlice(&input, &value)) {
   59|      0|          handler->Put(key, value);
   60|      0|        } else {
   61|      0|          return Status::Corruption("bad WriteBatch Put");
   62|      0|        }
   63|      0|        break;
   64|      0|      case kTypeDeletion:
   65|      0|        if (GetLengthPrefixedSlice(&input, &key)) {
   66|      0|          handler->Delete(key);
   67|      0|        } else {
   68|      0|          return Status::Corruption("bad WriteBatch Delete");
   69|      0|        }
   70|      0|        break;
   71|      0|      default:
   72|      0|        return Status::Corruption("unknown WriteBatch tag");
   73|      0|    }
   74|      0|  }
   75|      0|  if (found != WriteBatchInternal::Count(this)) {
   76|      0|    return Status::Corruption("WriteBatch has wrong count");
   77|      0|  } else {
   78|      0|    return Status::OK();
   79|      0|  }
   80|      0|}
   81|       |
   82|      0|int WriteBatchInternal::Count(const WriteBatch* b) {
   83|      0|  return DecodeFixed32(b->rep_.data() + 8);
   84|      0|}
   85|       |
   86|      0|void WriteBatchInternal::SetCount(WriteBatch* b, int n) {
   87|      0|  EncodeFixed32(&b->rep_[8], n);
   88|      0|}
   89|       |
   90|      0|SequenceNumber WriteBatchInternal::Sequence(const WriteBatch* b) {
   91|      0|  return SequenceNumber(DecodeFixed64(b->rep_.data()));
   92|      0|}
   93|       |
   94|      0|void WriteBatchInternal::SetSequence(WriteBatch* b, SequenceNumber seq) {
   95|      0|  EncodeFixed64(&b->rep_[0], seq);
   96|      0|}
   97|       |
   98|      0|void WriteBatch::Put(const Slice& key, const Slice& value) {
   99|      0|  WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1);
  100|      0|  rep_.push_back(static_cast<char>(kTypeValue));
  101|      0|  PutLengthPrefixedSlice(&rep_, key);
  102|      0|  PutLengthPrefixedSlice(&rep_, value);
  103|      0|}
  104|       |
  105|      0|void WriteBatch::Delete(const Slice& key) {
  106|      0|  WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1);
  107|      0|  rep_.push_back(static_cast<char>(kTypeDeletion));
  108|      0|  PutLengthPrefixedSlice(&rep_, key);
  109|      0|}
  110|       |
  111|      0|void WriteBatch::Append(const WriteBatch& source) {
  112|      0|  WriteBatchInternal::Append(this, &source);
  113|      0|}
  114|       |
  115|       |namespace {
  116|       |class MemTableInserter : public WriteBatch::Handler {
  117|       | public:
  118|       |  SequenceNumber sequence_;
  119|       |  MemTable* mem_;
  120|       |
  121|      0|  virtual void Put(const Slice& key, const Slice& value) {
  122|      0|    mem_->Add(sequence_, kTypeValue, key, value);
  123|      0|    sequence_++;
  124|      0|  }
  125|      0|  virtual void Delete(const Slice& key) {
  126|      0|    mem_->Add(sequence_, kTypeDeletion, key, Slice());
  127|      0|    sequence_++;
  128|      0|  }
  129|       |};
  130|       |}  // namespace
  131|       |
  132|      0|Status WriteBatchInternal::InsertInto(const WriteBatch* b, MemTable* memtable) {
  133|      0|  MemTableInserter inserter;
  134|      0|  inserter.sequence_ = WriteBatchInternal::Sequence(b);
  135|      0|  inserter.mem_ = memtable;
  136|      0|  return b->Iterate(&inserter);
  137|      0|}
  138|       |
  139|      0|void WriteBatchInternal::SetContents(WriteBatch* b, const Slice& contents) {
  140|      0|  assert(contents.size() >= kHeader);
  141|      0|  b->rep_.assign(contents.data(), contents.size());
  142|      0|}
  143|       |
  144|      0|void WriteBatchInternal::Append(WriteBatch* dst, const WriteBatch* src) {
  145|      0|  SetCount(dst, Count(dst) + Count(src));
  146|      0|  assert(src->rep_.size() >= kHeader);
  147|      0|  dst->rep_.append(src->rep_.data() + kHeader, src->rep_.size() - kHeader);
  148|      0|}
  149|       |
  150|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/db/write_batch_internal.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_DB_WRITE_BATCH_INTERNAL_H_
    6|       |#define STORAGE_LEVELDB_DB_WRITE_BATCH_INTERNAL_H_
    7|       |
    8|       |#include "db/dbformat.h"
    9|       |#include "leveldb/write_batch.h"
   10|       |
   11|       |namespace leveldb {
   12|       |
   13|       |class MemTable;
   14|       |
   15|       |// WriteBatchInternal provides static methods for manipulating a
   16|       |// WriteBatch that we don't want in the public WriteBatch interface.
   17|       |class WriteBatchInternal {
   18|       | public:
   19|       |  // Return the number of entries in the batch.
   20|       |  static int Count(const WriteBatch* batch);
   21|       |
   22|       |  // Set the count for the number of entries in the batch.
   23|       |  static void SetCount(WriteBatch* batch, int n);
   24|       |
   25|       |  // Return the sequence number for the start of this batch.
   26|       |  static SequenceNumber Sequence(const WriteBatch* batch);
   27|       |
   28|       |  // Store the specified number as the sequence number for the start of
   29|       |  // this batch.
   30|       |  static void SetSequence(WriteBatch* batch, SequenceNumber seq);
   31|       |
   32|      0|  static Slice Contents(const WriteBatch* batch) { return Slice(batch->rep_); }
   33|       |
   34|      0|  static size_t ByteSize(const WriteBatch* batch) { return batch->rep_.size(); }
   35|       |
   36|       |  static void SetContents(WriteBatch* batch, const Slice& contents);
   37|       |
   38|       |  static Status InsertInto(const WriteBatch* batch, MemTable* memtable);
   39|       |
   40|       |  static void Append(WriteBatch* dst, const WriteBatch* src);
   41|       |};
   42|       |
   43|       |}  // namespace leveldb
   44|       |
   45|       |#endif  // STORAGE_LEVELDB_DB_WRITE_BATCH_INTERNAL_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/include/leveldb/cache.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// A Cache is an interface that maps keys to values.  It has internal
    6|       |// synchronization and may be safely accessed concurrently from
    7|       |// multiple threads.  It may automatically evict entries to make room
    8|       |// for new entries.  Values have a specified charge against the cache
    9|       |// capacity.  For example, a cache where the values are variable
   10|       |// length strings, may use the length of the string as the charge for
   11|       |// the string.
   12|       |//
   13|       |// A builtin cache implementation with a least-recently-used eviction
   14|       |// policy is provided.  Clients may use their own implementations if
   15|       |// they want something more sophisticated (like scan-resistance, a
   16|       |// custom eviction policy, variable cache sizing, etc.)
   17|       |
   18|       |#ifndef STORAGE_LEVELDB_INCLUDE_CACHE_H_
   19|       |#define STORAGE_LEVELDB_INCLUDE_CACHE_H_
   20|       |
   21|       |#include <stdint.h>
   22|       |
   23|       |#include "leveldb/export.h"
   24|       |#include "leveldb/slice.h"
   25|       |
   26|       |namespace leveldb {
   27|       |
   28|       |class LEVELDB_EXPORT Cache;
   29|       |
   30|       |// Create a new cache with a fixed size capacity.  This implementation
   31|       |// of Cache uses a least-recently-used eviction policy.
   32|       |LEVELDB_EXPORT Cache* NewLRUCache(size_t capacity);
   33|       |
   34|       |class LEVELDB_EXPORT Cache {
   35|       | public:
   36|      0|  Cache() = default;
   37|       |
   38|       |  Cache(const Cache&) = delete;
   39|       |  Cache& operator=(const Cache&) = delete;
   40|       |
   41|       |  // Destroys all existing entries by calling the "deleter"
   42|       |  // function that was passed to the constructor.
   43|       |  virtual ~Cache();
   44|       |
   45|       |  // Opaque handle to an entry stored in the cache.
   46|       |  struct Handle {};
   47|       |
   48|       |  // Insert a mapping from key->value into the cache and assign it
   49|       |  // the specified charge against the total cache capacity.
   50|       |  //
   51|       |  // Returns a handle that corresponds to the mapping.  The caller
   52|       |  // must call this->Release(handle) when the returned mapping is no
   53|       |  // longer needed.
   54|       |  //
   55|       |  // When the inserted entry is no longer needed, the key and
   56|       |  // value will be passed to "deleter".
   57|       |  virtual Handle* Insert(const Slice& key, void* value, size_t charge,
   58|       |                         void (*deleter)(const Slice& key, void* value)) = 0;
   59|       |
   60|       |  // If the cache has no mapping for "key", returns nullptr.
   61|       |  //
   62|       |  // Else return a handle that corresponds to the mapping.  The caller
   63|       |  // must call this->Release(handle) when the returned mapping is no
   64|       |  // longer needed.
   65|       |  virtual Handle* Lookup(const Slice& key) = 0;
   66|       |
   67|       |  // Release a mapping returned by a previous Lookup().
   68|       |  // REQUIRES: handle must not have been released yet.
   69|       |  // REQUIRES: handle must have been returned by a method on *this.
   70|       |  virtual void Release(Handle* handle) = 0;
   71|       |
   72|       |  // Return the value encapsulated in a handle returned by a
   73|       |  // successful Lookup().
   74|       |  // REQUIRES: handle must not have been released yet.
   75|       |  // REQUIRES: handle must have been returned by a method on *this.
   76|       |  virtual void* Value(Handle* handle) = 0;
   77|       |
   78|       |  // If the cache contains entry for key, erase it.  Note that the
   79|       |  // underlying entry will be kept around until all existing handles
   80|       |  // to it have been released.
   81|       |  virtual void Erase(const Slice& key) = 0;
   82|       |
   83|       |  // Return a new numeric id.  May be used by multiple clients who are
   84|       |  // sharing the same cache to partition the key space.  Typically the
   85|       |  // client will allocate a new id at startup and prepend the id to
   86|       |  // its cache keys.
   87|       |  virtual uint64_t NewId() = 0;
   88|       |
   89|       |  // Remove all cache entries that are not actively in use.  Memory-constrained
   90|       |  // applications may wish to call this method to reduce memory usage.
   91|       |  // Default implementation of Prune() does nothing.  Subclasses are strongly
   92|       |  // encouraged to override the default implementation.  A future release of
   93|       |  // leveldb may change Prune() to a pure abstract method.
   94|      0|  virtual void Prune() {}
   95|       |
   96|       |  // Return an estimate of the combined charges of all elements stored in the
   97|       |  // cache.
   98|       |  virtual size_t TotalCharge() const = 0;
   99|       |
  100|       | private:
  101|       |  void LRU_Remove(Handle* e);
  102|       |  void LRU_Append(Handle* e);
  103|       |  void Unref(Handle* e);
  104|       |
  105|       |  struct Rep;
  106|       |  Rep* rep_;
  107|       |};
  108|       |
  109|       |}  // namespace leveldb
  110|       |
  111|       |#endif  // STORAGE_LEVELDB_INCLUDE_CACHE_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/include/leveldb/db.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_INCLUDE_DB_H_
    6|       |#define STORAGE_LEVELDB_INCLUDE_DB_H_
    7|       |
    8|       |#include <stdint.h>
    9|       |#include <stdio.h>
   10|       |
   11|       |#include "leveldb/export.h"
   12|       |#include "leveldb/iterator.h"
   13|       |#include "leveldb/options.h"
   14|       |
   15|       |namespace leveldb {
   16|       |
   17|       |// Update CMakeLists.txt if you change these
   18|       |static const int kMajorVersion = 1;
   19|       |static const int kMinorVersion = 22;
   20|       |
   21|       |struct Options;
   22|       |struct ReadOptions;
   23|       |struct WriteOptions;
   24|       |class WriteBatch;
   25|       |
   26|       |// Abstract handle to particular state of a DB.
   27|       |// A Snapshot is an immutable object and can therefore be safely
   28|       |// accessed from multiple threads without any external synchronization.
   29|       |class LEVELDB_EXPORT Snapshot {
   30|       | protected:
   31|       |  virtual ~Snapshot();
   32|       |};
   33|       |
   34|       |// A range of keys
   35|       |struct LEVELDB_EXPORT Range {
   36|      0|  Range() {}
   37|      0|  Range(const Slice& s, const Slice& l) : start(s), limit(l) {}
   38|       |
   39|       |  Slice start;  // Included in the range
   40|       |  Slice limit;  // Not included in the range
   41|       |};
   42|       |
   43|       |// A DB is a persistent ordered map from keys to values.
   44|       |// A DB is safe for concurrent access from multiple threads without
   45|       |// any external synchronization.
   46|       |class LEVELDB_EXPORT DB {
   47|       | public:
   48|       |  // Open the database with the specified "name".
   49|       |  // Stores a pointer to a heap-allocated database in *dbptr and returns
   50|       |  // OK on success.
   51|       |  // Stores nullptr in *dbptr and returns a non-OK status on error.
   52|       |  // Caller should delete *dbptr when it is no longer needed.
   53|       |  static Status Open(const Options& options, const std::string& name,
   54|       |                     DB** dbptr);
   55|       |
   56|      0|  DB() = default;
   57|       |
   58|       |  DB(const DB&) = delete;
   59|       |  DB& operator=(const DB&) = delete;
   60|       |
   61|       |  virtual ~DB();
   62|       |
   63|       |  // Set the database entry for "key" to "value".  Returns OK on success,
   64|       |  // and a non-OK status on error.
   65|       |  // Note: consider setting options.sync = true.
   66|       |  virtual Status Put(const WriteOptions& options, const Slice& key,
   67|       |                     const Slice& value) = 0;
   68|       |
   69|       |  // Remove the database entry (if any) for "key".  Returns OK on
   70|       |  // success, and a non-OK status on error.  It is not an error if "key"
   71|       |  // did not exist in the database.
   72|       |  // Note: consider setting options.sync = true.
   73|       |  virtual Status Delete(const WriteOptions& options, const Slice& key) = 0;
   74|       |
   75|       |  // Apply the specified updates to the database.
   76|       |  // Returns OK on success, non-OK on failure.
   77|       |  // Note: consider setting options.sync = true.
   78|       |  virtual Status Write(const WriteOptions& options, WriteBatch* updates) = 0;
   79|       |
   80|       |  // If the database contains an entry for "key" store the
   81|       |  // corresponding value in *value and return OK.
   82|       |  //
   83|       |  // If there is no entry for "key" leave *value unchanged and return
   84|       |  // a status for which Status::IsNotFound() returns true.
   85|       |  //
   86|       |  // May return some other Status on an error.
   87|       |  virtual Status Get(const ReadOptions& options, const Slice& key,
   88|       |                     std::string* value) = 0;
   89|       |
   90|       |  // Return a heap-allocated iterator over the contents of the database.
   91|       |  // The result of NewIterator() is initially invalid (caller must
   92|       |  // call one of the Seek methods on the iterator before using it).
   93|       |  //
   94|       |  // Caller should delete the iterator when it is no longer needed.
   95|       |  // The returned iterator should be deleted before this db is deleted.
   96|       |  virtual Iterator* NewIterator(const ReadOptions& options) = 0;
   97|       |
   98|       |  // Return a handle to the current DB state.  Iterators created with
   99|       |  // this handle will all observe a stable snapshot of the current DB
  100|       |  // state.  The caller must call ReleaseSnapshot(result) when the
  101|       |  // snapshot is no longer needed.
  102|       |  virtual const Snapshot* GetSnapshot() = 0;
  103|       |
  104|       |  // Release a previously acquired snapshot.  The caller must not
  105|       |  // use "snapshot" after this call.
  106|       |  virtual void ReleaseSnapshot(const Snapshot* snapshot) = 0;
  107|       |
  108|       |  // DB implementations can export properties about their state
  109|       |  // via this method.  If "property" is a valid property understood by this
  110|       |  // DB implementation, fills "*value" with its current value and returns
  111|       |  // true.  Otherwise returns false.
  112|       |  //
  113|       |  //
  114|       |  // Valid property names include:
  115|       |  //
  116|       |  //  "leveldb.num-files-at-level<N>" - return the number of files at level <N>,
  117|       |  //     where <N> is an ASCII representation of a level number (e.g. "0").
  118|       |  //  "leveldb.stats" - returns a multi-line string that describes statistics
  119|       |  //     about the internal operation of the DB.
  120|       |  //  "leveldb.sstables" - returns a multi-line string that describes all
  121|       |  //     of the sstables that make up the db contents.
  122|       |  //  "leveldb.approximate-memory-usage" - returns the approximate number of
  123|       |  //     bytes of memory in use by the DB.
  124|       |  virtual bool GetProperty(const Slice& property, std::string* value) = 0;
  125|       |
  126|       |  // For each i in [0,n-1], store in "sizes[i]", the approximate
  127|       |  // file system space used by keys in "[range[i].start .. range[i].limit)".
  128|       |  //
  129|       |  // Note that the returned sizes measure file system space usage, so
  130|       |  // if the user data compresses by a factor of ten, the returned
  131|       |  // sizes will be one-tenth the size of the corresponding user data size.
  132|       |  //
  133|       |  // The results may not include the sizes of recently written data.
  134|       |  virtual void GetApproximateSizes(const Range* range, int n,
  135|       |                                   uint64_t* sizes) = 0;
  136|       |
  137|       |  // Compact the underlying storage for the key range [*begin,*end].
  138|       |  // In particular, deleted and overwritten versions are discarded,
  139|       |  // and the data is rearranged to reduce the cost of operations
  140|       |  // needed to access the data.  This operation should typically only
  141|       |  // be invoked by users who understand the underlying implementation.
  142|       |  //
  143|       |  // begin==nullptr is treated as a key before all keys in the database.
  144|       |  // end==nullptr is treated as a key after all keys in the database.
  145|       |  // Therefore the following call will compact the entire database:
  146|       |  //    db->CompactRange(nullptr, nullptr);
  147|       |  virtual void CompactRange(const Slice* begin, const Slice* end) = 0;
  148|       |};
  149|       |
  150|       |// Destroy the contents of the specified database.
  151|       |// Be very careful using this method.
  152|       |//
  153|       |// Note: For backwards compatibility, if DestroyDB is unable to list the
  154|       |// database files, Status::OK() will still be returned masking this failure.
  155|       |LEVELDB_EXPORT Status DestroyDB(const std::string& name,
  156|       |                                const Options& options);
  157|       |
  158|       |// If a DB cannot be opened, you may attempt to call this method to
  159|       |// resurrect as much of the contents of the database as possible.
  160|       |// Some data may be lost, so be careful when calling this function
  161|       |// on a database that contains important information.
  162|       |LEVELDB_EXPORT Status RepairDB(const std::string& dbname,
  163|       |                               const Options& options);
  164|       |
  165|       |}  // namespace leveldb
  166|       |
  167|       |#endif  // STORAGE_LEVELDB_INCLUDE_DB_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/include/leveldb/env.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// An Env is an interface used by the leveldb implementation to access
    6|       |// operating system functionality like the filesystem etc.  Callers
    7|       |// may wish to provide a custom Env object when opening a database to
    8|       |// get fine gain control; e.g., to rate limit file system operations.
    9|       |//
   10|       |// All Env implementations are safe for concurrent access from
   11|       |// multiple threads without any external synchronization.
   12|       |
   13|       |#ifndef STORAGE_LEVELDB_INCLUDE_ENV_H_
   14|       |#define STORAGE_LEVELDB_INCLUDE_ENV_H_
   15|       |
   16|       |#include <stdarg.h>
   17|       |#include <stdint.h>
   18|       |
   19|       |#include <string>
   20|       |#include <vector>
   21|       |
   22|       |#include "leveldb/export.h"
   23|       |#include "leveldb/status.h"
   24|       |
   25|       |#if defined(_WIN32)
   26|       |// The leveldb::Env class below contains a DeleteFile method.
   27|       |// At the same time, <windows.h>, a fairly popular header
   28|       |// file for Windows applications, defines a DeleteFile macro.
   29|       |//
   30|       |// Without any intervention on our part, the result of this
   31|       |// unfortunate coincidence is that the name of the
   32|       |// leveldb::Env::DeleteFile method seen by the compiler depends on
   33|       |// whether <windows.h> was included before or after the LevelDB
   34|       |// headers.
   35|       |//
   36|       |// To avoid headaches, we undefined DeleteFile (if defined) and
   37|       |// redefine it at the bottom of this file. This way <windows.h>
   38|       |// can be included before this file (or not at all) and the
   39|       |// exported method will always be leveldb::Env::DeleteFile.
   40|       |#if defined(DeleteFile)
   41|       |#undef DeleteFile
   42|       |#define LEVELDB_DELETEFILE_UNDEFINED
   43|       |#endif  // defined(DeleteFile)
   44|       |#endif  // defined(_WIN32)
   45|       |
   46|       |namespace leveldb {
   47|       |
   48|       |class FileLock;
   49|       |class Logger;
   50|       |class RandomAccessFile;
   51|       |class SequentialFile;
   52|       |class Slice;
   53|       |class WritableFile;
   54|       |
   55|       |class LEVELDB_EXPORT Env {
   56|       | public:
   57|      0|  Env() = default;
   58|       |
   59|       |  Env(const Env&) = delete;
   60|       |  Env& operator=(const Env&) = delete;
   61|       |
   62|       |  virtual ~Env();
   63|       |
   64|       |  // Return a default environment suitable for the current operating
   65|       |  // system.  Sophisticated users may wish to provide their own Env
   66|       |  // implementation instead of relying on this default environment.
   67|       |  //
   68|       |  // The result of Default() belongs to leveldb and must never be deleted.
   69|       |  static Env* Default();
   70|       |
   71|       |  // Create an object that sequentially reads the file with the specified name.
   72|       |  // On success, stores a pointer to the new file in *result and returns OK.
   73|       |  // On failure stores nullptr in *result and returns non-OK.  If the file does
   74|       |  // not exist, returns a non-OK status.  Implementations should return a
   75|       |  // NotFound status when the file does not exist.
   76|       |  //
   77|       |  // The returned file will only be accessed by one thread at a time.
   78|       |  virtual Status NewSequentialFile(const std::string& fname,
   79|       |                                   SequentialFile** result) = 0;
   80|       |
   81|       |  // Create an object supporting random-access reads from the file with the
   82|       |  // specified name.  On success, stores a pointer to the new file in
   83|       |  // *result and returns OK.  On failure stores nullptr in *result and
   84|       |  // returns non-OK.  If the file does not exist, returns a non-OK
   85|       |  // status.  Implementations should return a NotFound status when the file does
   86|       |  // not exist.
   87|       |  //
   88|       |  // The returned file may be concurrently accessed by multiple threads.
   89|       |  virtual Status NewRandomAccessFile(const std::string& fname,
   90|       |                                     RandomAccessFile** result) = 0;
   91|       |
   92|       |  // Create an object that writes to a new file with the specified
   93|       |  // name.  Deletes any existing file with the same name and creates a
   94|       |  // new file.  On success, stores a pointer to the new file in
   95|       |  // *result and returns OK.  On failure stores nullptr in *result and
   96|       |  // returns non-OK.
   97|       |  //
   98|       |  // The returned file will only be accessed by one thread at a time.
   99|       |  virtual Status NewWritableFile(const std::string& fname,
  100|       |                                 WritableFile** result) = 0;
  101|       |
  102|       |  // Create an object that either appends to an existing file, or
  103|       |  // writes to a new file (if the file does not exist to begin with).
  104|       |  // On success, stores a pointer to the new file in *result and
  105|       |  // returns OK.  On failure stores nullptr in *result and returns
  106|       |  // non-OK.
  107|       |  //
  108|       |  // The returned file will only be accessed by one thread at a time.
  109|       |  //
  110|       |  // May return an IsNotSupportedError error if this Env does
  111|       |  // not allow appending to an existing file.  Users of Env (including
  112|       |  // the leveldb implementation) must be prepared to deal with
  113|       |  // an Env that does not support appending.
  114|       |  virtual Status NewAppendableFile(const std::string& fname,
  115|       |                                   WritableFile** result);
  116|       |
  117|       |  // Returns true iff the named file exists.
  118|       |  virtual bool FileExists(const std::string& fname) = 0;
  119|       |
  120|       |  // Store in *result the names of the children of the specified directory.
  121|       |  // The names are relative to "dir".
  122|       |  // Original contents of *results are dropped.
  123|       |  virtual Status GetChildren(const std::string& dir,
  124|       |                             std::vector<std::string>* result) = 0;
  125|       |
  126|       |  // Delete the named file.
  127|       |  virtual Status DeleteFile(const std::string& fname) = 0;
  128|       |
  129|       |  // Create the specified directory.
  130|       |  virtual Status CreateDir(const std::string& dirname) = 0;
  131|       |
  132|       |  // Delete the specified directory.
  133|       |  virtual Status DeleteDir(const std::string& dirname) = 0;
  134|       |
  135|       |  // Store the size of fname in *file_size.
  136|       |  virtual Status GetFileSize(const std::string& fname, uint64_t* file_size) = 0;
  137|       |
  138|       |  // Rename file src to target.
  139|       |  virtual Status RenameFile(const std::string& src,
  140|       |                            const std::string& target) = 0;
  141|       |
  142|       |  // Lock the specified file.  Used to prevent concurrent access to
  143|       |  // the same db by multiple processes.  On failure, stores nullptr in
  144|       |  // *lock and returns non-OK.
  145|       |  //
  146|       |  // On success, stores a pointer to the object that represents the
  147|       |  // acquired lock in *lock and returns OK.  The caller should call
  148|       |  // UnlockFile(*lock) to release the lock.  If the process exits,
  149|       |  // the lock will be automatically released.
  150|       |  //
  151|       |  // If somebody else already holds the lock, finishes immediately
  152|       |  // with a failure.  I.e., this call does not wait for existing locks
  153|       |  // to go away.
  154|       |  //
  155|       |  // May create the named file if it does not already exist.
  156|       |  virtual Status LockFile(const std::string& fname, FileLock** lock) = 0;
  157|       |
  158|       |  // Release the lock acquired by a previous successful call to LockFile.
  159|       |  // REQUIRES: lock was returned by a successful LockFile() call
  160|       |  // REQUIRES: lock has not already been unlocked.
  161|       |  virtual Status UnlockFile(FileLock* lock) = 0;
  162|       |
  163|       |  // Arrange to run "(*function)(arg)" once in a background thread.
  164|       |  //
  165|       |  // "function" may run in an unspecified thread.  Multiple functions
  166|       |  // added to the same Env may run concurrently in different threads.
  167|       |  // I.e., the caller may not assume that background work items are
  168|       |  // serialized.
  169|       |  virtual void Schedule(void (*function)(void* arg), void* arg) = 0;
  170|       |
  171|       |  // Start a new thread, invoking "function(arg)" within the new thread.
  172|       |  // When "function(arg)" returns, the thread will be destroyed.
  173|       |  virtual void StartThread(void (*function)(void* arg), void* arg) = 0;
  174|       |
  175|       |  // *path is set to a temporary directory that can be used for testing. It may
  176|       |  // or may not have just been created. The directory may or may not differ
  177|       |  // between runs of the same process, but subsequent calls will return the
  178|       |  // same directory.
  179|       |  virtual Status GetTestDirectory(std::string* path) = 0;
  180|       |
  181|       |  // Create and return a log file for storing informational messages.
  182|       |  virtual Status NewLogger(const std::string& fname, Logger** result) = 0;
  183|       |
  184|       |  // Returns the number of micro-seconds since some fixed point in time. Only
  185|       |  // useful for computing deltas of time.
  186|       |  virtual uint64_t NowMicros() = 0;
  187|       |
  188|       |  // Sleep/delay the thread for the prescribed number of micro-seconds.
  189|       |  virtual void SleepForMicroseconds(int micros) = 0;
  190|       |};
  191|       |
  192|       |// A file abstraction for reading sequentially through a file
  193|       |class LEVELDB_EXPORT SequentialFile {
  194|       | public:
  195|      0|  SequentialFile() = default;
  196|       |
  197|       |  SequentialFile(const SequentialFile&) = delete;
  198|       |  SequentialFile& operator=(const SequentialFile&) = delete;
  199|       |
  200|       |  virtual ~SequentialFile();
  201|       |
  202|       |  // Read up to "n" bytes from the file.  "scratch[0..n-1]" may be
  203|       |  // written by this routine.  Sets "*result" to the data that was
  204|       |  // read (including if fewer than "n" bytes were successfully read).
  205|       |  // May set "*result" to point at data in "scratch[0..n-1]", so
  206|       |  // "scratch[0..n-1]" must be live when "*result" is used.
  207|       |  // If an error was encountered, returns a non-OK status.
  208|       |  //
  209|       |  // REQUIRES: External synchronization
  210|       |  virtual Status Read(size_t n, Slice* result, char* scratch) = 0;
  211|       |
  212|       |  // Skip "n" bytes from the file. This is guaranteed to be no
  213|       |  // slower that reading the same data, but may be faster.
  214|       |  //
  215|       |  // If end of file is reached, skipping will stop at the end of the
  216|       |  // file, and Skip will return OK.
  217|       |  //
  218|       |  // REQUIRES: External synchronization
  219|       |  virtual Status Skip(uint64_t n) = 0;
  220|       |};
  221|       |
  222|       |// A file abstraction for randomly reading the contents of a file.
  223|       |class LEVELDB_EXPORT RandomAccessFile {
  224|       | public:
  225|      0|  RandomAccessFile() = default;
  226|       |
  227|       |  RandomAccessFile(const RandomAccessFile&) = delete;
  228|       |  RandomAccessFile& operator=(const RandomAccessFile&) = delete;
  229|       |
  230|       |  virtual ~RandomAccessFile();
  231|       |
  232|       |  // Read up to "n" bytes from the file starting at "offset".
  233|       |  // "scratch[0..n-1]" may be written by this routine.  Sets "*result"
  234|       |  // to the data that was read (including if fewer than "n" bytes were
  235|       |  // successfully read).  May set "*result" to point at data in
  236|       |  // "scratch[0..n-1]", so "scratch[0..n-1]" must be live when
  237|       |  // "*result" is used.  If an error was encountered, returns a non-OK
  238|       |  // status.
  239|       |  //
  240|       |  // Safe for concurrent use by multiple threads.
  241|       |  virtual Status Read(uint64_t offset, size_t n, Slice* result,
  242|       |                      char* scratch) const = 0;
  243|       |};
  244|       |
  245|       |// A file abstraction for sequential writing.  The implementation
  246|       |// must provide buffering since callers may append small fragments
  247|       |// at a time to the file.
  248|       |class LEVELDB_EXPORT WritableFile {
  249|       | public:
  250|      0|  WritableFile() = default;
  251|       |
  252|       |  WritableFile(const WritableFile&) = delete;
  253|       |  WritableFile& operator=(const WritableFile&) = delete;
  254|       |
  255|       |  virtual ~WritableFile();
  256|       |
  257|       |  virtual Status Append(const Slice& data) = 0;
  258|       |  virtual Status Close() = 0;
  259|       |  virtual Status Flush() = 0;
  260|       |  virtual Status Sync() = 0;
  261|       |};
  262|       |
  263|       |// An interface for writing log messages.
  264|       |class LEVELDB_EXPORT Logger {
  265|       | public:
  266|      0|  Logger() = default;
  267|       |
  268|       |  Logger(const Logger&) = delete;
  269|       |  Logger& operator=(const Logger&) = delete;
  270|       |
  271|       |  virtual ~Logger();
  272|       |
  273|       |  // Write an entry to the log file with the specified format.
  274|       |  virtual void Logv(const char* format, va_list ap) = 0;
  275|       |};
  276|       |
  277|       |// Identifies a locked file.
  278|       |class LEVELDB_EXPORT FileLock {
  279|       | public:
  280|      0|  FileLock() = default;
  281|       |
  282|       |  FileLock(const FileLock&) = delete;
  283|       |  FileLock& operator=(const FileLock&) = delete;
  284|       |
  285|       |  virtual ~FileLock();
  286|       |};
  287|       |
  288|       |// Log the specified data to *info_log if info_log is non-null.
  289|       |void Log(Logger* info_log, const char* format, ...)
  290|       |#if defined(__GNUC__) || defined(__clang__)
  291|       |    __attribute__((__format__(__printf__, 2, 3)))
  292|       |#endif
  293|       |    ;
  294|       |
  295|       |// A utility routine: write "data" to the named file.
  296|       |LEVELDB_EXPORT Status WriteStringToFile(Env* env, const Slice& data,
  297|       |                                        const std::string& fname);
  298|       |
  299|       |// A utility routine: read contents of named file into *data
  300|       |LEVELDB_EXPORT Status ReadFileToString(Env* env, const std::string& fname,
  301|       |                                       std::string* data);
  302|       |
  303|       |// An implementation of Env that forwards all calls to another Env.
  304|       |// May be useful to clients who wish to override just part of the
  305|       |// functionality of another Env.
  306|       |class LEVELDB_EXPORT EnvWrapper : public Env {
  307|       | public:
  308|       |  // Initialize an EnvWrapper that delegates all calls to *t.
  309|      0|  explicit EnvWrapper(Env* t) : target_(t) {}
  310|       |  virtual ~EnvWrapper();
  311|       |
  312|       |  // Return the target to which this Env forwards all calls.
  313|      0|  Env* target() const { return target_; }
  314|       |
  315|       |  // The following text is boilerplate that forwards all methods to target().
  316|      0|  Status NewSequentialFile(const std::string& f, SequentialFile** r) override {
  317|      0|    return target_->NewSequentialFile(f, r);
  318|      0|  }
  319|       |  Status NewRandomAccessFile(const std::string& f,
  320|      0|                             RandomAccessFile** r) override {
  321|      0|    return target_->NewRandomAccessFile(f, r);
  322|      0|  }
  323|      0|  Status NewWritableFile(const std::string& f, WritableFile** r) override {
  324|      0|    return target_->NewWritableFile(f, r);
  325|      0|  }
  326|      0|  Status NewAppendableFile(const std::string& f, WritableFile** r) override {
  327|      0|    return target_->NewAppendableFile(f, r);
  328|      0|  }
  329|      0|  bool FileExists(const std::string& f) override {
  330|      0|    return target_->FileExists(f);
  331|      0|  }
  332|       |  Status GetChildren(const std::string& dir,
  333|      0|                     std::vector<std::string>* r) override {
  334|      0|    return target_->GetChildren(dir, r);
  335|      0|  }
  336|      0|  Status DeleteFile(const std::string& f) override {
  337|      0|    return target_->DeleteFile(f);
  338|      0|  }
  339|      0|  Status CreateDir(const std::string& d) override {
  340|      0|    return target_->CreateDir(d);
  341|      0|  }
  342|      0|  Status DeleteDir(const std::string& d) override {
  343|      0|    return target_->DeleteDir(d);
  344|      0|  }
  345|      0|  Status GetFileSize(const std::string& f, uint64_t* s) override {
  346|      0|    return target_->GetFileSize(f, s);
  347|      0|  }
  348|      0|  Status RenameFile(const std::string& s, const std::string& t) override {
  349|      0|    return target_->RenameFile(s, t);
  350|      0|  }
  351|      0|  Status LockFile(const std::string& f, FileLock** l) override {
  352|      0|    return target_->LockFile(f, l);
  353|      0|  }
  354|      0|  Status UnlockFile(FileLock* l) override { return target_->UnlockFile(l); }
  355|      0|  void Schedule(void (*f)(void*), void* a) override {
  356|      0|    return target_->Schedule(f, a);
  357|      0|  }
  358|      0|  void StartThread(void (*f)(void*), void* a) override {
  359|      0|    return target_->StartThread(f, a);
  360|      0|  }
  361|      0|  Status GetTestDirectory(std::string* path) override {
  362|      0|    return target_->GetTestDirectory(path);
  363|      0|  }
  364|      0|  Status NewLogger(const std::string& fname, Logger** result) override {
  365|      0|    return target_->NewLogger(fname, result);
  366|      0|  }
  367|      0|  uint64_t NowMicros() override { return target_->NowMicros(); }
  368|      0|  void SleepForMicroseconds(int micros) override {
  369|      0|    target_->SleepForMicroseconds(micros);
  370|      0|  }
  371|       |
  372|       | private:
  373|       |  Env* target_;
  374|       |};
  375|       |
  376|       |}  // namespace leveldb
  377|       |
  378|       |// Redefine DeleteFile if necessary.
  379|       |#if defined(_WIN32) && defined(LEVELDB_DELETEFILE_UNDEFINED)
  380|       |#if defined(UNICODE)
  381|       |#define DeleteFile DeleteFileW
  382|       |#else
  383|       |#define DeleteFile DeleteFileA
  384|       |#endif  // defined(UNICODE)
  385|       |#endif  // defined(_WIN32) && defined(LEVELDB_DELETEFILE_UNDEFINED)
  386|       |
  387|       |#endif  // STORAGE_LEVELDB_INCLUDE_ENV_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/include/leveldb/iterator.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// An iterator yields a sequence of key/value pairs from a source.
    6|       |// The following class defines the interface.  Multiple implementations
    7|       |// are provided by this library.  In particular, iterators are provided
    8|       |// to access the contents of a Table or a DB.
    9|       |//
   10|       |// Multiple threads can invoke const methods on an Iterator without
   11|       |// external synchronization, but if any of the threads may call a
   12|       |// non-const method, all threads accessing the same Iterator must use
   13|       |// external synchronization.
   14|       |
   15|       |#ifndef STORAGE_LEVELDB_INCLUDE_ITERATOR_H_
   16|       |#define STORAGE_LEVELDB_INCLUDE_ITERATOR_H_
   17|       |
   18|       |#include "leveldb/export.h"
   19|       |#include "leveldb/slice.h"
   20|       |#include "leveldb/status.h"
   21|       |
   22|       |namespace leveldb {
   23|       |
   24|       |class LEVELDB_EXPORT Iterator {
   25|       | public:
   26|       |  Iterator();
   27|       |
   28|       |  Iterator(const Iterator&) = delete;
   29|       |  Iterator& operator=(const Iterator&) = delete;
   30|       |
   31|       |  virtual ~Iterator();
   32|       |
   33|       |  // An iterator is either positioned at a key/value pair, or
   34|       |  // not valid.  This method returns true iff the iterator is valid.
   35|       |  virtual bool Valid() const = 0;
   36|       |
   37|       |  // Position at the first key in the source.  The iterator is Valid()
   38|       |  // after this call iff the source is not empty.
   39|       |  virtual void SeekToFirst() = 0;
   40|       |
   41|       |  // Position at the last key in the source.  The iterator is
   42|       |  // Valid() after this call iff the source is not empty.
   43|       |  virtual void SeekToLast() = 0;
   44|       |
   45|       |  // Position at the first key in the source that is at or past target.
   46|       |  // The iterator is Valid() after this call iff the source contains
   47|       |  // an entry that comes at or past target.
   48|       |  virtual void Seek(const Slice& target) = 0;
   49|       |
   50|       |  // Moves to the next entry in the source.  After this call, Valid() is
   51|       |  // true iff the iterator was not positioned at the last entry in the source.
   52|       |  // REQUIRES: Valid()
   53|       |  virtual void Next() = 0;
   54|       |
   55|       |  // Moves to the previous entry in the source.  After this call, Valid() is
   56|       |  // true iff the iterator was not positioned at the first entry in source.
   57|       |  // REQUIRES: Valid()
   58|       |  virtual void Prev() = 0;
   59|       |
   60|       |  // Return the key for the current entry.  The underlying storage for
   61|       |  // the returned slice is valid only until the next modification of
   62|       |  // the iterator.
   63|       |  // REQUIRES: Valid()
   64|       |  virtual Slice key() const = 0;
   65|       |
   66|       |  // Return the value for the current entry.  The underlying storage for
   67|       |  // the returned slice is valid only until the next modification of
   68|       |  // the iterator.
   69|       |  // REQUIRES: Valid()
   70|       |  virtual Slice value() const = 0;
   71|       |
   72|       |  // If an error has occurred, return it.  Else return an ok status.
   73|       |  virtual Status status() const = 0;
   74|       |
   75|       |  // Clients are allowed to register function/arg1/arg2 triples that
   76|       |  // will be invoked when this iterator is destroyed.
   77|       |  //
   78|       |  // Note that unlike all of the preceding methods, this method is
   79|       |  // not abstract and therefore clients should not override it.
   80|       |  using CleanupFunction = void (*)(void* arg1, void* arg2);
   81|       |  void RegisterCleanup(CleanupFunction function, void* arg1, void* arg2);
   82|       |
   83|       | private:
   84|       |  // Cleanup functions are stored in a single-linked list.
   85|       |  // The list's head node is inlined in the iterator.
   86|       |  struct CleanupNode {
   87|       |    // True if the node is not used. Only head nodes might be unused.
   88|      0|    bool IsEmpty() const { return function == nullptr; }
   89|       |    // Invokes the cleanup function.
   90|      0|    void Run() {
   91|      0|      assert(function != nullptr);
   92|      0|      (*function)(arg1, arg2);
   93|      0|    }
   94|       |
   95|       |    // The head node is used if the function pointer is not null.
   96|       |    CleanupFunction function;
   97|       |    void* arg1;
   98|       |    void* arg2;
   99|       |    CleanupNode* next;
  100|       |  };
  101|       |  CleanupNode cleanup_head_;
  102|       |};
  103|       |
  104|       |// Return an empty iterator (yields nothing).
  105|       |LEVELDB_EXPORT Iterator* NewEmptyIterator();
  106|       |
  107|       |// Return an empty iterator with the specified status.
  108|       |LEVELDB_EXPORT Iterator* NewErrorIterator(const Status& status);
  109|       |
  110|       |}  // namespace leveldb
  111|       |
  112|       |#endif  // STORAGE_LEVELDB_INCLUDE_ITERATOR_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/include/leveldb/options.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_INCLUDE_OPTIONS_H_
    6|       |#define STORAGE_LEVELDB_INCLUDE_OPTIONS_H_
    7|       |
    8|       |#include <stddef.h>
    9|       |
   10|       |#include "leveldb/export.h"
   11|       |
   12|       |namespace leveldb {
   13|       |
   14|       |class Cache;
   15|       |class Comparator;
   16|       |class Env;
   17|       |class FilterPolicy;
   18|       |class Logger;
   19|       |class Snapshot;
   20|       |
   21|       |// DB contents are stored in a set of blocks, each of which holds a
   22|       |// sequence of key,value pairs.  Each block may be compressed before
   23|       |// being stored in a file.  The following enum describes which
   24|       |// compression method (if any) is used to compress a block.
   25|       |enum CompressionType {
   26|       |  // NOTE: do not change the values of existing entries, as these are
   27|       |  // part of the persistent format on disk.
   28|       |  kNoCompression = 0x0,
   29|       |  kSnappyCompression = 0x1
   30|       |};
   31|       |
   32|       |// Options to control the behavior of a database (passed to DB::Open)
   33|       |struct LEVELDB_EXPORT Options {
   34|       |  // Create an Options object with default values for all fields.
   35|       |  Options();
   36|       |
   37|       |  // -------------------
   38|       |  // Parameters that affect behavior
   39|       |
   40|       |  // Comparator used to define the order of keys in the table.
   41|       |  // Default: a comparator that uses lexicographic byte-wise ordering
   42|       |  //
   43|       |  // REQUIRES: The client must ensure that the comparator supplied
   44|       |  // here has the same name and orders keys *exactly* the same as the
   45|       |  // comparator provided to previous open calls on the same DB.
   46|       |  const Comparator* comparator;
   47|       |
   48|       |  // If true, the database will be created if it is missing.
   49|       |  bool create_if_missing = false;
   50|       |
   51|       |  // If true, an error is raised if the database already exists.
   52|       |  bool error_if_exists = false;
   53|       |
   54|       |  // If true, the implementation will do aggressive checking of the
   55|       |  // data it is processing and will stop early if it detects any
   56|       |  // errors.  This may have unforeseen ramifications: for example, a
   57|       |  // corruption of one DB entry may cause a large number of entries to
   58|       |  // become unreadable or for the entire DB to become unopenable.
   59|       |  bool paranoid_checks = false;
   60|       |
   61|       |  // Use the specified object to interact with the environment,
   62|       |  // e.g. to read/write files, schedule background work, etc.
   63|       |  // Default: Env::Default()
   64|       |  Env* env;
   65|       |
   66|       |  // Any internal progress/error information generated by the db will
   67|       |  // be written to info_log if it is non-null, or to a file stored
   68|       |  // in the same directory as the DB contents if info_log is null.
   69|       |  Logger* info_log = nullptr;
   70|       |
   71|       |  // -------------------
   72|       |  // Parameters that affect performance
   73|       |
   74|       |  // Amount of data to build up in memory (backed by an unsorted log
   75|       |  // on disk) before converting to a sorted on-disk file.
   76|       |  //
   77|       |  // Larger values increase performance, especially during bulk loads.
   78|       |  // Up to two write buffers may be held in memory at the same time,
   79|       |  // so you may wish to adjust this parameter to control memory usage.
   80|       |  // Also, a larger write buffer will result in a longer recovery time
   81|       |  // the next time the database is opened.
   82|       |  size_t write_buffer_size = 4 * 1024 * 1024;
   83|       |
   84|       |  // Number of open files that can be used by the DB.  You may need to
   85|       |  // increase this if your database has a large working set (budget
   86|       |  // one open file per 2MB of working set).
   87|       |  int max_open_files = 1000;
   88|       |
   89|       |  // Control over blocks (user data is stored in a set of blocks, and
   90|       |  // a block is the unit of reading from disk).
   91|       |
   92|       |  // If non-null, use the specified cache for blocks.
   93|       |  // If null, leveldb will automatically create and use an 8MB internal cache.
   94|       |  Cache* block_cache = nullptr;
   95|       |
   96|       |  // Approximate size of user data packed per block.  Note that the
   97|       |  // block size specified here corresponds to uncompressed data.  The
   98|       |  // actual size of the unit read from disk may be smaller if
   99|       |  // compression is enabled.  This parameter can be changed dynamically.
  100|       |  size_t block_size = 4 * 1024;
  101|       |
  102|       |  // Number of keys between restart points for delta encoding of keys.
  103|       |  // This parameter can be changed dynamically.  Most clients should
  104|       |  // leave this parameter alone.
  105|       |  int block_restart_interval = 16;
  106|       |
  107|       |  // Leveldb will write up to this amount of bytes to a file before
  108|       |  // switching to a new one.
  109|       |  // Most clients should leave this parameter alone.  However if your
  110|       |  // filesystem is more efficient with larger files, you could
  111|       |  // consider increasing the value.  The downside will be longer
  112|       |  // compactions and hence longer latency/performance hiccups.
  113|       |  // Another reason to increase this parameter might be when you are
  114|       |  // initially populating a large database.
  115|       |  size_t max_file_size = 2 * 1024 * 1024;
  116|       |
  117|       |  // Compress blocks using the specified compression algorithm.  This
  118|       |  // parameter can be changed dynamically.
  119|       |  //
  120|       |  // Default: kSnappyCompression, which gives lightweight but fast
  121|       |  // compression.
  122|       |  //
  123|       |  // Typical speeds of kSnappyCompression on an Intel(R) Core(TM)2 2.4GHz:
  124|       |  //    ~200-500MB/s compression
  125|       |  //    ~400-800MB/s decompression
  126|       |  // Note that these speeds are significantly faster than most
  127|       |  // persistent storage speeds, and therefore it is typically never
  128|       |  // worth switching to kNoCompression.  Even if the input data is
  129|       |  // incompressible, the kSnappyCompression implementation will
  130|       |  // efficiently detect that and will switch to uncompressed mode.
  131|       |  CompressionType compression = kSnappyCompression;
  132|       |
  133|       |  // EXPERIMENTAL: If true, append to existing MANIFEST and log files
  134|       |  // when a database is opened.  This can significantly speed up open.
  135|       |  //
  136|       |  // Default: currently false, but may become true later.
  137|       |  bool reuse_logs = false;
  138|       |
  139|       |  // If non-null, use the specified filter policy to reduce disk reads.
  140|       |  // Many applications will benefit from passing the result of
  141|       |  // NewBloomFilterPolicy() here.
  142|       |  const FilterPolicy* filter_policy = nullptr;
  143|       |};
  144|       |
  145|       |// Options that control read operations
  146|       |struct LEVELDB_EXPORT ReadOptions {
  147|      0|  ReadOptions() = default;
  148|       |
  149|       |  // If true, all data read from underlying storage will be
  150|       |  // verified against corresponding checksums.
  151|       |  bool verify_checksums = false;
  152|       |
  153|       |  // Should the data read for this iteration be cached in memory?
  154|       |  // Callers may wish to set this field to false for bulk scans.
  155|       |  bool fill_cache = true;
  156|       |
  157|       |  // If "snapshot" is non-null, read as of the supplied snapshot
  158|       |  // (which must belong to the DB that is being read and which must
  159|       |  // not have been released).  If "snapshot" is null, use an implicit
  160|       |  // snapshot of the state at the beginning of this read operation.
  161|       |  const Snapshot* snapshot = nullptr;
  162|       |};
  163|       |
  164|       |// Options that control write operations
  165|       |struct LEVELDB_EXPORT WriteOptions {
  166|      0|  WriteOptions() = default;
  167|       |
  168|       |  // If true, the write will be flushed from the operating system
  169|       |  // buffer cache (by calling WritableFile::Sync()) before the write
  170|       |  // is considered complete.  If this flag is true, writes will be
  171|       |  // slower.
  172|       |  //
  173|       |  // If this flag is false, and the machine crashes, some recent
  174|       |  // writes may be lost.  Note that if it is just the process that
  175|       |  // crashes (i.e., the machine does not reboot), no writes will be
  176|       |  // lost even if sync==false.
  177|       |  //
  178|       |  // In other words, a DB write with sync==false has similar
  179|       |  // crash semantics as the "write()" system call.  A DB write
  180|       |  // with sync==true has similar crash semantics to a "write()"
  181|       |  // system call followed by "fsync()".
  182|       |  bool sync = false;
  183|       |};
  184|       |
  185|       |}  // namespace leveldb
  186|       |
  187|       |#endif  // STORAGE_LEVELDB_INCLUDE_OPTIONS_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/include/leveldb/slice.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// Slice is a simple structure containing a pointer into some external
    6|       |// storage and a size.  The user of a Slice must ensure that the slice
    7|       |// is not used after the corresponding external storage has been
    8|       |// deallocated.
    9|       |//
   10|       |// Multiple threads can invoke const methods on a Slice without
   11|       |// external synchronization, but if any of the threads may call a
   12|       |// non-const method, all threads accessing the same Slice must use
   13|       |// external synchronization.
   14|       |
   15|       |#ifndef STORAGE_LEVELDB_INCLUDE_SLICE_H_
   16|       |#define STORAGE_LEVELDB_INCLUDE_SLICE_H_
   17|       |
   18|       |#include <assert.h>
   19|       |#include <stddef.h>
   20|       |#include <string.h>
   21|       |
   22|       |#include <string>
   23|       |
   24|       |#include "leveldb/export.h"
   25|       |
   26|       |namespace leveldb {
   27|       |
   28|       |class LEVELDB_EXPORT Slice {
   29|       | public:
   30|       |  // Create an empty slice.
   31|      0|  Slice() : data_(""), size_(0) {}
   32|       |
   33|       |  // Create a slice that refers to d[0,n-1].
   34|      0|  Slice(const char* d, size_t n) : data_(d), size_(n) {}
   35|       |
   36|       |  // Create a slice that refers to the contents of "s"
   37|      0|  Slice(const std::string& s) : data_(s.data()), size_(s.size()) {}
   38|       |
   39|       |  // Create a slice that refers to s[0,strlen(s)-1]
   40|      0|  Slice(const char* s) : data_(s), size_(strlen(s)) {}
   41|       |
   42|       |  // Intentionally copyable.
   43|       |  Slice(const Slice&) = default;
   44|       |  Slice& operator=(const Slice&) = default;
   45|       |
   46|       |  // Return a pointer to the beginning of the referenced data
   47|      0|  const char* data() const { return data_; }
   48|       |
   49|       |  // Return the length (in bytes) of the referenced data
   50|      0|  size_t size() const { return size_; }
   51|       |
   52|       |  // Return true iff the length of the referenced data is zero
   53|      0|  bool empty() const { return size_ == 0; }
   54|       |
   55|       |  // Return the ith byte in the referenced data.
   56|       |  // REQUIRES: n < size()
   57|      0|  char operator[](size_t n) const {
   58|      0|    assert(n < size());
   59|      0|    return data_[n];
   60|      0|  }
   61|       |
   62|       |  // Change this slice to refer to an empty array
   63|      0|  void clear() {
   64|      0|    data_ = "";
   65|      0|    size_ = 0;
   66|      0|  }
   67|       |
   68|       |  // Drop the first "n" bytes from this slice.
   69|      0|  void remove_prefix(size_t n) {
   70|      0|    assert(n <= size());
   71|      0|    data_ += n;
   72|      0|    size_ -= n;
   73|      0|  }
   74|       |
   75|       |  // Return a string that contains the copy of the referenced data.
   76|      0|  std::string ToString() const { return std::string(data_, size_); }
   77|       |
   78|       |  // Three-way comparison.  Returns value:
   79|       |  //   <  0 iff "*this" <  "b",
   80|       |  //   == 0 iff "*this" == "b",
   81|       |  //   >  0 iff "*this" >  "b"
   82|       |  int compare(const Slice& b) const;
   83|       |
   84|       |  // Return true iff "x" is a prefix of "*this"
   85|      0|  bool starts_with(const Slice& x) const {
   86|      0|    return ((size_ >= x.size_) && (memcmp(data_, x.data_, x.size_) == 0));
   87|      0|  }
   88|       |
   89|       | private:
   90|       |  const char* data_;
   91|       |  size_t size_;
   92|       |};
   93|       |
   94|      0|inline bool operator==(const Slice& x, const Slice& y) {
   95|      0|  return ((x.size() == y.size()) &&
   96|      0|          (memcmp(x.data(), y.data(), x.size()) == 0));
   97|      0|}
   98|       |
   99|      0|inline bool operator!=(const Slice& x, const Slice& y) { return !(x == y); }
  100|       |
  101|      0|inline int Slice::compare(const Slice& b) const {
  102|      0|  const size_t min_len = (size_ < b.size_) ? size_ : b.size_;
  103|      0|  int r = memcmp(data_, b.data_, min_len);
  104|      0|  if (r == 0) {
  105|      0|    if (size_ < b.size_)
  106|      0|      r = -1;
  107|      0|    else if (size_ > b.size_)
  108|      0|      r = +1;
  109|      0|  }
  110|      0|  return r;
  111|      0|}
  112|       |
  113|       |}  // namespace leveldb
  114|       |
  115|       |#endif  // STORAGE_LEVELDB_INCLUDE_SLICE_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/include/leveldb/status.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// A Status encapsulates the result of an operation.  It may indicate success,
    6|       |// or it may indicate an error with an associated error message.
    7|       |//
    8|       |// Multiple threads can invoke const methods on a Status without
    9|       |// external synchronization, but if any of the threads may call a
   10|       |// non-const method, all threads accessing the same Status must use
   11|       |// external synchronization.
   12|       |
   13|       |#ifndef STORAGE_LEVELDB_INCLUDE_STATUS_H_
   14|       |#define STORAGE_LEVELDB_INCLUDE_STATUS_H_
   15|       |
   16|       |#include <algorithm>
   17|       |#include <string>
   18|       |
   19|       |#include "leveldb/export.h"
   20|       |#include "leveldb/slice.h"
   21|       |
   22|       |namespace leveldb {
   23|       |
   24|       |class LEVELDB_EXPORT Status {
   25|       | public:
   26|       |  // Create a success status.
   27|      0|  Status() noexcept : state_(nullptr) {}
   28|      0|  ~Status() { delete[] state_; }
   29|       |
   30|       |  Status(const Status& rhs);
   31|       |  Status& operator=(const Status& rhs);
   32|       |
   33|      0|  Status(Status&& rhs) noexcept : state_(rhs.state_) { rhs.state_ = nullptr; }
   34|       |  Status& operator=(Status&& rhs) noexcept;
   35|       |
   36|       |  // Return a success status.
   37|      0|  static Status OK() { return Status(); }
   38|       |
   39|       |  // Return error status of an appropriate type.
   40|      0|  static Status NotFound(const Slice& msg, const Slice& msg2 = Slice()) {
   41|      0|    return Status(kNotFound, msg, msg2);
   42|      0|  }
   43|      0|  static Status Corruption(const Slice& msg, const Slice& msg2 = Slice()) {
   44|      0|    return Status(kCorruption, msg, msg2);
   45|      0|  }
   46|      0|  static Status NotSupported(const Slice& msg, const Slice& msg2 = Slice()) {
   47|      0|    return Status(kNotSupported, msg, msg2);
   48|      0|  }
   49|      0|  static Status InvalidArgument(const Slice& msg, const Slice& msg2 = Slice()) {
   50|      0|    return Status(kInvalidArgument, msg, msg2);
   51|      0|  }
   52|      0|  static Status IOError(const Slice& msg, const Slice& msg2 = Slice()) {
   53|      0|    return Status(kIOError, msg, msg2);
   54|      0|  }
   55|       |
   56|       |  // Returns true iff the status indicates success.
   57|      0|  bool ok() const { return (state_ == nullptr); }
   58|       |
   59|       |  // Returns true iff the status indicates a NotFound error.
   60|      0|  bool IsNotFound() const { return code() == kNotFound; }
   61|       |
   62|       |  // Returns true iff the status indicates a Corruption error.
   63|       |  bool IsCorruption() const { return code() == kCorruption; }
   64|       |
   65|       |  // Returns true iff the status indicates an IOError.
   66|       |  bool IsIOError() const { return code() == kIOError; }
   67|       |
   68|       |  // Returns true iff the status indicates a NotSupportedError.
   69|       |  bool IsNotSupportedError() const { return code() == kNotSupported; }
   70|       |
   71|       |  // Returns true iff the status indicates an InvalidArgument.
   72|       |  bool IsInvalidArgument() const { return code() == kInvalidArgument; }
   73|       |
   74|       |  // Return a string representation of this status suitable for printing.
   75|       |  // Returns the string "OK" for success.
   76|       |  std::string ToString() const;
   77|       |
   78|       | private:
   79|       |  enum Code {
   80|       |    kOk = 0,
   81|       |    kNotFound = 1,
   82|       |    kCorruption = 2,
   83|       |    kNotSupported = 3,
   84|       |    kInvalidArgument = 4,
   85|       |    kIOError = 5
   86|       |  };
   87|       |
   88|      0|  Code code() const {
   89|      0|    return (state_ == nullptr) ? kOk : static_cast<Code>(state_[4]);
   90|      0|  }
   91|       |
   92|       |  Status(Code code, const Slice& msg, const Slice& msg2);
   93|       |  static const char* CopyState(const char* s);
   94|       |
   95|       |  // OK status has a null state_.  Otherwise, state_ is a new[] array
   96|       |  // of the following form:
   97|       |  //    state_[0..3] == length of message
   98|       |  //    state_[4]    == code
   99|       |  //    state_[5..]  == message
  100|       |  const char* state_;
  101|       |};
  102|       |
  103|      0|inline Status::Status(const Status& rhs) {
  104|      0|  state_ = (rhs.state_ == nullptr) ? nullptr : CopyState(rhs.state_);
  105|      0|}
  106|      0|inline Status& Status::operator=(const Status& rhs) {
  107|      0|  // The following condition catches both aliasing (when this == &rhs),
  108|      0|  // and the common case where both rhs and *this are ok.
  109|      0|  if (state_ != rhs.state_) {
  110|      0|    delete[] state_;
  111|      0|    state_ = (rhs.state_ == nullptr) ? nullptr : CopyState(rhs.state_);
  112|      0|  }
  113|      0|  return *this;
  114|      0|}
  115|      0|inline Status& Status::operator=(Status&& rhs) noexcept {
  116|      0|  std::swap(state_, rhs.state_);
  117|      0|  return *this;
  118|      0|}
  119|       |
  120|       |}  // namespace leveldb
  121|       |
  122|       |#endif  // STORAGE_LEVELDB_INCLUDE_STATUS_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/include/leveldb/table.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_INCLUDE_TABLE_H_
    6|       |#define STORAGE_LEVELDB_INCLUDE_TABLE_H_
    7|       |
    8|       |#include <stdint.h>
    9|       |
   10|       |#include "leveldb/export.h"
   11|       |#include "leveldb/iterator.h"
   12|       |
   13|       |namespace leveldb {
   14|       |
   15|       |class Block;
   16|       |class BlockHandle;
   17|       |class Footer;
   18|       |struct Options;
   19|       |class RandomAccessFile;
   20|       |struct ReadOptions;
   21|       |class TableCache;
   22|       |
   23|       |// A Table is a sorted map from strings to strings.  Tables are
   24|       |// immutable and persistent.  A Table may be safely accessed from
   25|       |// multiple threads without external synchronization.
   26|       |class LEVELDB_EXPORT Table {
   27|       | public:
   28|       |  // Attempt to open the table that is stored in bytes [0..file_size)
   29|       |  // of "file", and read the metadata entries necessary to allow
   30|       |  // retrieving data from the table.
   31|       |  //
   32|       |  // If successful, returns ok and sets "*table" to the newly opened
   33|       |  // table.  The client should delete "*table" when no longer needed.
   34|       |  // If there was an error while initializing the table, sets "*table"
   35|       |  // to nullptr and returns a non-ok status.  Does not take ownership of
   36|       |  // "*source", but the client must ensure that "source" remains live
   37|       |  // for the duration of the returned table's lifetime.
   38|       |  //
   39|       |  // *file must remain live while this Table is in use.
   40|       |  static Status Open(const Options& options, RandomAccessFile* file,
   41|       |                     uint64_t file_size, Table** table);
   42|       |
   43|       |  Table(const Table&) = delete;
   44|       |  Table& operator=(const Table&) = delete;
   45|       |
   46|       |  ~Table();
   47|       |
   48|       |  // Returns a new iterator over the table contents.
   49|       |  // The result of NewIterator() is initially invalid (caller must
   50|       |  // call one of the Seek methods on the iterator before using it).
   51|       |  Iterator* NewIterator(const ReadOptions&) const;
   52|       |
   53|       |  // Given a key, return an approximate byte offset in the file where
   54|       |  // the data for that key begins (or would begin if the key were
   55|       |  // present in the file).  The returned value is in terms of file
   56|       |  // bytes, and so includes effects like compression of the underlying data.
   57|       |  // E.g., the approximate offset of the last key in the table will
   58|       |  // be close to the file length.
   59|       |  uint64_t ApproximateOffsetOf(const Slice& key) const;
   60|       |
   61|       | private:
   62|       |  friend class TableCache;
   63|       |  struct Rep;
   64|       |
   65|       |  static Iterator* BlockReader(void*, const ReadOptions&, const Slice&);
   66|       |
   67|      0|  explicit Table(Rep* rep) : rep_(rep) {}
   68|       |
   69|       |  // Calls (*handle_result)(arg, ...) with the entry found after a call
   70|       |  // to Seek(key).  May not make such a call if filter policy says
   71|       |  // that key is not present.
   72|       |  Status InternalGet(const ReadOptions&, const Slice& key, void* arg,
   73|       |                     void (*handle_result)(void* arg, const Slice& k,
   74|       |                                           const Slice& v));
   75|       |
   76|       |  void ReadMeta(const Footer& footer);
   77|       |  void ReadFilter(const Slice& filter_handle_value);
   78|       |
   79|       |  Rep* const rep_;
   80|       |};
   81|       |
   82|       |}  // namespace leveldb
   83|       |
   84|       |#endif  // STORAGE_LEVELDB_INCLUDE_TABLE_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/include/leveldb/table_builder.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// TableBuilder provides the interface used to build a Table
    6|       |// (an immutable and sorted map from keys to values).
    7|       |//
    8|       |// Multiple threads can invoke const methods on a TableBuilder without
    9|       |// external synchronization, but if any of the threads may call a
   10|       |// non-const method, all threads accessing the same TableBuilder must use
   11|       |// external synchronization.
   12|       |
   13|       |#ifndef STORAGE_LEVELDB_INCLUDE_TABLE_BUILDER_H_
   14|       |#define STORAGE_LEVELDB_INCLUDE_TABLE_BUILDER_H_
   15|       |
   16|       |#include <stdint.h>
   17|       |
   18|       |#include "leveldb/export.h"
   19|       |#include "leveldb/options.h"
   20|       |#include "leveldb/status.h"
   21|       |
   22|       |namespace leveldb {
   23|       |
   24|       |class BlockBuilder;
   25|       |class BlockHandle;
   26|       |class WritableFile;
   27|       |
   28|       |class LEVELDB_EXPORT TableBuilder {
   29|       | public:
   30|       |  // Create a builder that will store the contents of the table it is
   31|       |  // building in *file.  Does not close the file.  It is up to the
   32|       |  // caller to close the file after calling Finish().
   33|       |  TableBuilder(const Options& options, WritableFile* file);
   34|       |
   35|       |  TableBuilder(const TableBuilder&) = delete;
   36|       |  TableBuilder& operator=(const TableBuilder&) = delete;
   37|       |
   38|       |  // REQUIRES: Either Finish() or Abandon() has been called.
   39|       |  ~TableBuilder();
   40|       |
   41|       |  // Change the options used by this builder.  Note: only some of the
   42|       |  // option fields can be changed after construction.  If a field is
   43|       |  // not allowed to change dynamically and its value in the structure
   44|       |  // passed to the constructor is different from its value in the
   45|       |  // structure passed to this method, this method will return an error
   46|       |  // without changing any fields.
   47|       |  Status ChangeOptions(const Options& options);
   48|       |
   49|       |  // Add key,value to the table being constructed.
   50|       |  // REQUIRES: key is after any previously added key according to comparator.
   51|       |  // REQUIRES: Finish(), Abandon() have not been called
   52|       |  void Add(const Slice& key, const Slice& value);
   53|       |
   54|       |  // Advanced operation: flush any buffered key/value pairs to file.
   55|       |  // Can be used to ensure that two adjacent entries never live in
   56|       |  // the same data block.  Most clients should not need to use this method.
   57|       |  // REQUIRES: Finish(), Abandon() have not been called
   58|       |  void Flush();
   59|       |
   60|       |  // Return non-ok iff some error has been detected.
   61|       |  Status status() const;
   62|       |
   63|       |  // Finish building the table.  Stops using the file passed to the
   64|       |  // constructor after this function returns.
   65|       |  // REQUIRES: Finish(), Abandon() have not been called
   66|       |  Status Finish();
   67|       |
   68|       |  // Indicate that the contents of this builder should be abandoned.  Stops
   69|       |  // using the file passed to the constructor after this function returns.
   70|       |  // If the caller is not going to call Finish(), it must call Abandon()
   71|       |  // before destroying this builder.
   72|       |  // REQUIRES: Finish(), Abandon() have not been called
   73|       |  void Abandon();
   74|       |
   75|       |  // Number of calls to Add() so far.
   76|       |  uint64_t NumEntries() const;
   77|       |
   78|       |  // Size of the file generated so far.  If invoked after a successful
   79|       |  // Finish() call, returns the size of the final generated file.
   80|       |  uint64_t FileSize() const;
   81|       |
   82|       | private:
   83|      0|  bool ok() const { return status().ok(); }
   84|       |  void WriteBlock(BlockBuilder* block, BlockHandle* handle);
   85|       |  void WriteRawBlock(const Slice& data, CompressionType, BlockHandle* handle);
   86|       |
   87|       |  struct Rep;
   88|       |  Rep* rep_;
   89|       |};
   90|       |
   91|       |}  // namespace leveldb
   92|       |
   93|       |#endif  // STORAGE_LEVELDB_INCLUDE_TABLE_BUILDER_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/port/port_stdcxx.h:
    1|       |// Copyright (c) 2018 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_PORT_PORT_STDCXX_H_
    6|       |#define STORAGE_LEVELDB_PORT_PORT_STDCXX_H_
    7|       |
    8|       |// port/port_config.h availability is automatically detected via __has_include
    9|       |// in newer compilers. If LEVELDB_HAS_PORT_CONFIG_H is defined, it overrides the
   10|       |// configuration detection.
   11|       |#if defined(LEVELDB_HAS_PORT_CONFIG_H)
   12|       |
   13|       |#if LEVELDB_HAS_PORT_CONFIG_H
   14|       |#include "port/port_config.h"
   15|       |#endif  // LEVELDB_HAS_PORT_CONFIG_H
   16|       |
   17|       |#elif defined(__has_include)
   18|       |
   19|       |#if __has_include("port/port_config.h")
   20|       |#include "port/port_config.h"
   21|       |#endif  // __has_include("port/port_config.h")
   22|       |
   23|       |#endif  // defined(LEVELDB_HAS_PORT_CONFIG_H)
   24|       |
   25|       |#if HAVE_CRC32C
   26|       |#include <crc32c/crc32c.h>
   27|       |#endif  // HAVE_CRC32C
   28|       |#if HAVE_SNAPPY
   29|       |#include <snappy.h>
   30|       |#endif  // HAVE_SNAPPY
   31|       |
   32|       |#include <cassert>
   33|       |#include <condition_variable>  // NOLINT
   34|       |#include <cstddef>
   35|       |#include <cstdint>
   36|       |#include <mutex>  // NOLINT
   37|       |#include <string>
   38|       |
   39|       |#include "port/thread_annotations.h"
   40|       |
   41|       |namespace leveldb {
   42|       |namespace port {
   43|       |
   44|       |static const bool kLittleEndian = !LEVELDB_IS_BIG_ENDIAN;
   45|       |
   46|       |class CondVar;
   47|       |
   48|       |// Thinly wraps std::mutex.
   49|       |class LOCKABLE Mutex {
   50|       | public:
   51|      0|  Mutex() = default;
   52|      0|  ~Mutex() = default;
   53|       |
   54|       |  Mutex(const Mutex&) = delete;
   55|       |  Mutex& operator=(const Mutex&) = delete;
   56|       |
   57|      0|  void Lock() EXCLUSIVE_LOCK_FUNCTION() { mu_.lock(); }
   58|      0|  void Unlock() UNLOCK_FUNCTION() { mu_.unlock(); }
   59|      0|  void AssertHeld() ASSERT_EXCLUSIVE_LOCK() {}
   60|       |
   61|       | private:
   62|       |  friend class CondVar;
   63|       |  std::mutex mu_;
   64|       |};
   65|       |
   66|       |// Thinly wraps std::condition_variable.
   67|       |class CondVar {
   68|       | public:
   69|      0|  explicit CondVar(Mutex* mu) : mu_(mu) { assert(mu != nullptr); }
   70|      0|  ~CondVar() = default;
   71|       |
   72|       |  CondVar(const CondVar&) = delete;
   73|       |  CondVar& operator=(const CondVar&) = delete;
   74|       |
   75|      0|  void Wait() {
   76|      0|    std::unique_lock<std::mutex> lock(mu_->mu_, std::adopt_lock);
   77|      0|    cv_.wait(lock);
   78|      0|    lock.release();
   79|      0|  }
   80|      0|  void Signal() { cv_.notify_one(); }
   81|      0|  void SignalAll() { cv_.notify_all(); }
   82|       |
   83|       | private:
   84|       |  std::condition_variable cv_;
   85|       |  Mutex* const mu_;
   86|       |};
   87|       |
   88|       |inline bool Snappy_Compress(const char* input, size_t length,
   89|      0|                            std::string* output) {
   90|       |#if HAVE_SNAPPY
   91|       |  output->resize(snappy::MaxCompressedLength(length));
   92|       |  size_t outlen;
   93|       |  snappy::RawCompress(input, length, &(*output)[0], &outlen);
   94|       |  output->resize(outlen);
   95|       |  return true;
   96|       |#else
   97|       |  // Silence compiler warnings about unused arguments.
   98|      0|  (void)input;
   99|      0|  (void)length;
  100|      0|  (void)output;
  101|      0|#endif  // HAVE_SNAPPY
  102|      0|
  103|      0|  return false;
  104|      0|}
  105|       |
  106|       |inline bool Snappy_GetUncompressedLength(const char* input, size_t length,
  107|      0|                                         size_t* result) {
  108|       |#if HAVE_SNAPPY
  109|       |  return snappy::GetUncompressedLength(input, length, result);
  110|       |#else
  111|       |  // Silence compiler warnings about unused arguments.
  112|      0|  (void)input;
  113|      0|  (void)length;
  114|      0|  (void)result;
  115|      0|  return false;
  116|      0|#endif  // HAVE_SNAPPY
  117|      0|}
  118|       |
  119|      0|inline bool Snappy_Uncompress(const char* input, size_t length, char* output) {
  120|       |#if HAVE_SNAPPY
  121|       |  return snappy::RawUncompress(input, length, output);
  122|       |#else
  123|       |  // Silence compiler warnings about unused arguments.
  124|      0|  (void)input;
  125|      0|  (void)length;
  126|      0|  (void)output;
  127|      0|  return false;
  128|      0|#endif  // HAVE_SNAPPY
  129|      0|}
  130|       |
  131|      0|inline bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg) {
  132|      0|  // Silence compiler warnings about unused arguments.
  133|      0|  (void)func;
  134|      0|  (void)arg;
  135|      0|  return false;
  136|      0|}
  137|       |
  138|      0|inline uint32_t AcceleratedCRC32C(uint32_t crc, const char* buf, size_t size) {
  139|       |#if HAVE_CRC32C
  140|       |  return ::crc32c::Extend(crc, reinterpret_cast<const uint8_t*>(buf), size);
  141|       |#else
  142|       |  // Silence compiler warnings about unused arguments.
  143|      0|  (void)crc;
  144|      0|  (void)buf;
  145|      0|  (void)size;
  146|      0|  return 0;
  147|      0|#endif  // HAVE_CRC32C
  148|      0|}
  149|       |
  150|       |}  // namespace port
  151|       |}  // namespace leveldb
  152|       |
  153|       |#endif  // STORAGE_LEVELDB_PORT_PORT_STDCXX_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/block.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// Decodes the blocks generated by block_builder.cc.
    6|       |
    7|       |#include "table/block.h"
    8|       |
    9|       |#include <algorithm>
   10|       |#include <vector>
   11|       |
   12|       |#include "leveldb/comparator.h"
   13|       |#include "table/format.h"
   14|       |#include "util/coding.h"
   15|       |#include "util/logging.h"
   16|       |
   17|       |namespace leveldb {
   18|       |
   19|      0|inline uint32_t Block::NumRestarts() const {
   20|      0|  assert(size_ >= sizeof(uint32_t));
   21|      0|  return DecodeFixed32(data_ + size_ - sizeof(uint32_t));
   22|      0|}
   23|       |
   24|       |Block::Block(const BlockContents& contents)
   25|       |    : data_(contents.data.data()),
   26|       |      size_(contents.data.size()),
   27|      0|      owned_(contents.heap_allocated) {
   28|      0|  if (size_ < sizeof(uint32_t)) {
   29|      0|    size_ = 0;  // Error marker
   30|      0|  } else {
   31|      0|    size_t max_restarts_allowed = (size_ - sizeof(uint32_t)) / sizeof(uint32_t);
   32|      0|    if (NumRestarts() > max_restarts_allowed) {
   33|      0|      // The size is too small for NumRestarts()
   34|      0|      size_ = 0;
   35|      0|    } else {
   36|      0|      restart_offset_ = size_ - (1 + NumRestarts()) * sizeof(uint32_t);
   37|      0|    }
   38|      0|  }
   39|      0|}
   40|       |
   41|      0|Block::~Block() {
   42|      0|  if (owned_) {
   43|      0|    delete[] data_;
   44|      0|  }
   45|      0|}
   46|       |
   47|       |// Helper routine: decode the next block entry starting at "p",
   48|       |// storing the number of shared key bytes, non_shared key bytes,
   49|       |// and the length of the value in "*shared", "*non_shared", and
   50|       |// "*value_length", respectively.  Will not dereference past "limit".
   51|       |//
   52|       |// If any errors are detected, returns nullptr.  Otherwise, returns a
   53|       |// pointer to the key delta (just past the three decoded values).
   54|       |static inline const char* DecodeEntry(const char* p, const char* limit,
   55|       |                                      uint32_t* shared, uint32_t* non_shared,
   56|      0|                                      uint32_t* value_length) {
   57|      0|  if (limit - p < 3) return nullptr;
   58|      0|  *shared = reinterpret_cast<const unsigned char*>(p)[0];
   59|      0|  *non_shared = reinterpret_cast<const unsigned char*>(p)[1];
   60|      0|  *value_length = reinterpret_cast<const unsigned char*>(p)[2];
   61|      0|  if ((*shared | *non_shared | *value_length) < 128) {
   62|      0|    // Fast path: all three values are encoded in one byte each
   63|      0|    p += 3;
   64|      0|  } else {
   65|      0|    if ((p = GetVarint32Ptr(p, limit, shared)) == nullptr) return nullptr;
   66|      0|    if ((p = GetVarint32Ptr(p, limit, non_shared)) == nullptr) return nullptr;
   67|      0|    if ((p = GetVarint32Ptr(p, limit, value_length)) == nullptr) return nullptr;
   68|      0|  }
   69|      0|
   70|      0|  if (static_cast<uint32_t>(limit - p) < (*non_shared + *value_length)) {
   71|      0|    return nullptr;
   72|      0|  }
   73|      0|  return p;
   74|      0|}
   75|       |
   76|       |class Block::Iter : public Iterator {
   77|       | private:
   78|       |  const Comparator* const comparator_;
   79|       |  const char* const data_;       // underlying block contents
   80|       |  uint32_t const restarts_;      // Offset of restart array (list of fixed32)
   81|       |  uint32_t const num_restarts_;  // Number of uint32_t entries in restart array
   82|       |
   83|       |  // current_ is offset in data_ of current entry.  >= restarts_ if !Valid
   84|       |  uint32_t current_;
   85|       |  uint32_t restart_index_;  // Index of restart block in which current_ falls
   86|       |  std::string key_;
   87|       |  Slice value_;
   88|       |  Status status_;
   89|       |
   90|      0|  inline int Compare(const Slice& a, const Slice& b) const {
   91|      0|    return comparator_->Compare(a, b);
   92|      0|  }
   93|       |
   94|       |  // Return the offset in data_ just past the end of the current entry.
   95|      0|  inline uint32_t NextEntryOffset() const {
   96|      0|    return (value_.data() + value_.size()) - data_;
   97|      0|  }
   98|       |
   99|      0|  uint32_t GetRestartPoint(uint32_t index) {
  100|      0|    assert(index < num_restarts_);
  101|      0|    return DecodeFixed32(data_ + restarts_ + index * sizeof(uint32_t));
  102|      0|  }
  103|       |
  104|      0|  void SeekToRestartPoint(uint32_t index) {
  105|      0|    key_.clear();
  106|      0|    restart_index_ = index;
  107|      0|    // current_ will be fixed by ParseNextKey();
  108|      0|
  109|      0|    // ParseNextKey() starts at the end of value_, so set value_ accordingly
  110|      0|    uint32_t offset = GetRestartPoint(index);
  111|      0|    value_ = Slice(data_ + offset, 0);
  112|      0|  }
  113|       |
  114|       | public:
  115|       |  Iter(const Comparator* comparator, const char* data, uint32_t restarts,
  116|       |       uint32_t num_restarts)
  117|       |      : comparator_(comparator),
  118|       |        data_(data),
  119|       |        restarts_(restarts),
  120|       |        num_restarts_(num_restarts),
  121|       |        current_(restarts_),
  122|      0|        restart_index_(num_restarts_) {
  123|      0|    assert(num_restarts_ > 0);
  124|      0|  }
  125|       |
  126|      0|  virtual bool Valid() const { return current_ < restarts_; }
  127|      0|  virtual Status status() const { return status_; }
  128|      0|  virtual Slice key() const {
  129|      0|    assert(Valid());
  130|      0|    return key_;
  131|      0|  }
  132|      0|  virtual Slice value() const {
  133|      0|    assert(Valid());
  134|      0|    return value_;
  135|      0|  }
  136|       |
  137|      0|  virtual void Next() {
  138|      0|    assert(Valid());
  139|      0|    ParseNextKey();
  140|      0|  }
  141|       |
  142|      0|  virtual void Prev() {
  143|      0|    assert(Valid());
  144|      0|
  145|      0|    // Scan backwards to a restart point before current_
  146|      0|    const uint32_t original = current_;
  147|      0|    while (GetRestartPoint(restart_index_) >= original) {
  148|      0|      if (restart_index_ == 0) {
  149|      0|        // No more entries
  150|      0|        current_ = restarts_;
  151|      0|        restart_index_ = num_restarts_;
  152|      0|        return;
  153|      0|      }
  154|      0|      restart_index_--;
  155|      0|    }
  156|      0|
  157|      0|    SeekToRestartPoint(restart_index_);
  158|      0|    do {
  159|      0|      // Loop until end of current entry hits the start of original entry
  160|      0|    } while (ParseNextKey() && NextEntryOffset() < original);
  161|      0|  }
  162|       |
  163|      0|  virtual void Seek(const Slice& target) {
  164|      0|    // Binary search in restart array to find the last restart point
  165|      0|    // with a key < target
  166|      0|    uint32_t left = 0;
  167|      0|    uint32_t right = num_restarts_ - 1;
  168|      0|    while (left < right) {
  169|      0|      uint32_t mid = (left + right + 1) / 2;
  170|      0|      uint32_t region_offset = GetRestartPoint(mid);
  171|      0|      uint32_t shared, non_shared, value_length;
  172|      0|      const char* key_ptr =
  173|      0|          DecodeEntry(data_ + region_offset, data_ + restarts_, &shared,
  174|      0|                      &non_shared, &value_length);
  175|      0|      if (key_ptr == nullptr || (shared != 0)) {
  176|      0|        CorruptionError();
  177|      0|        return;
  178|      0|      }
  179|      0|      Slice mid_key(key_ptr, non_shared);
  180|      0|      if (Compare(mid_key, target) < 0) {
  181|      0|        // Key at "mid" is smaller than "target".  Therefore all
  182|      0|        // blocks before "mid" are uninteresting.
  183|      0|        left = mid;
  184|      0|      } else {
  185|      0|        // Key at "mid" is >= "target".  Therefore all blocks at or
  186|      0|        // after "mid" are uninteresting.
  187|      0|        right = mid - 1;
  188|      0|      }
  189|      0|    }
  190|      0|
  191|      0|    // Linear search (within restart block) for first key >= target
  192|      0|    SeekToRestartPoint(left);
  193|      0|    while (true) {
  194|      0|      if (!ParseNextKey()) {
  195|      0|        return;
  196|      0|      }
  197|      0|      if (Compare(key_, target) >= 0) {
  198|      0|        return;
  199|      0|      }
  200|      0|    }
  201|      0|  }
  202|       |
  203|      0|  virtual void SeekToFirst() {
  204|      0|    SeekToRestartPoint(0);
  205|      0|    ParseNextKey();
  206|      0|  }
  207|       |
  208|      0|  virtual void SeekToLast() {
  209|      0|    SeekToRestartPoint(num_restarts_ - 1);
  210|      0|    while (ParseNextKey() && NextEntryOffset() < restarts_) {
  211|      0|      // Keep skipping
  212|      0|    }
  213|      0|  }
  214|       |
  215|       | private:
  216|      0|  void CorruptionError() {
  217|      0|    current_ = restarts_;
  218|      0|    restart_index_ = num_restarts_;
  219|      0|    status_ = Status::Corruption("bad entry in block");
  220|      0|    key_.clear();
  221|      0|    value_.clear();
  222|      0|  }
  223|       |
  224|      0|  bool ParseNextKey() {
  225|      0|    current_ = NextEntryOffset();
  226|      0|    const char* p = data_ + current_;
  227|      0|    const char* limit = data_ + restarts_;  // Restarts come right after data
  228|      0|    if (p >= limit) {
  229|      0|      // No more entries to return.  Mark as invalid.
  230|      0|      current_ = restarts_;
  231|      0|      restart_index_ = num_restarts_;
  232|      0|      return false;
  233|      0|    }
  234|      0|
  235|      0|    // Decode next entry
  236|      0|    uint32_t shared, non_shared, value_length;
  237|      0|    p = DecodeEntry(p, limit, &shared, &non_shared, &value_length);
  238|      0|    if (p == nullptr || key_.size() < shared) {
  239|      0|      CorruptionError();
  240|      0|      return false;
  241|      0|    } else {
  242|      0|      key_.resize(shared);
  243|      0|      key_.append(p, non_shared);
  244|      0|      value_ = Slice(p + non_shared, value_length);
  245|      0|      while (restart_index_ + 1 < num_restarts_ &&
  246|      0|             GetRestartPoint(restart_index_ + 1) < current_) {
  247|      0|        ++restart_index_;
  248|      0|      }
  249|      0|      return true;
  250|      0|    }
  251|      0|  }
  252|       |};
  253|       |
  254|      0|Iterator* Block::NewIterator(const Comparator* comparator) {
  255|      0|  if (size_ < sizeof(uint32_t)) {
  256|      0|    return NewErrorIterator(Status::Corruption("bad block contents"));
  257|      0|  }
  258|      0|  const uint32_t num_restarts = NumRestarts();
  259|      0|  if (num_restarts == 0) {
  260|      0|    return NewEmptyIterator();
  261|      0|  } else {
  262|      0|    return new Iter(comparator, data_, restart_offset_, num_restarts);
  263|      0|  }
  264|      0|}
  265|       |
  266|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/block.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_TABLE_BLOCK_H_
    6|       |#define STORAGE_LEVELDB_TABLE_BLOCK_H_
    7|       |
    8|       |#include <stddef.h>
    9|       |#include <stdint.h>
   10|       |
   11|       |#include "leveldb/iterator.h"
   12|       |
   13|       |namespace leveldb {
   14|       |
   15|       |struct BlockContents;
   16|       |class Comparator;
   17|       |
   18|       |class Block {
   19|       | public:
   20|       |  // Initialize the block with the specified contents.
   21|       |  explicit Block(const BlockContents& contents);
   22|       |
   23|       |  Block(const Block&) = delete;
   24|       |  Block& operator=(const Block&) = delete;
   25|       |
   26|       |  ~Block();
   27|       |
   28|      0|  size_t size() const { return size_; }
   29|       |  Iterator* NewIterator(const Comparator* comparator);
   30|       |
   31|       | private:
   32|       |  class Iter;
   33|       |
   34|       |  uint32_t NumRestarts() const;
   35|       |
   36|       |  const char* data_;
   37|       |  size_t size_;
   38|       |  uint32_t restart_offset_;  // Offset in data_ of restart array
   39|       |  bool owned_;               // Block owns data_[]
   40|       |};
   41|       |
   42|       |}  // namespace leveldb
   43|       |
   44|       |#endif  // STORAGE_LEVELDB_TABLE_BLOCK_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/block_builder.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// BlockBuilder generates blocks where keys are prefix-compressed:
    6|       |//
    7|       |// When we store a key, we drop the prefix shared with the previous
    8|       |// string.  This helps reduce the space requirement significantly.
    9|       |// Furthermore, once every K keys, we do not apply the prefix
   10|       |// compression and store the entire key.  We call this a "restart
   11|       |// point".  The tail end of the block stores the offsets of all of the
   12|       |// restart points, and can be used to do a binary search when looking
   13|       |// for a particular key.  Values are stored as-is (without compression)
   14|       |// immediately following the corresponding key.
   15|       |//
   16|       |// An entry for a particular key-value pair has the form:
   17|       |//     shared_bytes: varint32
   18|       |//     unshared_bytes: varint32
   19|       |//     value_length: varint32
   20|       |//     key_delta: char[unshared_bytes]
   21|       |//     value: char[value_length]
   22|       |// shared_bytes == 0 for restart points.
   23|       |//
   24|       |// The trailer of the block has the form:
   25|       |//     restarts: uint32[num_restarts]
   26|       |//     num_restarts: uint32
   27|       |// restarts[i] contains the offset within the block of the ith restart point.
   28|       |
   29|       |#include "table/block_builder.h"
   30|       |
   31|       |#include <assert.h>
   32|       |
   33|       |#include <algorithm>
   34|       |
   35|       |#include "leveldb/comparator.h"
   36|       |#include "leveldb/table_builder.h"
   37|       |#include "util/coding.h"
   38|       |
   39|       |namespace leveldb {
   40|       |
   41|       |BlockBuilder::BlockBuilder(const Options* options)
   42|      0|    : options_(options), restarts_(), counter_(0), finished_(false) {
   43|      0|  assert(options->block_restart_interval >= 1);
   44|      0|  restarts_.push_back(0);  // First restart point is at offset 0
   45|      0|}
   46|       |
   47|      0|void BlockBuilder::Reset() {
   48|      0|  buffer_.clear();
   49|      0|  restarts_.clear();
   50|      0|  restarts_.push_back(0);  // First restart point is at offset 0
   51|      0|  counter_ = 0;
   52|      0|  finished_ = false;
   53|      0|  last_key_.clear();
   54|      0|}
   55|       |
   56|      0|size_t BlockBuilder::CurrentSizeEstimate() const {
   57|      0|  return (buffer_.size() +                       // Raw data buffer
   58|      0|          restarts_.size() * sizeof(uint32_t) +  // Restart array
   59|      0|          sizeof(uint32_t));                     // Restart array length
   60|      0|}
   61|       |
   62|      0|Slice BlockBuilder::Finish() {
   63|      0|  // Append restart array
   64|      0|  for (size_t i = 0; i < restarts_.size(); i++) {
   65|      0|    PutFixed32(&buffer_, restarts_[i]);
   66|      0|  }
   67|      0|  PutFixed32(&buffer_, restarts_.size());
   68|      0|  finished_ = true;
   69|      0|  return Slice(buffer_);
   70|      0|}
   71|       |
   72|      0|void BlockBuilder::Add(const Slice& key, const Slice& value) {
   73|      0|  Slice last_key_piece(last_key_);
   74|      0|  assert(!finished_);
   75|      0|  assert(counter_ <= options_->block_restart_interval);
   76|      0|  assert(buffer_.empty()  // No values yet?
   77|      0|         || options_->comparator->Compare(key, last_key_piece) > 0);
   78|      0|  size_t shared = 0;
   79|      0|  if (counter_ < options_->block_restart_interval) {
   80|      0|    // See how much sharing to do with previous string
   81|      0|    const size_t min_length = std::min(last_key_piece.size(), key.size());
   82|      0|    while ((shared < min_length) && (last_key_piece[shared] == key[shared])) {
   83|      0|      shared++;
   84|      0|    }
   85|      0|  } else {
   86|      0|    // Restart compression
   87|      0|    restarts_.push_back(buffer_.size());
   88|      0|    counter_ = 0;
   89|      0|  }
   90|      0|  const size_t non_shared = key.size() - shared;
   91|      0|
   92|      0|  // Add "<shared><non_shared><value_size>" to buffer_
   93|      0|  PutVarint32(&buffer_, shared);
   94|      0|  PutVarint32(&buffer_, non_shared);
   95|      0|  PutVarint32(&buffer_, value.size());
   96|      0|
   97|      0|  // Add string delta to buffer_ followed by value
   98|      0|  buffer_.append(key.data() + shared, non_shared);
   99|      0|  buffer_.append(value.data(), value.size());
  100|      0|
  101|      0|  // Update state
  102|      0|  last_key_.resize(shared);
  103|      0|  last_key_.append(key.data() + shared, non_shared);
  104|      0|  assert(Slice(last_key_) == key);
  105|      0|  counter_++;
  106|      0|}
  107|       |
  108|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/block_builder.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_TABLE_BLOCK_BUILDER_H_
    6|       |#define STORAGE_LEVELDB_TABLE_BLOCK_BUILDER_H_
    7|       |
    8|       |#include <stdint.h>
    9|       |
   10|       |#include <vector>
   11|       |
   12|       |#include "leveldb/slice.h"
   13|       |
   14|       |namespace leveldb {
   15|       |
   16|       |struct Options;
   17|       |
   18|       |class BlockBuilder {
   19|       | public:
   20|       |  explicit BlockBuilder(const Options* options);
   21|       |
   22|       |  BlockBuilder(const BlockBuilder&) = delete;
   23|       |  BlockBuilder& operator=(const BlockBuilder&) = delete;
   24|       |
   25|       |  // Reset the contents as if the BlockBuilder was just constructed.
   26|       |  void Reset();
   27|       |
   28|       |  // REQUIRES: Finish() has not been called since the last call to Reset().
   29|       |  // REQUIRES: key is larger than any previously added key
   30|       |  void Add(const Slice& key, const Slice& value);
   31|       |
   32|       |  // Finish building the block and return a slice that refers to the
   33|       |  // block contents.  The returned slice will remain valid for the
   34|       |  // lifetime of this builder or until Reset() is called.
   35|       |  Slice Finish();
   36|       |
   37|       |  // Returns an estimate of the current (uncompressed) size of the block
   38|       |  // we are building.
   39|       |  size_t CurrentSizeEstimate() const;
   40|       |
   41|       |  // Return true iff no entries have been added since the last Reset()
   42|      0|  bool empty() const { return buffer_.empty(); }
   43|       |
   44|       | private:
   45|       |  const Options* options_;
   46|       |  std::string buffer_;              // Destination buffer
   47|       |  std::vector<uint32_t> restarts_;  // Restart points
   48|       |  int counter_;                     // Number of entries emitted since restart
   49|       |  bool finished_;                   // Has Finish() been called?
   50|       |  std::string last_key_;
   51|       |};
   52|       |
   53|       |}  // namespace leveldb
   54|       |
   55|       |#endif  // STORAGE_LEVELDB_TABLE_BLOCK_BUILDER_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/filter_block.cc:
    1|       |// Copyright (c) 2012 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "table/filter_block.h"
    6|       |
    7|       |#include "leveldb/filter_policy.h"
    8|       |#include "util/coding.h"
    9|       |
   10|       |namespace leveldb {
   11|       |
   12|       |// See doc/table_format.md for an explanation of the filter block format.
   13|       |
   14|       |// Generate new filter every 2KB of data
   15|       |static const size_t kFilterBaseLg = 11;
   16|       |static const size_t kFilterBase = 1 << kFilterBaseLg;
   17|       |
   18|       |FilterBlockBuilder::FilterBlockBuilder(const FilterPolicy* policy)
   19|      0|    : policy_(policy) {}
   20|       |
   21|      0|void FilterBlockBuilder::StartBlock(uint64_t block_offset) {
   22|      0|  uint64_t filter_index = (block_offset / kFilterBase);
   23|      0|  assert(filter_index >= filter_offsets_.size());
   24|      0|  while (filter_index > filter_offsets_.size()) {
   25|      0|    GenerateFilter();
   26|      0|  }
   27|      0|}
   28|       |
   29|      0|void FilterBlockBuilder::AddKey(const Slice& key) {
   30|      0|  Slice k = key;
   31|      0|  start_.push_back(keys_.size());
   32|      0|  keys_.append(k.data(), k.size());
   33|      0|}
   34|       |
   35|      0|Slice FilterBlockBuilder::Finish() {
   36|      0|  if (!start_.empty()) {
   37|      0|    GenerateFilter();
   38|      0|  }
   39|      0|
   40|      0|  // Append array of per-filter offsets
   41|      0|  const uint32_t array_offset = result_.size();
   42|      0|  for (size_t i = 0; i < filter_offsets_.size(); i++) {
   43|      0|    PutFixed32(&result_, filter_offsets_[i]);
   44|      0|  }
   45|      0|
   46|      0|  PutFixed32(&result_, array_offset);
   47|      0|  result_.push_back(kFilterBaseLg);  // Save encoding parameter in result
   48|      0|  return Slice(result_);
   49|      0|}
   50|       |
   51|      0|void FilterBlockBuilder::GenerateFilter() {
   52|      0|  const size_t num_keys = start_.size();
   53|      0|  if (num_keys == 0) {
   54|      0|    // Fast path if there are no keys for this filter
   55|      0|    filter_offsets_.push_back(result_.size());
   56|      0|    return;
   57|      0|  }
   58|      0|
   59|      0|  // Make list of keys from flattened key structure
   60|      0|  start_.push_back(keys_.size());  // Simplify length computation
   61|      0|  tmp_keys_.resize(num_keys);
   62|      0|  for (size_t i = 0; i < num_keys; i++) {
   63|      0|    const char* base = keys_.data() + start_[i];
   64|      0|    size_t length = start_[i + 1] - start_[i];
   65|      0|    tmp_keys_[i] = Slice(base, length);
   66|      0|  }
   67|      0|
   68|      0|  // Generate filter for current set of keys and append to result_.
   69|      0|  filter_offsets_.push_back(result_.size());
   70|      0|  policy_->CreateFilter(&tmp_keys_[0], static_cast<int>(num_keys), &result_);
   71|      0|
   72|      0|  tmp_keys_.clear();
   73|      0|  keys_.clear();
   74|      0|  start_.clear();
   75|      0|}
   76|       |
   77|       |FilterBlockReader::FilterBlockReader(const FilterPolicy* policy,
   78|       |                                     const Slice& contents)
   79|      0|    : policy_(policy), data_(nullptr), offset_(nullptr), num_(0), base_lg_(0) {
   80|      0|  size_t n = contents.size();
   81|      0|  if (n < 5) return;  // 1 byte for base_lg_ and 4 for start of offset array
   82|      0|  base_lg_ = contents[n - 1];
   83|      0|  uint32_t last_word = DecodeFixed32(contents.data() + n - 5);
   84|      0|  if (last_word > n - 5) return;
   85|      0|  data_ = contents.data();
   86|      0|  offset_ = data_ + last_word;
   87|      0|  num_ = (n - 5 - last_word) / 4;
   88|      0|}
   89|       |
   90|      0|bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, const Slice& key) {
   91|      0|  uint64_t index = block_offset >> base_lg_;
   92|      0|  if (index < num_) {
   93|      0|    uint32_t start = DecodeFixed32(offset_ + index * 4);
   94|      0|    uint32_t limit = DecodeFixed32(offset_ + index * 4 + 4);
   95|      0|    if (start <= limit && limit <= static_cast<size_t>(offset_ - data_)) {
   96|      0|      Slice filter = Slice(data_ + start, limit - start);
   97|      0|      return policy_->KeyMayMatch(key, filter);
   98|      0|    } else if (start == limit) {
   99|      0|      // Empty filters do not match any keys
  100|      0|      return false;
  101|      0|    }
  102|      0|  }
  103|      0|  return true;  // Errors are treated as potential matches
  104|      0|}
  105|       |
  106|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/format.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "table/format.h"
    6|       |
    7|       |#include "leveldb/env.h"
    8|       |#include "port/port.h"
    9|       |#include "table/block.h"
   10|       |#include "util/coding.h"
   11|       |#include "util/crc32c.h"
   12|       |
   13|       |namespace leveldb {
   14|       |
   15|      0|void BlockHandle::EncodeTo(std::string* dst) const {
   16|      0|  // Sanity check that all fields have been set
   17|      0|  assert(offset_ != ~static_cast<uint64_t>(0));
   18|      0|  assert(size_ != ~static_cast<uint64_t>(0));
   19|      0|  PutVarint64(dst, offset_);
   20|      0|  PutVarint64(dst, size_);
   21|      0|}
   22|       |
   23|      0|Status BlockHandle::DecodeFrom(Slice* input) {
   24|      0|  if (GetVarint64(input, &offset_) && GetVarint64(input, &size_)) {
   25|      0|    return Status::OK();
   26|      0|  } else {
   27|      0|    return Status::Corruption("bad block handle");
   28|      0|  }
   29|      0|}
   30|       |
   31|      0|void Footer::EncodeTo(std::string* dst) const {
   32|      0|  const size_t original_size = dst->size();
   33|      0|  metaindex_handle_.EncodeTo(dst);
   34|      0|  index_handle_.EncodeTo(dst);
   35|      0|  dst->resize(2 * BlockHandle::kMaxEncodedLength);  // Padding
   36|      0|  PutFixed32(dst, static_cast<uint32_t>(kTableMagicNumber & 0xffffffffu));
   37|      0|  PutFixed32(dst, static_cast<uint32_t>(kTableMagicNumber >> 32));
   38|      0|  assert(dst->size() == original_size + kEncodedLength);
   39|      0|  (void)original_size;  // Disable unused variable warning.
   40|      0|}
   41|       |
   42|      0|Status Footer::DecodeFrom(Slice* input) {
   43|      0|  const char* magic_ptr = input->data() + kEncodedLength - 8;
   44|      0|  const uint32_t magic_lo = DecodeFixed32(magic_ptr);
   45|      0|  const uint32_t magic_hi = DecodeFixed32(magic_ptr + 4);
   46|      0|  const uint64_t magic = ((static_cast<uint64_t>(magic_hi) << 32) |
   47|      0|                          (static_cast<uint64_t>(magic_lo)));
   48|      0|  if (magic != kTableMagicNumber) {
   49|      0|    return Status::Corruption("not an sstable (bad magic number)");
   50|      0|  }
   51|      0|
   52|      0|  Status result = metaindex_handle_.DecodeFrom(input);
   53|      0|  if (result.ok()) {
   54|      0|    result = index_handle_.DecodeFrom(input);
   55|      0|  }
   56|      0|  if (result.ok()) {
   57|      0|    // We skip over any leftover data (just padding for now) in "input"
   58|      0|    const char* end = magic_ptr + 8;
   59|      0|    *input = Slice(end, input->data() + input->size() - end);
   60|      0|  }
   61|      0|  return result;
   62|      0|}
   63|       |
   64|       |Status ReadBlock(RandomAccessFile* file, const ReadOptions& options,
   65|      0|                 const BlockHandle& handle, BlockContents* result) {
   66|      0|  result->data = Slice();
   67|      0|  result->cachable = false;
   68|      0|  result->heap_allocated = false;
   69|      0|
   70|      0|  // Read the block contents as well as the type/crc footer.
   71|      0|  // See table_builder.cc for the code that built this structure.
   72|      0|  size_t n = static_cast<size_t>(handle.size());
   73|      0|  char* buf = new char[n + kBlockTrailerSize];
   74|      0|  Slice contents;
   75|      0|  Status s = file->Read(handle.offset(), n + kBlockTrailerSize, &contents, buf);
   76|      0|  if (!s.ok()) {
   77|      0|    delete[] buf;
   78|      0|    return s;
   79|      0|  }
   80|      0|  if (contents.size() != n + kBlockTrailerSize) {
   81|      0|    delete[] buf;
   82|      0|    return Status::Corruption("truncated block read");
   83|      0|  }
   84|      0|
   85|      0|  // Check the crc of the type and the block contents
   86|      0|  const char* data = contents.data();  // Pointer to where Read put the data
   87|      0|  if (options.verify_checksums) {
   88|      0|    const uint32_t crc = crc32c::Unmask(DecodeFixed32(data + n + 1));
   89|      0|    const uint32_t actual = crc32c::Value(data, n + 1);
   90|      0|    if (actual != crc) {
   91|      0|      delete[] buf;
   92|      0|      s = Status::Corruption("block checksum mismatch");
   93|      0|      return s;
   94|      0|    }
   95|      0|  }
   96|      0|
   97|      0|  switch (data[n]) {
   98|      0|    case kNoCompression:
   99|      0|      if (data != buf) {
  100|      0|        // File implementation gave us pointer to some other data.
  101|      0|        // Use it directly under the assumption that it will be live
  102|      0|        // while the file is open.
  103|      0|        delete[] buf;
  104|      0|        result->data = Slice(data, n);
  105|      0|        result->heap_allocated = false;
  106|      0|        result->cachable = false;  // Do not double-cache
  107|      0|      } else {
  108|      0|        result->data = Slice(buf, n);
  109|      0|        result->heap_allocated = true;
  110|      0|        result->cachable = true;
  111|      0|      }
  112|      0|
  113|      0|      // Ok
  114|      0|      break;
  115|      0|    case kSnappyCompression: {
  116|      0|      size_t ulength = 0;
  117|      0|      if (!port::Snappy_GetUncompressedLength(data, n, &ulength)) {
  118|      0|        delete[] buf;
  119|      0|        return Status::Corruption("corrupted compressed block contents");
  120|      0|      }
  121|      0|      char* ubuf = new char[ulength];
  122|      0|      if (!port::Snappy_Uncompress(data, n, ubuf)) {
  123|      0|        delete[] buf;
  124|      0|        delete[] ubuf;
  125|      0|        return Status::Corruption("corrupted compressed block contents");
  126|      0|      }
  127|      0|      delete[] buf;
  128|      0|      result->data = Slice(ubuf, ulength);
  129|      0|      result->heap_allocated = true;
  130|      0|      result->cachable = true;
  131|      0|      break;
  132|      0|    }
  133|      0|    default:
  134|      0|      delete[] buf;
  135|      0|      return Status::Corruption("bad block type");
  136|      0|  }
  137|      0|
  138|      0|  return Status::OK();
  139|      0|}
  140|       |
  141|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/format.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_TABLE_FORMAT_H_
    6|       |#define STORAGE_LEVELDB_TABLE_FORMAT_H_
    7|       |
    8|       |#include <stdint.h>
    9|       |
   10|       |#include <string>
   11|       |
   12|       |#include "leveldb/slice.h"
   13|       |#include "leveldb/status.h"
   14|       |#include "leveldb/table_builder.h"
   15|       |
   16|       |namespace leveldb {
   17|       |
   18|       |class Block;
   19|       |class RandomAccessFile;
   20|       |struct ReadOptions;
   21|       |
   22|       |// BlockHandle is a pointer to the extent of a file that stores a data
   23|       |// block or a meta block.
   24|       |class BlockHandle {
   25|       | public:
   26|       |  // Maximum encoding length of a BlockHandle
   27|       |  enum { kMaxEncodedLength = 10 + 10 };
   28|       |
   29|       |  BlockHandle();
   30|       |
   31|       |  // The offset of the block in the file.
   32|      0|  uint64_t offset() const { return offset_; }
   33|      0|  void set_offset(uint64_t offset) { offset_ = offset; }
   34|       |
   35|       |  // The size of the stored block
   36|      0|  uint64_t size() const { return size_; }
   37|      0|  void set_size(uint64_t size) { size_ = size; }
   38|       |
   39|       |  void EncodeTo(std::string* dst) const;
   40|       |  Status DecodeFrom(Slice* input);
   41|       |
   42|       | private:
   43|       |  uint64_t offset_;
   44|       |  uint64_t size_;
   45|       |};
   46|       |
   47|       |// Footer encapsulates the fixed information stored at the tail
   48|       |// end of every table file.
   49|       |class Footer {
   50|       | public:
   51|       |  // Encoded length of a Footer.  Note that the serialization of a
   52|       |  // Footer will always occupy exactly this many bytes.  It consists
   53|       |  // of two block handles and a magic number.
   54|       |  enum { kEncodedLength = 2 * BlockHandle::kMaxEncodedLength + 8 };
   55|       |
   56|      0|  Footer() {}
   57|       |
   58|       |  // The block handle for the metaindex block of the table
   59|      0|  const BlockHandle& metaindex_handle() const { return metaindex_handle_; }
   60|      0|  void set_metaindex_handle(const BlockHandle& h) { metaindex_handle_ = h; }
   61|       |
   62|       |  // The block handle for the index block of the table
   63|      0|  const BlockHandle& index_handle() const { return index_handle_; }
   64|      0|  void set_index_handle(const BlockHandle& h) { index_handle_ = h; }
   65|       |
   66|       |  void EncodeTo(std::string* dst) const;
   67|       |  Status DecodeFrom(Slice* input);
   68|       |
   69|       | private:
   70|       |  BlockHandle metaindex_handle_;
   71|       |  BlockHandle index_handle_;
   72|       |};
   73|       |
   74|       |// kTableMagicNumber was picked by running
   75|       |//    echo http://code.google.com/p/leveldb/ | sha1sum
   76|       |// and taking the leading 64 bits.
   77|       |static const uint64_t kTableMagicNumber = 0xdb4775248b80fb57ull;
   78|       |
   79|       |// 1-byte type + 32-bit crc
   80|       |static const size_t kBlockTrailerSize = 5;
   81|       |
   82|       |struct BlockContents {
   83|       |  Slice data;           // Actual contents of data
   84|       |  bool cachable;        // True iff data can be cached
   85|       |  bool heap_allocated;  // True iff caller should delete[] data.data()
   86|       |};
   87|       |
   88|       |// Read the block identified by "handle" from "file".  On failure
   89|       |// return non-OK.  On success fill *result and return OK.
   90|       |Status ReadBlock(RandomAccessFile* file, const ReadOptions& options,
   91|       |                 const BlockHandle& handle, BlockContents* result);
   92|       |
   93|       |// Implementation details follow.  Clients should ignore,
   94|       |
   95|       |inline BlockHandle::BlockHandle()
   96|      0|    : offset_(~static_cast<uint64_t>(0)), size_(~static_cast<uint64_t>(0)) {}
   97|       |
   98|       |}  // namespace leveldb
   99|       |
  100|       |#endif  // STORAGE_LEVELDB_TABLE_FORMAT_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/iterator.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "leveldb/iterator.h"
    6|       |
    7|       |namespace leveldb {
    8|       |
    9|      0|Iterator::Iterator() {
   10|      0|  cleanup_head_.function = nullptr;
   11|      0|  cleanup_head_.next = nullptr;
   12|      0|}
   13|       |
   14|      0|Iterator::~Iterator() {
   15|      0|  if (!cleanup_head_.IsEmpty()) {
   16|      0|    cleanup_head_.Run();
   17|      0|    for (CleanupNode* node = cleanup_head_.next; node != nullptr;) {
   18|      0|      node->Run();
   19|      0|      CleanupNode* next_node = node->next;
   20|      0|      delete node;
   21|      0|      node = next_node;
   22|      0|    }
   23|      0|  }
   24|      0|}
   25|       |
   26|      0|void Iterator::RegisterCleanup(CleanupFunction func, void* arg1, void* arg2) {
   27|      0|  assert(func != nullptr);
   28|      0|  CleanupNode* node;
   29|      0|  if (cleanup_head_.IsEmpty()) {
   30|      0|    node = &cleanup_head_;
   31|      0|  } else {
   32|      0|    node = new CleanupNode();
   33|      0|    node->next = cleanup_head_.next;
   34|      0|    cleanup_head_.next = node;
   35|      0|  }
   36|      0|  node->function = func;
   37|      0|  node->arg1 = arg1;
   38|      0|  node->arg2 = arg2;
   39|      0|}
   40|       |
   41|       |namespace {
   42|       |
   43|       |class EmptyIterator : public Iterator {
   44|       | public:
   45|      0|  EmptyIterator(const Status& s) : status_(s) {}
   46|      0|  ~EmptyIterator() override = default;
   47|       |
   48|      0|  bool Valid() const override { return false; }
   49|      0|  void Seek(const Slice& target) override {}
   50|      0|  void SeekToFirst() override {}
   51|      0|  void SeekToLast() override {}
   52|      0|  void Next() override { assert(false); }
   53|      0|  void Prev() override { assert(false); }
   54|      0|  Slice key() const override {
   55|      0|    assert(false);
   56|      0|    return Slice();
   57|      0|  }
   58|      0|  Slice value() const override {
   59|      0|    assert(false);
   60|      0|    return Slice();
   61|      0|  }
   62|      0|  Status status() const override { return status_; }
   63|       |
   64|       | private:
   65|       |  Status status_;
   66|       |};
   67|       |
   68|       |}  // anonymous namespace
   69|       |
   70|      0|Iterator* NewEmptyIterator() { return new EmptyIterator(Status::OK()); }
   71|       |
   72|      0|Iterator* NewErrorIterator(const Status& status) {
   73|      0|  return new EmptyIterator(status);
   74|      0|}
   75|       |
   76|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/iterator_wrapper.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_TABLE_ITERATOR_WRAPPER_H_
    6|       |#define STORAGE_LEVELDB_TABLE_ITERATOR_WRAPPER_H_
    7|       |
    8|       |#include "leveldb/iterator.h"
    9|       |#include "leveldb/slice.h"
   10|       |
   11|       |namespace leveldb {
   12|       |
   13|       |// A internal wrapper class with an interface similar to Iterator that
   14|       |// caches the valid() and key() results for an underlying iterator.
   15|       |// This can help avoid virtual function calls and also gives better
   16|       |// cache locality.
   17|       |class IteratorWrapper {
   18|       | public:
   19|      0|  IteratorWrapper() : iter_(nullptr), valid_(false) {}
   20|      0|  explicit IteratorWrapper(Iterator* iter) : iter_(nullptr) { Set(iter); }
   21|      0|  ~IteratorWrapper() { delete iter_; }
   22|      0|  Iterator* iter() const { return iter_; }
   23|       |
   24|       |  // Takes ownership of "iter" and will delete it when destroyed, or
   25|       |  // when Set() is invoked again.
   26|      0|  void Set(Iterator* iter) {
   27|      0|    delete iter_;
   28|      0|    iter_ = iter;
   29|      0|    if (iter_ == nullptr) {
   30|      0|      valid_ = false;
   31|      0|    } else {
   32|      0|      Update();
   33|      0|    }
   34|      0|  }
   35|       |
   36|       |  // Iterator interface methods
   37|      0|  bool Valid() const { return valid_; }
   38|      0|  Slice key() const {
   39|      0|    assert(Valid());
   40|      0|    return key_;
   41|      0|  }
   42|      0|  Slice value() const {
   43|      0|    assert(Valid());
   44|      0|    return iter_->value();
   45|      0|  }
   46|       |  // Methods below require iter() != nullptr
   47|      0|  Status status() const {
   48|      0|    assert(iter_);
   49|      0|    return iter_->status();
   50|      0|  }
   51|      0|  void Next() {
   52|      0|    assert(iter_);
   53|      0|    iter_->Next();
   54|      0|    Update();
   55|      0|  }
   56|      0|  void Prev() {
   57|      0|    assert(iter_);
   58|      0|    iter_->Prev();
   59|      0|    Update();
   60|      0|  }
   61|      0|  void Seek(const Slice& k) {
   62|      0|    assert(iter_);
   63|      0|    iter_->Seek(k);
   64|      0|    Update();
   65|      0|  }
   66|      0|  void SeekToFirst() {
   67|      0|    assert(iter_);
   68|      0|    iter_->SeekToFirst();
   69|      0|    Update();
   70|      0|  }
   71|      0|  void SeekToLast() {
   72|      0|    assert(iter_);
   73|      0|    iter_->SeekToLast();
   74|      0|    Update();
   75|      0|  }
   76|       |
   77|       | private:
   78|      0|  void Update() {
   79|      0|    valid_ = iter_->Valid();
   80|      0|    if (valid_) {
   81|      0|      key_ = iter_->key();
   82|      0|    }
   83|      0|  }
   84|       |
   85|       |  Iterator* iter_;
   86|       |  bool valid_;
   87|       |  Slice key_;
   88|       |};
   89|       |
   90|       |}  // namespace leveldb
   91|       |
   92|       |#endif  // STORAGE_LEVELDB_TABLE_ITERATOR_WRAPPER_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/merger.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "table/merger.h"
    6|       |
    7|       |#include "leveldb/comparator.h"
    8|       |#include "leveldb/iterator.h"
    9|       |#include "table/iterator_wrapper.h"
   10|       |
   11|       |namespace leveldb {
   12|       |
   13|       |namespace {
   14|       |class MergingIterator : public Iterator {
   15|       | public:
   16|       |  MergingIterator(const Comparator* comparator, Iterator** children, int n)
   17|       |      : comparator_(comparator),
   18|       |        children_(new IteratorWrapper[n]),
   19|       |        n_(n),
   20|       |        current_(nullptr),
   21|      0|        direction_(kForward) {
   22|      0|    for (int i = 0; i < n; i++) {
   23|      0|      children_[i].Set(children[i]);
   24|      0|    }
   25|      0|  }
   26|       |
   27|      0|  virtual ~MergingIterator() { delete[] children_; }
   28|       |
   29|      0|  virtual bool Valid() const { return (current_ != nullptr); }
   30|       |
   31|      0|  virtual void SeekToFirst() {
   32|      0|    for (int i = 0; i < n_; i++) {
   33|      0|      children_[i].SeekToFirst();
   34|      0|    }
   35|      0|    FindSmallest();
   36|      0|    direction_ = kForward;
   37|      0|  }
   38|       |
   39|      0|  virtual void SeekToLast() {
   40|      0|    for (int i = 0; i < n_; i++) {
   41|      0|      children_[i].SeekToLast();
   42|      0|    }
   43|      0|    FindLargest();
   44|      0|    direction_ = kReverse;
   45|      0|  }
   46|       |
   47|      0|  virtual void Seek(const Slice& target) {
   48|      0|    for (int i = 0; i < n_; i++) {
   49|      0|      children_[i].Seek(target);
   50|      0|    }
   51|      0|    FindSmallest();
   52|      0|    direction_ = kForward;
   53|      0|  }
   54|       |
   55|      0|  virtual void Next() {
   56|      0|    assert(Valid());
   57|      0|
   58|      0|    // Ensure that all children are positioned after key().
   59|      0|    // If we are moving in the forward direction, it is already
   60|      0|    // true for all of the non-current_ children since current_ is
   61|      0|    // the smallest child and key() == current_->key().  Otherwise,
   62|      0|    // we explicitly position the non-current_ children.
   63|      0|    if (direction_ != kForward) {
   64|      0|      for (int i = 0; i < n_; i++) {
   65|      0|        IteratorWrapper* child = &children_[i];
   66|      0|        if (child != current_) {
   67|      0|          child->Seek(key());
   68|      0|          if (child->Valid() &&
   69|      0|              comparator_->Compare(key(), child->key()) == 0) {
   70|      0|            child->Next();
   71|      0|          }
   72|      0|        }
   73|      0|      }
   74|      0|      direction_ = kForward;
   75|      0|    }
   76|      0|
   77|      0|    current_->Next();
   78|      0|    FindSmallest();
   79|      0|  }
   80|       |
   81|      0|  virtual void Prev() {
   82|      0|    assert(Valid());
   83|      0|
   84|      0|    // Ensure that all children are positioned before key().
   85|      0|    // If we are moving in the reverse direction, it is already
   86|      0|    // true for all of the non-current_ children since current_ is
   87|      0|    // the largest child and key() == current_->key().  Otherwise,
   88|      0|    // we explicitly position the non-current_ children.
   89|      0|    if (direction_ != kReverse) {
   90|      0|      for (int i = 0; i < n_; i++) {
   91|      0|        IteratorWrapper* child = &children_[i];
   92|      0|        if (child != current_) {
   93|      0|          child->Seek(key());
   94|      0|          if (child->Valid()) {
   95|      0|            // Child is at first entry >= key().  Step back one to be < key()
   96|      0|            child->Prev();
   97|      0|          } else {
   98|      0|            // Child has no entries >= key().  Position at last entry.
   99|      0|            child->SeekToLast();
  100|      0|          }
  101|      0|        }
  102|      0|      }
  103|      0|      direction_ = kReverse;
  104|      0|    }
  105|      0|
  106|      0|    current_->Prev();
  107|      0|    FindLargest();
  108|      0|  }
  109|       |
  110|      0|  virtual Slice key() const {
  111|      0|    assert(Valid());
  112|      0|    return current_->key();
  113|      0|  }
  114|       |
  115|      0|  virtual Slice value() const {
  116|      0|    assert(Valid());
  117|      0|    return current_->value();
  118|      0|  }
  119|       |
  120|      0|  virtual Status status() const {
  121|      0|    Status status;
  122|      0|    for (int i = 0; i < n_; i++) {
  123|      0|      status = children_[i].status();
  124|      0|      if (!status.ok()) {
  125|      0|        break;
  126|      0|      }
  127|      0|    }
  128|      0|    return status;
  129|      0|  }
  130|       |
  131|       | private:
  132|       |  // Which direction is the iterator moving?
  133|       |  enum Direction { kForward, kReverse };
  134|       |
  135|       |  void FindSmallest();
  136|       |  void FindLargest();
  137|       |
  138|       |  // We might want to use a heap in case there are lots of children.
  139|       |  // For now we use a simple array since we expect a very small number
  140|       |  // of children in leveldb.
  141|       |  const Comparator* comparator_;
  142|       |  IteratorWrapper* children_;
  143|       |  int n_;
  144|       |  IteratorWrapper* current_;
  145|       |  Direction direction_;
  146|       |};
  147|       |
  148|      0|void MergingIterator::FindSmallest() {
  149|      0|  IteratorWrapper* smallest = nullptr;
  150|      0|  for (int i = 0; i < n_; i++) {
  151|      0|    IteratorWrapper* child = &children_[i];
  152|      0|    if (child->Valid()) {
  153|      0|      if (smallest == nullptr) {
  154|      0|        smallest = child;
  155|      0|      } else if (comparator_->Compare(child->key(), smallest->key()) < 0) {
  156|      0|        smallest = child;
  157|      0|      }
  158|      0|    }
  159|      0|  }
  160|      0|  current_ = smallest;
  161|      0|}
  162|       |
  163|      0|void MergingIterator::FindLargest() {
  164|      0|  IteratorWrapper* largest = nullptr;
  165|      0|  for (int i = n_ - 1; i >= 0; i--) {
  166|      0|    IteratorWrapper* child = &children_[i];
  167|      0|    if (child->Valid()) {
  168|      0|      if (largest == nullptr) {
  169|      0|        largest = child;
  170|      0|      } else if (comparator_->Compare(child->key(), largest->key()) > 0) {
  171|      0|        largest = child;
  172|      0|      }
  173|      0|    }
  174|      0|  }
  175|      0|  current_ = largest;
  176|      0|}
  177|       |}  // namespace
  178|       |
  179|       |Iterator* NewMergingIterator(const Comparator* comparator, Iterator** children,
  180|      0|                             int n) {
  181|      0|  assert(n >= 0);
  182|      0|  if (n == 0) {
  183|      0|    return NewEmptyIterator();
  184|      0|  } else if (n == 1) {
  185|      0|    return children[0];
  186|      0|  } else {
  187|      0|    return new MergingIterator(comparator, children, n);
  188|      0|  }
  189|      0|}
  190|       |
  191|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/table.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "leveldb/table.h"
    6|       |
    7|       |#include "leveldb/cache.h"
    8|       |#include "leveldb/comparator.h"
    9|       |#include "leveldb/env.h"
   10|       |#include "leveldb/filter_policy.h"
   11|       |#include "leveldb/options.h"
   12|       |#include "table/block.h"
   13|       |#include "table/filter_block.h"
   14|       |#include "table/format.h"
   15|       |#include "table/two_level_iterator.h"
   16|       |#include "util/coding.h"
   17|       |
   18|       |namespace leveldb {
   19|       |
   20|       |struct Table::Rep {
   21|      0|  ~Rep() {
   22|      0|    delete filter;
   23|      0|    delete[] filter_data;
   24|      0|    delete index_block;
   25|      0|  }
   26|       |
   27|       |  Options options;
   28|       |  Status status;
   29|       |  RandomAccessFile* file;
   30|       |  uint64_t cache_id;
   31|       |  FilterBlockReader* filter;
   32|       |  const char* filter_data;
   33|       |
   34|       |  BlockHandle metaindex_handle;  // Handle to metaindex_block: saved from footer
   35|       |  Block* index_block;
   36|       |};
   37|       |
   38|       |Status Table::Open(const Options& options, RandomAccessFile* file,
   39|      0|                   uint64_t size, Table** table) {
   40|      0|  *table = nullptr;
   41|      0|  if (size < Footer::kEncodedLength) {
   42|      0|    return Status::Corruption("file is too short to be an sstable");
   43|      0|  }
   44|      0|
   45|      0|  char footer_space[Footer::kEncodedLength];
   46|      0|  Slice footer_input;
   47|      0|  Status s = file->Read(size - Footer::kEncodedLength, Footer::kEncodedLength,
   48|      0|                        &footer_input, footer_space);
   49|      0|  if (!s.ok()) return s;
   50|      0|
   51|      0|  Footer footer;
   52|      0|  s = footer.DecodeFrom(&footer_input);
   53|      0|  if (!s.ok()) return s;
   54|      0|
   55|      0|  // Read the index block
   56|      0|  BlockContents index_block_contents;
   57|      0|  if (s.ok()) {
   58|      0|    ReadOptions opt;
   59|      0|    if (options.paranoid_checks) {
   60|      0|      opt.verify_checksums = true;
   61|      0|    }
   62|      0|    s = ReadBlock(file, opt, footer.index_handle(), &index_block_contents);
   63|      0|  }
   64|      0|
   65|      0|  if (s.ok()) {
   66|      0|    // We've successfully read the footer and the index block: we're
   67|      0|    // ready to serve requests.
   68|      0|    Block* index_block = new Block(index_block_contents);
   69|      0|    Rep* rep = new Table::Rep;
   70|      0|    rep->options = options;
   71|      0|    rep->file = file;
   72|      0|    rep->metaindex_handle = footer.metaindex_handle();
   73|      0|    rep->index_block = index_block;
   74|      0|    rep->cache_id = (options.block_cache ? options.block_cache->NewId() : 0);
   75|      0|    rep->filter_data = nullptr;
   76|      0|    rep->filter = nullptr;
   77|      0|    *table = new Table(rep);
   78|      0|    (*table)->ReadMeta(footer);
   79|      0|  }
   80|      0|
   81|      0|  return s;
   82|      0|}
   83|       |
   84|      0|void Table::ReadMeta(const Footer& footer) {
   85|      0|  if (rep_->options.filter_policy == nullptr) {
   86|      0|    return;  // Do not need any metadata
   87|      0|  }
   88|      0|
   89|      0|  // TODO(sanjay): Skip this if footer.metaindex_handle() size indicates
   90|      0|  // it is an empty block.
   91|      0|  ReadOptions opt;
   92|      0|  if (rep_->options.paranoid_checks) {
   93|      0|    opt.verify_checksums = true;
   94|      0|  }
   95|      0|  BlockContents contents;
   96|      0|  if (!ReadBlock(rep_->file, opt, footer.metaindex_handle(), &contents).ok()) {
   97|      0|    // Do not propagate errors since meta info is not needed for operation
   98|      0|    return;
   99|      0|  }
  100|      0|  Block* meta = new Block(contents);
  101|      0|
  102|      0|  Iterator* iter = meta->NewIterator(BytewiseComparator());
  103|      0|  std::string key = "filter.";
  104|      0|  key.append(rep_->options.filter_policy->Name());
  105|      0|  iter->Seek(key);
  106|      0|  if (iter->Valid() && iter->key() == Slice(key)) {
  107|      0|    ReadFilter(iter->value());
  108|      0|  }
  109|      0|  delete iter;
  110|      0|  delete meta;
  111|      0|}
  112|       |
  113|      0|void Table::ReadFilter(const Slice& filter_handle_value) {
  114|      0|  Slice v = filter_handle_value;
  115|      0|  BlockHandle filter_handle;
  116|      0|  if (!filter_handle.DecodeFrom(&v).ok()) {
  117|      0|    return;
  118|      0|  }
  119|      0|
  120|      0|  // We might want to unify with ReadBlock() if we start
  121|      0|  // requiring checksum verification in Table::Open.
  122|      0|  ReadOptions opt;
  123|      0|  if (rep_->options.paranoid_checks) {
  124|      0|    opt.verify_checksums = true;
  125|      0|  }
  126|      0|  BlockContents block;
  127|      0|  if (!ReadBlock(rep_->file, opt, filter_handle, &block).ok()) {
  128|      0|    return;
  129|      0|  }
  130|      0|  if (block.heap_allocated) {
  131|      0|    rep_->filter_data = block.data.data();  // Will need to delete later
  132|      0|  }
  133|      0|  rep_->filter = new FilterBlockReader(rep_->options.filter_policy, block.data);
  134|      0|}
  135|       |
  136|      0|Table::~Table() { delete rep_; }
  137|       |
  138|      0|static void DeleteBlock(void* arg, void* ignored) {
  139|      0|  delete reinterpret_cast<Block*>(arg);
  140|      0|}
  141|       |
  142|      0|static void DeleteCachedBlock(const Slice& key, void* value) {
  143|      0|  Block* block = reinterpret_cast<Block*>(value);
  144|      0|  delete block;
  145|      0|}
  146|       |
  147|      0|static void ReleaseBlock(void* arg, void* h) {
  148|      0|  Cache* cache = reinterpret_cast<Cache*>(arg);
  149|      0|  Cache::Handle* handle = reinterpret_cast<Cache::Handle*>(h);
  150|      0|  cache->Release(handle);
  151|      0|}
  152|       |
  153|       |// Convert an index iterator value (i.e., an encoded BlockHandle)
  154|       |// into an iterator over the contents of the corresponding block.
  155|       |Iterator* Table::BlockReader(void* arg, const ReadOptions& options,
  156|      0|                             const Slice& index_value) {
  157|      0|  Table* table = reinterpret_cast<Table*>(arg);
  158|      0|  Cache* block_cache = table->rep_->options.block_cache;
  159|      0|  Block* block = nullptr;
  160|      0|  Cache::Handle* cache_handle = nullptr;
  161|      0|
  162|      0|  BlockHandle handle;
  163|      0|  Slice input = index_value;
  164|      0|  Status s = handle.DecodeFrom(&input);
  165|      0|  // We intentionally allow extra stuff in index_value so that we
  166|      0|  // can add more features in the future.
  167|      0|
  168|      0|  if (s.ok()) {
  169|      0|    BlockContents contents;
  170|      0|    if (block_cache != nullptr) {
  171|      0|      char cache_key_buffer[16];
  172|      0|      EncodeFixed64(cache_key_buffer, table->rep_->cache_id);
  173|      0|      EncodeFixed64(cache_key_buffer + 8, handle.offset());
  174|      0|      Slice key(cache_key_buffer, sizeof(cache_key_buffer));
  175|      0|      cache_handle = block_cache->Lookup(key);
  176|      0|      if (cache_handle != nullptr) {
  177|      0|        block = reinterpret_cast<Block*>(block_cache->Value(cache_handle));
  178|      0|      } else {
  179|      0|        s = ReadBlock(table->rep_->file, options, handle, &contents);
  180|      0|        if (s.ok()) {
  181|      0|          block = new Block(contents);
  182|      0|          if (contents.cachable && options.fill_cache) {
  183|      0|            cache_handle = block_cache->Insert(key, block, block->size(),
  184|      0|                                               &DeleteCachedBlock);
  185|      0|          }
  186|      0|        }
  187|      0|      }
  188|      0|    } else {
  189|      0|      s = ReadBlock(table->rep_->file, options, handle, &contents);
  190|      0|      if (s.ok()) {
  191|      0|        block = new Block(contents);
  192|      0|      }
  193|      0|    }
  194|      0|  }
  195|      0|
  196|      0|  Iterator* iter;
  197|      0|  if (block != nullptr) {
  198|      0|    iter = block->NewIterator(table->rep_->options.comparator);
  199|      0|    if (cache_handle == nullptr) {
  200|      0|      iter->RegisterCleanup(&DeleteBlock, block, nullptr);
  201|      0|    } else {
  202|      0|      iter->RegisterCleanup(&ReleaseBlock, block_cache, cache_handle);
  203|      0|    }
  204|      0|  } else {
  205|      0|    iter = NewErrorIterator(s);
  206|      0|  }
  207|      0|  return iter;
  208|      0|}
  209|       |
  210|      0|Iterator* Table::NewIterator(const ReadOptions& options) const {
  211|      0|  return NewTwoLevelIterator(
  212|      0|      rep_->index_block->NewIterator(rep_->options.comparator),
  213|      0|      &Table::BlockReader, const_cast<Table*>(this), options);
  214|      0|}
  215|       |
  216|       |Status Table::InternalGet(const ReadOptions& options, const Slice& k, void* arg,
  217|       |                          void (*handle_result)(void*, const Slice&,
  218|      0|                                                const Slice&)) {
  219|      0|  Status s;
  220|      0|  Iterator* iiter = rep_->index_block->NewIterator(rep_->options.comparator);
  221|      0|  iiter->Seek(k);
  222|      0|  if (iiter->Valid()) {
  223|      0|    Slice handle_value = iiter->value();
  224|      0|    FilterBlockReader* filter = rep_->filter;
  225|      0|    BlockHandle handle;
  226|      0|    if (filter != nullptr && handle.DecodeFrom(&handle_value).ok() &&
  227|      0|        !filter->KeyMayMatch(handle.offset(), k)) {
  228|      0|      // Not found
  229|      0|    } else {
  230|      0|      Iterator* block_iter = BlockReader(this, options, iiter->value());
  231|      0|      block_iter->Seek(k);
  232|      0|      if (block_iter->Valid()) {
  233|      0|        (*handle_result)(arg, block_iter->key(), block_iter->value());
  234|      0|      }
  235|      0|      s = block_iter->status();
  236|      0|      delete block_iter;
  237|      0|    }
  238|      0|  }
  239|      0|  if (s.ok()) {
  240|      0|    s = iiter->status();
  241|      0|  }
  242|      0|  delete iiter;
  243|      0|  return s;
  244|      0|}
  245|       |
  246|      0|uint64_t Table::ApproximateOffsetOf(const Slice& key) const {
  247|      0|  Iterator* index_iter =
  248|      0|      rep_->index_block->NewIterator(rep_->options.comparator);
  249|      0|  index_iter->Seek(key);
  250|      0|  uint64_t result;
  251|      0|  if (index_iter->Valid()) {
  252|      0|    BlockHandle handle;
  253|      0|    Slice input = index_iter->value();
  254|      0|    Status s = handle.DecodeFrom(&input);
  255|      0|    if (s.ok()) {
  256|      0|      result = handle.offset();
  257|      0|    } else {
  258|      0|      // Strange: we can't decode the block handle in the index block.
  259|      0|      // We'll just return the offset of the metaindex block, which is
  260|      0|      // close to the whole file size for this case.
  261|      0|      result = rep_->metaindex_handle.offset();
  262|      0|    }
  263|      0|  } else {
  264|      0|    // key is past the last key in the file.  Approximate the offset
  265|      0|    // by returning the offset of the metaindex block (which is
  266|      0|    // right near the end of the file).
  267|      0|    result = rep_->metaindex_handle.offset();
  268|      0|  }
  269|      0|  delete index_iter;
  270|      0|  return result;
  271|      0|}
  272|       |
  273|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/table_builder.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "leveldb/table_builder.h"
    6|       |
    7|       |#include <assert.h>
    8|       |
    9|       |#include "leveldb/comparator.h"
   10|       |#include "leveldb/env.h"
   11|       |#include "leveldb/filter_policy.h"
   12|       |#include "leveldb/options.h"
   13|       |#include "table/block_builder.h"
   14|       |#include "table/filter_block.h"
   15|       |#include "table/format.h"
   16|       |#include "util/coding.h"
   17|       |#include "util/crc32c.h"
   18|       |
   19|       |namespace leveldb {
   20|       |
   21|       |struct TableBuilder::Rep {
   22|       |  Rep(const Options& opt, WritableFile* f)
   23|       |      : options(opt),
   24|       |        index_block_options(opt),
   25|       |        file(f),
   26|       |        offset(0),
   27|       |        data_block(&options),
   28|       |        index_block(&index_block_options),
   29|       |        num_entries(0),
   30|       |        closed(false),
   31|       |        filter_block(opt.filter_policy == nullptr
   32|       |                         ? nullptr
   33|       |                         : new FilterBlockBuilder(opt.filter_policy)),
   34|      0|        pending_index_entry(false) {
   35|      0|    index_block_options.block_restart_interval = 1;
   36|      0|  }
   37|       |
   38|       |  Options options;
   39|       |  Options index_block_options;
   40|       |  WritableFile* file;
   41|       |  uint64_t offset;
   42|       |  Status status;
   43|       |  BlockBuilder data_block;
   44|       |  BlockBuilder index_block;
   45|       |  std::string last_key;
   46|       |  int64_t num_entries;
   47|       |  bool closed;  // Either Finish() or Abandon() has been called.
   48|       |  FilterBlockBuilder* filter_block;
   49|       |
   50|       |  // We do not emit the index entry for a block until we have seen the
   51|       |  // first key for the next data block.  This allows us to use shorter
   52|       |  // keys in the index block.  For example, consider a block boundary
   53|       |  // between the keys "the quick brown fox" and "the who".  We can use
   54|       |  // "the r" as the key for the index block entry since it is >= all
   55|       |  // entries in the first block and < all entries in subsequent
   56|       |  // blocks.
   57|       |  //
   58|       |  // Invariant: r->pending_index_entry is true only if data_block is empty.
   59|       |  bool pending_index_entry;
   60|       |  BlockHandle pending_handle;  // Handle to add to index block
   61|       |
   62|       |  std::string compressed_output;
   63|       |};
   64|       |
   65|       |TableBuilder::TableBuilder(const Options& options, WritableFile* file)
   66|      0|    : rep_(new Rep(options, file)) {
   67|      0|  if (rep_->filter_block != nullptr) {
   68|      0|    rep_->filter_block->StartBlock(0);
   69|      0|  }
   70|      0|}
   71|       |
   72|      0|TableBuilder::~TableBuilder() {
   73|      0|  assert(rep_->closed);  // Catch errors where caller forgot to call Finish()
   74|      0|  delete rep_->filter_block;
   75|      0|  delete rep_;
   76|      0|}
   77|       |
   78|      0|Status TableBuilder::ChangeOptions(const Options& options) {
   79|      0|  // Note: if more fields are added to Options, update
   80|      0|  // this function to catch changes that should not be allowed to
   81|      0|  // change in the middle of building a Table.
   82|      0|  if (options.comparator != rep_->options.comparator) {
   83|      0|    return Status::InvalidArgument("changing comparator while building table");
   84|      0|  }
   85|      0|
   86|      0|  // Note that any live BlockBuilders point to rep_->options and therefore
   87|      0|  // will automatically pick up the updated options.
   88|      0|  rep_->options = options;
   89|      0|  rep_->index_block_options = options;
   90|      0|  rep_->index_block_options.block_restart_interval = 1;
   91|      0|  return Status::OK();
   92|      0|}
   93|       |
   94|      0|void TableBuilder::Add(const Slice& key, const Slice& value) {
   95|      0|  Rep* r = rep_;
   96|      0|  assert(!r->closed);
   97|      0|  if (!ok()) return;
   98|      0|  if (r->num_entries > 0) {
   99|      0|    assert(r->options.comparator->Compare(key, Slice(r->last_key)) > 0);
  100|      0|  }
  101|      0|
  102|      0|  if (r->pending_index_entry) {
  103|      0|    assert(r->data_block.empty());
  104|      0|    r->options.comparator->FindShortestSeparator(&r->last_key, key);
  105|      0|    std::string handle_encoding;
  106|      0|    r->pending_handle.EncodeTo(&handle_encoding);
  107|      0|    r->index_block.Add(r->last_key, Slice(handle_encoding));
  108|      0|    r->pending_index_entry = false;
  109|      0|  }
  110|      0|
  111|      0|  if (r->filter_block != nullptr) {
  112|      0|    r->filter_block->AddKey(key);
  113|      0|  }
  114|      0|
  115|      0|  r->last_key.assign(key.data(), key.size());
  116|      0|  r->num_entries++;
  117|      0|  r->data_block.Add(key, value);
  118|      0|
  119|      0|  const size_t estimated_block_size = r->data_block.CurrentSizeEstimate();
  120|      0|  if (estimated_block_size >= r->options.block_size) {
  121|      0|    Flush();
  122|      0|  }
  123|      0|}
  124|       |
  125|      0|void TableBuilder::Flush() {
  126|      0|  Rep* r = rep_;
  127|      0|  assert(!r->closed);
  128|      0|  if (!ok()) return;
  129|      0|  if (r->data_block.empty()) return;
  130|      0|  assert(!r->pending_index_entry);
  131|      0|  WriteBlock(&r->data_block, &r->pending_handle);
  132|      0|  if (ok()) {
  133|      0|    r->pending_index_entry = true;
  134|      0|    r->status = r->file->Flush();
  135|      0|  }
  136|      0|  if (r->filter_block != nullptr) {
  137|      0|    r->filter_block->StartBlock(r->offset);
  138|      0|  }
  139|      0|}
  140|       |
  141|      0|void TableBuilder::WriteBlock(BlockBuilder* block, BlockHandle* handle) {
  142|      0|  // File format contains a sequence of blocks where each block has:
  143|      0|  //    block_data: uint8[n]
  144|      0|  //    type: uint8
  145|      0|  //    crc: uint32
  146|      0|  assert(ok());
  147|      0|  Rep* r = rep_;
  148|      0|  Slice raw = block->Finish();
  149|      0|
  150|      0|  Slice block_contents;
  151|      0|  CompressionType type = r->options.compression;
  152|      0|  // TODO(postrelease): Support more compression options: zlib?
  153|      0|  switch (type) {
  154|      0|    case kNoCompression:
  155|      0|      block_contents = raw;
  156|      0|      break;
  157|      0|
  158|      0|    case kSnappyCompression: {
  159|      0|      std::string* compressed = &r->compressed_output;
  160|      0|      if (port::Snappy_Compress(raw.data(), raw.size(), compressed) &&
  161|      0|          compressed->size() < raw.size() - (raw.size() / 8u)) {
  162|      0|        block_contents = *compressed;
  163|      0|      } else {
  164|      0|        // Snappy not supported, or compressed less than 12.5%, so just
  165|      0|        // store uncompressed form
  166|      0|        block_contents = raw;
  167|      0|        type = kNoCompression;
  168|      0|      }
  169|      0|      break;
  170|      0|    }
  171|      0|  }
  172|      0|  WriteRawBlock(block_contents, type, handle);
  173|      0|  r->compressed_output.clear();
  174|      0|  block->Reset();
  175|      0|}
  176|       |
  177|       |void TableBuilder::WriteRawBlock(const Slice& block_contents,
  178|      0|                                 CompressionType type, BlockHandle* handle) {
  179|      0|  Rep* r = rep_;
  180|      0|  handle->set_offset(r->offset);
  181|      0|  handle->set_size(block_contents.size());
  182|      0|  r->status = r->file->Append(block_contents);
  183|      0|  if (r->status.ok()) {
  184|      0|    char trailer[kBlockTrailerSize];
  185|      0|    trailer[0] = type;
  186|      0|    uint32_t crc = crc32c::Value(block_contents.data(), block_contents.size());
  187|      0|    crc = crc32c::Extend(crc, trailer, 1);  // Extend crc to cover block type
  188|      0|    EncodeFixed32(trailer + 1, crc32c::Mask(crc));
  189|      0|    r->status = r->file->Append(Slice(trailer, kBlockTrailerSize));
  190|      0|    if (r->status.ok()) {
  191|      0|      r->offset += block_contents.size() + kBlockTrailerSize;
  192|      0|    }
  193|      0|  }
  194|      0|}
  195|       |
  196|      0|Status TableBuilder::status() const { return rep_->status; }
  197|       |
  198|      0|Status TableBuilder::Finish() {
  199|      0|  Rep* r = rep_;
  200|      0|  Flush();
  201|      0|  assert(!r->closed);
  202|      0|  r->closed = true;
  203|      0|
  204|      0|  BlockHandle filter_block_handle, metaindex_block_handle, index_block_handle;
  205|      0|
  206|      0|  // Write filter block
  207|      0|  if (ok() && r->filter_block != nullptr) {
  208|      0|    WriteRawBlock(r->filter_block->Finish(), kNoCompression,
  209|      0|                  &filter_block_handle);
  210|      0|  }
  211|      0|
  212|      0|  // Write metaindex block
  213|      0|  if (ok()) {
  214|      0|    BlockBuilder meta_index_block(&r->options);
  215|      0|    if (r->filter_block != nullptr) {
  216|      0|      // Add mapping from "filter.Name" to location of filter data
  217|      0|      std::string key = "filter.";
  218|      0|      key.append(r->options.filter_policy->Name());
  219|      0|      std::string handle_encoding;
  220|      0|      filter_block_handle.EncodeTo(&handle_encoding);
  221|      0|      meta_index_block.Add(key, handle_encoding);
  222|      0|    }
  223|      0|
  224|      0|    // TODO(postrelease): Add stats and other meta blocks
  225|      0|    WriteBlock(&meta_index_block, &metaindex_block_handle);
  226|      0|  }
  227|      0|
  228|      0|  // Write index block
  229|      0|  if (ok()) {
  230|      0|    if (r->pending_index_entry) {
  231|      0|      r->options.comparator->FindShortSuccessor(&r->last_key);
  232|      0|      std::string handle_encoding;
  233|      0|      r->pending_handle.EncodeTo(&handle_encoding);
  234|      0|      r->index_block.Add(r->last_key, Slice(handle_encoding));
  235|      0|      r->pending_index_entry = false;
  236|      0|    }
  237|      0|    WriteBlock(&r->index_block, &index_block_handle);
  238|      0|  }
  239|      0|
  240|      0|  // Write footer
  241|      0|  if (ok()) {
  242|      0|    Footer footer;
  243|      0|    footer.set_metaindex_handle(metaindex_block_handle);
  244|      0|    footer.set_index_handle(index_block_handle);
  245|      0|    std::string footer_encoding;
  246|      0|    footer.EncodeTo(&footer_encoding);
  247|      0|    r->status = r->file->Append(footer_encoding);
  248|      0|    if (r->status.ok()) {
  249|      0|      r->offset += footer_encoding.size();
  250|      0|    }
  251|      0|  }
  252|      0|  return r->status;
  253|      0|}
  254|       |
  255|      0|void TableBuilder::Abandon() {
  256|      0|  Rep* r = rep_;
  257|      0|  assert(!r->closed);
  258|      0|  r->closed = true;
  259|      0|}
  260|       |
  261|      0|uint64_t TableBuilder::NumEntries() const { return rep_->num_entries; }
  262|       |
  263|      0|uint64_t TableBuilder::FileSize() const { return rep_->offset; }
  264|       |
  265|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/table/two_level_iterator.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "table/two_level_iterator.h"
    6|       |
    7|       |#include "leveldb/table.h"
    8|       |#include "table/block.h"
    9|       |#include "table/format.h"
   10|       |#include "table/iterator_wrapper.h"
   11|       |
   12|       |namespace leveldb {
   13|       |
   14|       |namespace {
   15|       |
   16|       |typedef Iterator* (*BlockFunction)(void*, const ReadOptions&, const Slice&);
   17|       |
   18|       |class TwoLevelIterator : public Iterator {
   19|       | public:
   20|       |  TwoLevelIterator(Iterator* index_iter, BlockFunction block_function,
   21|       |                   void* arg, const ReadOptions& options);
   22|       |
   23|       |  virtual ~TwoLevelIterator();
   24|       |
   25|       |  virtual void Seek(const Slice& target);
   26|       |  virtual void SeekToFirst();
   27|       |  virtual void SeekToLast();
   28|       |  virtual void Next();
   29|       |  virtual void Prev();
   30|       |
   31|      0|  virtual bool Valid() const { return data_iter_.Valid(); }
   32|      0|  virtual Slice key() const {
   33|      0|    assert(Valid());
   34|      0|    return data_iter_.key();
   35|      0|  }
   36|      0|  virtual Slice value() const {
   37|      0|    assert(Valid());
   38|      0|    return data_iter_.value();
   39|      0|  }
   40|      0|  virtual Status status() const {
   41|      0|    // It'd be nice if status() returned a const Status& instead of a Status
   42|      0|    if (!index_iter_.status().ok()) {
   43|      0|      return index_iter_.status();
   44|      0|    } else if (data_iter_.iter() != nullptr && !data_iter_.status().ok()) {
   45|      0|      return data_iter_.status();
   46|      0|    } else {
   47|      0|      return status_;
   48|      0|    }
   49|      0|  }
   50|       |
   51|       | private:
   52|      0|  void SaveError(const Status& s) {
   53|      0|    if (status_.ok() && !s.ok()) status_ = s;
   54|      0|  }
   55|       |  void SkipEmptyDataBlocksForward();
   56|       |  void SkipEmptyDataBlocksBackward();
   57|       |  void SetDataIterator(Iterator* data_iter);
   58|       |  void InitDataBlock();
   59|       |
   60|       |  BlockFunction block_function_;
   61|       |  void* arg_;
   62|       |  const ReadOptions options_;
   63|       |  Status status_;
   64|       |  IteratorWrapper index_iter_;
   65|       |  IteratorWrapper data_iter_;  // May be nullptr
   66|       |  // If data_iter_ is non-null, then "data_block_handle_" holds the
   67|       |  // "index_value" passed to block_function_ to create the data_iter_.
   68|       |  std::string data_block_handle_;
   69|       |};
   70|       |
   71|       |TwoLevelIterator::TwoLevelIterator(Iterator* index_iter,
   72|       |                                   BlockFunction block_function, void* arg,
   73|       |                                   const ReadOptions& options)
   74|       |    : block_function_(block_function),
   75|       |      arg_(arg),
   76|       |      options_(options),
   77|       |      index_iter_(index_iter),
   78|      0|      data_iter_(nullptr) {}
   79|       |
   80|      0|TwoLevelIterator::~TwoLevelIterator() {}
   81|       |
   82|      0|void TwoLevelIterator::Seek(const Slice& target) {
   83|      0|  index_iter_.Seek(target);
   84|      0|  InitDataBlock();
   85|      0|  if (data_iter_.iter() != nullptr) data_iter_.Seek(target);
   86|      0|  SkipEmptyDataBlocksForward();
   87|      0|}
   88|       |
   89|      0|void TwoLevelIterator::SeekToFirst() {
   90|      0|  index_iter_.SeekToFirst();
   91|      0|  InitDataBlock();
   92|      0|  if (data_iter_.iter() != nullptr) data_iter_.SeekToFirst();
   93|      0|  SkipEmptyDataBlocksForward();
   94|      0|}
   95|       |
   96|      0|void TwoLevelIterator::SeekToLast() {
   97|      0|  index_iter_.SeekToLast();
   98|      0|  InitDataBlock();
   99|      0|  if (data_iter_.iter() != nullptr) data_iter_.SeekToLast();
  100|      0|  SkipEmptyDataBlocksBackward();
  101|      0|}
  102|       |
  103|      0|void TwoLevelIterator::Next() {
  104|      0|  assert(Valid());
  105|      0|  data_iter_.Next();
  106|      0|  SkipEmptyDataBlocksForward();
  107|      0|}
  108|       |
  109|      0|void TwoLevelIterator::Prev() {
  110|      0|  assert(Valid());
  111|      0|  data_iter_.Prev();
  112|      0|  SkipEmptyDataBlocksBackward();
  113|      0|}
  114|       |
  115|      0|void TwoLevelIterator::SkipEmptyDataBlocksForward() {
  116|      0|  while (data_iter_.iter() == nullptr || !data_iter_.Valid()) {
  117|      0|    // Move to next block
  118|      0|    if (!index_iter_.Valid()) {
  119|      0|      SetDataIterator(nullptr);
  120|      0|      return;
  121|      0|    }
  122|      0|    index_iter_.Next();
  123|      0|    InitDataBlock();
  124|      0|    if (data_iter_.iter() != nullptr) data_iter_.SeekToFirst();
  125|      0|  }
  126|      0|}
  127|       |
  128|      0|void TwoLevelIterator::SkipEmptyDataBlocksBackward() {
  129|      0|  while (data_iter_.iter() == nullptr || !data_iter_.Valid()) {
  130|      0|    // Move to next block
  131|      0|    if (!index_iter_.Valid()) {
  132|      0|      SetDataIterator(nullptr);
  133|      0|      return;
  134|      0|    }
  135|      0|    index_iter_.Prev();
  136|      0|    InitDataBlock();
  137|      0|    if (data_iter_.iter() != nullptr) data_iter_.SeekToLast();
  138|      0|  }
  139|      0|}
  140|       |
  141|      0|void TwoLevelIterator::SetDataIterator(Iterator* data_iter) {
  142|      0|  if (data_iter_.iter() != nullptr) SaveError(data_iter_.status());
  143|      0|  data_iter_.Set(data_iter);
  144|      0|}
  145|       |
  146|      0|void TwoLevelIterator::InitDataBlock() {
  147|      0|  if (!index_iter_.Valid()) {
  148|      0|    SetDataIterator(nullptr);
  149|      0|  } else {
  150|      0|    Slice handle = index_iter_.value();
  151|      0|    if (data_iter_.iter() != nullptr &&
  152|      0|        handle.compare(data_block_handle_) == 0) {
  153|      0|      // data_iter_ is already constructed with this iterator, so
  154|      0|      // no need to change anything
  155|      0|    } else {
  156|      0|      Iterator* iter = (*block_function_)(arg_, options_, handle);
  157|      0|      data_block_handle_.assign(handle.data(), handle.size());
  158|      0|      SetDataIterator(iter);
  159|      0|    }
  160|      0|  }
  161|      0|}
  162|       |
  163|       |}  // namespace
  164|       |
  165|       |Iterator* NewTwoLevelIterator(Iterator* index_iter,
  166|       |                              BlockFunction block_function, void* arg,
  167|      0|                              const ReadOptions& options) {
  168|      0|  return new TwoLevelIterator(index_iter, block_function, arg, options);
  169|      0|}
  170|       |
  171|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/arena.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "util/arena.h"
    6|       |
    7|       |namespace leveldb {
    8|       |
    9|       |static const int kBlockSize = 4096;
   10|       |
   11|       |Arena::Arena()
   12|      0|    : alloc_ptr_(nullptr), alloc_bytes_remaining_(0), memory_usage_(0) {}
   13|       |
   14|      0|Arena::~Arena() {
   15|      0|  for (size_t i = 0; i < blocks_.size(); i++) {
   16|      0|    delete[] blocks_[i];
   17|      0|  }
   18|      0|}
   19|       |
   20|      0|char* Arena::AllocateFallback(size_t bytes) {
   21|      0|  if (bytes > kBlockSize / 4) {
   22|      0|    // Object is more than a quarter of our block size.  Allocate it separately
   23|      0|    // to avoid wasting too much space in leftover bytes.
   24|      0|    char* result = AllocateNewBlock(bytes);
   25|      0|    return result;
   26|      0|  }
   27|      0|
   28|      0|  // We waste the remaining space in the current block.
   29|      0|  alloc_ptr_ = AllocateNewBlock(kBlockSize);
   30|      0|  alloc_bytes_remaining_ = kBlockSize;
   31|      0|
   32|      0|  char* result = alloc_ptr_;
   33|      0|  alloc_ptr_ += bytes;
   34|      0|  alloc_bytes_remaining_ -= bytes;
   35|      0|  return result;
   36|      0|}
   37|       |
   38|      0|char* Arena::AllocateAligned(size_t bytes) {
   39|      0|  const int align = (sizeof(void*) > 8) ? sizeof(void*) : 8;
   40|      0|  static_assert((align & (align - 1)) == 0,
   41|      0|                "Pointer size should be a power of 2");
   42|      0|  size_t current_mod = reinterpret_cast<uintptr_t>(alloc_ptr_) & (align - 1);
   43|      0|  size_t slop = (current_mod == 0 ? 0 : align - current_mod);
   44|      0|  size_t needed = bytes + slop;
   45|      0|  char* result;
   46|      0|  if (needed <= alloc_bytes_remaining_) {
   47|      0|    result = alloc_ptr_ + slop;
   48|      0|    alloc_ptr_ += needed;
   49|      0|    alloc_bytes_remaining_ -= needed;
   50|      0|  } else {
   51|      0|    // AllocateFallback always returned aligned memory
   52|      0|    result = AllocateFallback(bytes);
   53|      0|  }
   54|      0|  assert((reinterpret_cast<uintptr_t>(result) & (align - 1)) == 0);
   55|      0|  return result;
   56|      0|}
   57|       |
   58|      0|char* Arena::AllocateNewBlock(size_t block_bytes) {
   59|      0|  char* result = new char[block_bytes];
   60|      0|  blocks_.push_back(result);
   61|      0|  memory_usage_.fetch_add(block_bytes + sizeof(char*),
   62|      0|                          std::memory_order_relaxed);
   63|      0|  return result;
   64|      0|}
   65|       |
   66|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/arena.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_UTIL_ARENA_H_
    6|       |#define STORAGE_LEVELDB_UTIL_ARENA_H_
    7|       |
    8|       |#include <atomic>
    9|       |#include <cassert>
   10|       |#include <cstddef>
   11|       |#include <cstdint>
   12|       |#include <vector>
   13|       |
   14|       |namespace leveldb {
   15|       |
   16|       |class Arena {
   17|       | public:
   18|       |  Arena();
   19|       |
   20|       |  Arena(const Arena&) = delete;
   21|       |  Arena& operator=(const Arena&) = delete;
   22|       |
   23|       |  ~Arena();
   24|       |
   25|       |  // Return a pointer to a newly allocated memory block of "bytes" bytes.
   26|       |  char* Allocate(size_t bytes);
   27|       |
   28|       |  // Allocate memory with the normal alignment guarantees provided by malloc.
   29|       |  char* AllocateAligned(size_t bytes);
   30|       |
   31|       |  // Returns an estimate of the total memory usage of data allocated
   32|       |  // by the arena.
   33|      0|  size_t MemoryUsage() const {
   34|      0|    return memory_usage_.load(std::memory_order_relaxed);
   35|      0|  }
   36|       |
   37|       | private:
   38|       |  char* AllocateFallback(size_t bytes);
   39|       |  char* AllocateNewBlock(size_t block_bytes);
   40|       |
   41|       |  // Allocation state
   42|       |  char* alloc_ptr_;
   43|       |  size_t alloc_bytes_remaining_;
   44|       |
   45|       |  // Array of new[] allocated memory blocks
   46|       |  std::vector<char*> blocks_;
   47|       |
   48|       |  // Total memory usage of the arena.
   49|       |  //
   50|       |  // TODO(costan): This member is accessed via atomics, but the others are
   51|       |  //               accessed without any locking. Is this OK?
   52|       |  std::atomic<size_t> memory_usage_;
   53|       |};
   54|       |
   55|      0|inline char* Arena::Allocate(size_t bytes) {
   56|      0|  // The semantics of what to return are a bit messy if we allow
   57|      0|  // 0-byte allocations, so we disallow them here (we don't need
   58|      0|  // them for our internal use).
   59|      0|  assert(bytes > 0);
   60|      0|  if (bytes <= alloc_bytes_remaining_) {
   61|      0|    char* result = alloc_ptr_;
   62|      0|    alloc_ptr_ += bytes;
   63|      0|    alloc_bytes_remaining_ -= bytes;
   64|      0|    return result;
   65|      0|  }
   66|      0|  return AllocateFallback(bytes);
   67|      0|}
   68|       |
   69|       |}  // namespace leveldb
   70|       |
   71|       |#endif  // STORAGE_LEVELDB_UTIL_ARENA_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/bloom.cc:
    1|       |// Copyright (c) 2012 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "leveldb/filter_policy.h"
    6|       |
    7|       |#include "leveldb/slice.h"
    8|       |#include "util/hash.h"
    9|       |
   10|       |namespace leveldb {
   11|       |
   12|       |namespace {
   13|      0|static uint32_t BloomHash(const Slice& key) {
   14|      0|  return Hash(key.data(), key.size(), 0xbc9f1d34);
   15|      0|}
   16|       |
   17|       |class BloomFilterPolicy : public FilterPolicy {
   18|       | public:
   19|      0|  explicit BloomFilterPolicy(int bits_per_key) : bits_per_key_(bits_per_key) {
   20|      0|    // We intentionally round down to reduce probing cost a little bit
   21|      0|    k_ = static_cast<size_t>(bits_per_key * 0.69);  // 0.69 =~ ln(2)
   22|      0|    if (k_ < 1) k_ = 1;
   23|      0|    if (k_ > 30) k_ = 30;
   24|      0|  }
   25|       |
   26|      0|  virtual const char* Name() const { return "leveldb.BuiltinBloomFilter2"; }
   27|       |
   28|      0|  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const {
   29|      0|    // Compute bloom filter size (in both bits and bytes)
   30|      0|    size_t bits = n * bits_per_key_;
   31|      0|
   32|      0|    // For small n, we can see a very high false positive rate.  Fix it
   33|      0|    // by enforcing a minimum bloom filter length.
   34|      0|    if (bits < 64) bits = 64;
   35|      0|
   36|      0|    size_t bytes = (bits + 7) / 8;
   37|      0|    bits = bytes * 8;
   38|      0|
   39|      0|    const size_t init_size = dst->size();
   40|      0|    dst->resize(init_size + bytes, 0);
   41|      0|    dst->push_back(static_cast<char>(k_));  // Remember # of probes in filter
   42|      0|    char* array = &(*dst)[init_size];
   43|      0|    for (int i = 0; i < n; i++) {
   44|      0|      // Use double-hashing to generate a sequence of hash values.
   45|      0|      // See analysis in [Kirsch,Mitzenmacher 2006].
   46|      0|      uint32_t h = BloomHash(keys[i]);
   47|      0|      const uint32_t delta = (h >> 17) | (h << 15);  // Rotate right 17 bits
   48|      0|      for (size_t j = 0; j < k_; j++) {
   49|      0|        const uint32_t bitpos = h % bits;
   50|      0|        array[bitpos / 8] |= (1 << (bitpos % 8));
   51|      0|        h += delta;
   52|      0|      }
   53|      0|    }
   54|      0|  }
   55|       |
   56|      0|  virtual bool KeyMayMatch(const Slice& key, const Slice& bloom_filter) const {
   57|      0|    const size_t len = bloom_filter.size();
   58|      0|    if (len < 2) return false;
   59|      0|
   60|      0|    const char* array = bloom_filter.data();
   61|      0|    const size_t bits = (len - 1) * 8;
   62|      0|
   63|      0|    // Use the encoded k so that we can read filters generated by
   64|      0|    // bloom filters created using different parameters.
   65|      0|    const size_t k = array[len - 1];
   66|      0|    if (k > 30) {
   67|      0|      // Reserved for potentially new encodings for short bloom filters.
   68|      0|      // Consider it a match.
   69|      0|      return true;
   70|      0|    }
   71|      0|
   72|      0|    uint32_t h = BloomHash(key);
   73|      0|    const uint32_t delta = (h >> 17) | (h << 15);  // Rotate right 17 bits
   74|      0|    for (size_t j = 0; j < k; j++) {
   75|      0|      const uint32_t bitpos = h % bits;
   76|      0|      if ((array[bitpos / 8] & (1 << (bitpos % 8))) == 0) return false;
   77|      0|      h += delta;
   78|      0|    }
   79|      0|    return true;
   80|      0|  }
   81|       |
   82|       | private:
   83|       |  size_t bits_per_key_;
   84|       |  size_t k_;
   85|       |};
   86|       |}  // namespace
   87|       |
   88|      0|const FilterPolicy* NewBloomFilterPolicy(int bits_per_key) {
   89|      0|  return new BloomFilterPolicy(bits_per_key);
   90|      0|}
   91|       |
   92|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/cache.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include <assert.h>
    6|       |#include <stdio.h>
    7|       |#include <stdlib.h>
    8|       |
    9|       |#include "leveldb/cache.h"
   10|       |#include "port/port.h"
   11|       |#include "port/thread_annotations.h"
   12|       |#include "util/hash.h"
   13|       |#include "util/mutexlock.h"
   14|       |
   15|       |namespace leveldb {
   16|       |
   17|      0|Cache::~Cache() {}
   18|       |
   19|       |namespace {
   20|       |
   21|       |// LRU cache implementation
   22|       |//
   23|       |// Cache entries have an "in_cache" boolean indicating whether the cache has a
   24|       |// reference on the entry.  The only ways that this can become false without the
   25|       |// entry being passed to its "deleter" are via Erase(), via Insert() when
   26|       |// an element with a duplicate key is inserted, or on destruction of the cache.
   27|       |//
   28|       |// The cache keeps two linked lists of items in the cache.  All items in the
   29|       |// cache are in one list or the other, and never both.  Items still referenced
   30|       |// by clients but erased from the cache are in neither list.  The lists are:
   31|       |// - in-use:  contains the items currently referenced by clients, in no
   32|       |//   particular order.  (This list is used for invariant checking.  If we
   33|       |//   removed the check, elements that would otherwise be on this list could be
   34|       |//   left as disconnected singleton lists.)
   35|       |// - LRU:  contains the items not currently referenced by clients, in LRU order
   36|       |// Elements are moved between these lists by the Ref() and Unref() methods,
   37|       |// when they detect an element in the cache acquiring or losing its only
   38|       |// external reference.
   39|       |
   40|       |// An entry is a variable length heap-allocated structure.  Entries
   41|       |// are kept in a circular doubly linked list ordered by access time.
   42|       |struct LRUHandle {
   43|       |  void* value;
   44|       |  void (*deleter)(const Slice&, void* value);
   45|       |  LRUHandle* next_hash;
   46|       |  LRUHandle* next;
   47|       |  LRUHandle* prev;
   48|       |  size_t charge;  // TODO(opt): Only allow uint32_t?
   49|       |  size_t key_length;
   50|       |  bool in_cache;     // Whether entry is in the cache.
   51|       |  uint32_t refs;     // References, including cache reference, if present.
   52|       |  uint32_t hash;     // Hash of key(); used for fast sharding and comparisons
   53|       |  char key_data[1];  // Beginning of key
   54|       |
   55|      0|  Slice key() const {
   56|      0|    // next_ is only equal to this if the LRU handle is the list head of an
   57|      0|    // empty list. List heads never have meaningful keys.
   58|      0|    assert(next != this);
   59|      0|
   60|      0|    return Slice(key_data, key_length);
   61|      0|  }
   62|       |};
   63|       |
   64|       |// We provide our own simple hash table since it removes a whole bunch
   65|       |// of porting hacks and is also faster than some of the built-in hash
   66|       |// table implementations in some of the compiler/runtime combinations
   67|       |// we have tested.  E.g., readrandom speeds up by ~5% over the g++
   68|       |// 4.4.3's builtin hashtable.
   69|       |class HandleTable {
   70|       | public:
   71|      0|  HandleTable() : length_(0), elems_(0), list_(nullptr) { Resize(); }
   72|      0|  ~HandleTable() { delete[] list_; }
   73|       |
   74|      0|  LRUHandle* Lookup(const Slice& key, uint32_t hash) {
   75|      0|    return *FindPointer(key, hash);
   76|      0|  }
   77|       |
   78|      0|  LRUHandle* Insert(LRUHandle* h) {
   79|      0|    LRUHandle** ptr = FindPointer(h->key(), h->hash);
   80|      0|    LRUHandle* old = *ptr;
   81|      0|    h->next_hash = (old == nullptr ? nullptr : old->next_hash);
   82|      0|    *ptr = h;
   83|      0|    if (old == nullptr) {
   84|      0|      ++elems_;
   85|      0|      if (elems_ > length_) {
   86|      0|        // Since each cache entry is fairly large, we aim for a small
   87|      0|        // average linked list length (<= 1).
   88|      0|        Resize();
   89|      0|      }
   90|      0|    }
   91|      0|    return old;
   92|      0|  }
   93|       |
   94|      0|  LRUHandle* Remove(const Slice& key, uint32_t hash) {
   95|      0|    LRUHandle** ptr = FindPointer(key, hash);
   96|      0|    LRUHandle* result = *ptr;
   97|      0|    if (result != nullptr) {
   98|      0|      *ptr = result->next_hash;
   99|      0|      --elems_;
  100|      0|    }
  101|      0|    return result;
  102|      0|  }
  103|       |
  104|       | private:
  105|       |  // The table consists of an array of buckets where each bucket is
  106|       |  // a linked list of cache entries that hash into the bucket.
  107|       |  uint32_t length_;
  108|       |  uint32_t elems_;
  109|       |  LRUHandle** list_;
  110|       |
  111|       |  // Return a pointer to slot that points to a cache entry that
  112|       |  // matches key/hash.  If there is no such cache entry, return a
  113|       |  // pointer to the trailing slot in the corresponding linked list.
  114|      0|  LRUHandle** FindPointer(const Slice& key, uint32_t hash) {
  115|      0|    LRUHandle** ptr = &list_[hash & (length_ - 1)];
  116|      0|    while (*ptr != nullptr && ((*ptr)->hash != hash || key != (*ptr)->key())) {
  117|      0|      ptr = &(*ptr)->next_hash;
  118|      0|    }
  119|      0|    return ptr;
  120|      0|  }
  121|       |
  122|      0|  void Resize() {
  123|      0|    uint32_t new_length = 4;
  124|      0|    while (new_length < elems_) {
  125|      0|      new_length *= 2;
  126|      0|    }
  127|      0|    LRUHandle** new_list = new LRUHandle*[new_length];
  128|      0|    memset(new_list, 0, sizeof(new_list[0]) * new_length);
  129|      0|    uint32_t count = 0;
  130|      0|    for (uint32_t i = 0; i < length_; i++) {
  131|      0|      LRUHandle* h = list_[i];
  132|      0|      while (h != nullptr) {
  133|      0|        LRUHandle* next = h->next_hash;
  134|      0|        uint32_t hash = h->hash;
  135|      0|        LRUHandle** ptr = &new_list[hash & (new_length - 1)];
  136|      0|        h->next_hash = *ptr;
  137|      0|        *ptr = h;
  138|      0|        h = next;
  139|      0|        count++;
  140|      0|      }
  141|      0|    }
  142|      0|    assert(elems_ == count);
  143|      0|    delete[] list_;
  144|      0|    list_ = new_list;
  145|      0|    length_ = new_length;
  146|      0|  }
  147|       |};
  148|       |
  149|       |// A single shard of sharded cache.
  150|       |class LRUCache {
  151|       | public:
  152|       |  LRUCache();
  153|       |  ~LRUCache();
  154|       |
  155|       |  // Separate from constructor so caller can easily make an array of LRUCache
  156|      0|  void SetCapacity(size_t capacity) { capacity_ = capacity; }
  157|       |
  158|       |  // Like Cache methods, but with an extra "hash" parameter.
  159|       |  Cache::Handle* Insert(const Slice& key, uint32_t hash, void* value,
  160|       |                        size_t charge,
  161|       |                        void (*deleter)(const Slice& key, void* value));
  162|       |  Cache::Handle* Lookup(const Slice& key, uint32_t hash);
  163|       |  void Release(Cache::Handle* handle);
  164|       |  void Erase(const Slice& key, uint32_t hash);
  165|       |  void Prune();
  166|      0|  size_t TotalCharge() const {
  167|      0|    MutexLock l(&mutex_);
  168|      0|    return usage_;
  169|      0|  }
  170|       |
  171|       | private:
  172|       |  void LRU_Remove(LRUHandle* e);
  173|       |  void LRU_Append(LRUHandle* list, LRUHandle* e);
  174|       |  void Ref(LRUHandle* e);
  175|       |  void Unref(LRUHandle* e);
  176|       |  bool FinishErase(LRUHandle* e) EXCLUSIVE_LOCKS_REQUIRED(mutex_);
  177|       |
  178|       |  // Initialized before use.
  179|       |  size_t capacity_;
  180|       |
  181|       |  // mutex_ protects the following state.
  182|       |  mutable port::Mutex mutex_;
  183|       |  size_t usage_ GUARDED_BY(mutex_);
  184|       |
  185|       |  // Dummy head of LRU list.
  186|       |  // lru.prev is newest entry, lru.next is oldest entry.
  187|       |  // Entries have refs==1 and in_cache==true.
  188|       |  LRUHandle lru_ GUARDED_BY(mutex_);
  189|       |
  190|       |  // Dummy head of in-use list.
  191|       |  // Entries are in use by clients, and have refs >= 2 and in_cache==true.
  192|       |  LRUHandle in_use_ GUARDED_BY(mutex_);
  193|       |
  194|       |  HandleTable table_ GUARDED_BY(mutex_);
  195|       |};
  196|       |
  197|      0|LRUCache::LRUCache() : capacity_(0), usage_(0) {
  198|      0|  // Make empty circular linked lists.
  199|      0|  lru_.next = &lru_;
  200|      0|  lru_.prev = &lru_;
  201|      0|  in_use_.next = &in_use_;
  202|      0|  in_use_.prev = &in_use_;
  203|      0|}
  204|       |
  205|      0|LRUCache::~LRUCache() {
  206|      0|  assert(in_use_.next == &in_use_);  // Error if caller has an unreleased handle
  207|      0|  for (LRUHandle* e = lru_.next; e != &lru_;) {
  208|      0|    LRUHandle* next = e->next;
  209|      0|    assert(e->in_cache);
  210|      0|    e->in_cache = false;
  211|      0|    assert(e->refs == 1);  // Invariant of lru_ list.
  212|      0|    Unref(e);
  213|      0|    e = next;
  214|      0|  }
  215|      0|}
  216|       |
  217|      0|void LRUCache::Ref(LRUHandle* e) {
  218|      0|  if (e->refs == 1 && e->in_cache) {  // If on lru_ list, move to in_use_ list.
  219|      0|    LRU_Remove(e);
  220|      0|    LRU_Append(&in_use_, e);
  221|      0|  }
  222|      0|  e->refs++;
  223|      0|}
  224|       |
  225|      0|void LRUCache::Unref(LRUHandle* e) {
  226|      0|  assert(e->refs > 0);
  227|      0|  e->refs--;
  228|      0|  if (e->refs == 0) {  // Deallocate.
  229|      0|    assert(!e->in_cache);
  230|      0|    (*e->deleter)(e->key(), e->value);
  231|      0|    free(e);
  232|      0|  } else if (e->in_cache && e->refs == 1) {
  233|      0|    // No longer in use; move to lru_ list.
  234|      0|    LRU_Remove(e);
  235|      0|    LRU_Append(&lru_, e);
  236|      0|  }
  237|      0|}
  238|       |
  239|      0|void LRUCache::LRU_Remove(LRUHandle* e) {
  240|      0|  e->next->prev = e->prev;
  241|      0|  e->prev->next = e->next;
  242|      0|}
  243|       |
  244|      0|void LRUCache::LRU_Append(LRUHandle* list, LRUHandle* e) {
  245|      0|  // Make "e" newest entry by inserting just before *list
  246|      0|  e->next = list;
  247|      0|  e->prev = list->prev;
  248|      0|  e->prev->next = e;
  249|      0|  e->next->prev = e;
  250|      0|}
  251|       |
  252|      0|Cache::Handle* LRUCache::Lookup(const Slice& key, uint32_t hash) {
  253|      0|  MutexLock l(&mutex_);
  254|      0|  LRUHandle* e = table_.Lookup(key, hash);
  255|      0|  if (e != nullptr) {
  256|      0|    Ref(e);
  257|      0|  }
  258|      0|  return reinterpret_cast<Cache::Handle*>(e);
  259|      0|}
  260|       |
  261|      0|void LRUCache::Release(Cache::Handle* handle) {
  262|      0|  MutexLock l(&mutex_);
  263|      0|  Unref(reinterpret_cast<LRUHandle*>(handle));
  264|      0|}
  265|       |
  266|       |Cache::Handle* LRUCache::Insert(const Slice& key, uint32_t hash, void* value,
  267|       |                                size_t charge,
  268|       |                                void (*deleter)(const Slice& key,
  269|      0|                                                void* value)) {
  270|      0|  MutexLock l(&mutex_);
  271|      0|
  272|      0|  LRUHandle* e =
  273|      0|      reinterpret_cast<LRUHandle*>(malloc(sizeof(LRUHandle) - 1 + key.size()));
  274|      0|  e->value = value;
  275|      0|  e->deleter = deleter;
  276|      0|  e->charge = charge;
  277|      0|  e->key_length = key.size();
  278|      0|  e->hash = hash;
  279|      0|  e->in_cache = false;
  280|      0|  e->refs = 1;  // for the returned handle.
  281|      0|  memcpy(e->key_data, key.data(), key.size());
  282|      0|
  283|      0|  if (capacity_ > 0) {
  284|      0|    e->refs++;  // for the cache's reference.
  285|      0|    e->in_cache = true;
  286|      0|    LRU_Append(&in_use_, e);
  287|      0|    usage_ += charge;
  288|      0|    FinishErase(table_.Insert(e));
  289|      0|  } else {  // don't cache. (capacity_==0 is supported and turns off caching.)
  290|      0|    // next is read by key() in an assert, so it must be initialized
  291|      0|    e->next = nullptr;
  292|      0|  }
  293|      0|  while (usage_ > capacity_ && lru_.next != &lru_) {
  294|      0|    LRUHandle* old = lru_.next;
  295|      0|    assert(old->refs == 1);
  296|      0|    bool erased = FinishErase(table_.Remove(old->key(), old->hash));
  297|      0|    if (!erased) {  // to avoid unused variable when compiled NDEBUG
  298|      0|      assert(erased);
  299|      0|    }
  300|      0|  }
  301|      0|
  302|      0|  return reinterpret_cast<Cache::Handle*>(e);
  303|      0|}
  304|       |
  305|       |// If e != nullptr, finish removing *e from the cache; it has already been
  306|       |// removed from the hash table.  Return whether e != nullptr.
  307|      0|bool LRUCache::FinishErase(LRUHandle* e) {
  308|      0|  if (e != nullptr) {
  309|      0|    assert(e->in_cache);
  310|      0|    LRU_Remove(e);
  311|      0|    e->in_cache = false;
  312|      0|    usage_ -= e->charge;
  313|      0|    Unref(e);
  314|      0|  }
  315|      0|  return e != nullptr;
  316|      0|}
  317|       |
  318|      0|void LRUCache::Erase(const Slice& key, uint32_t hash) {
  319|      0|  MutexLock l(&mutex_);
  320|      0|  FinishErase(table_.Remove(key, hash));
  321|      0|}
  322|       |
  323|      0|void LRUCache::Prune() {
  324|      0|  MutexLock l(&mutex_);
  325|      0|  while (lru_.next != &lru_) {
  326|      0|    LRUHandle* e = lru_.next;
  327|      0|    assert(e->refs == 1);
  328|      0|    bool erased = FinishErase(table_.Remove(e->key(), e->hash));
  329|      0|    if (!erased) {  // to avoid unused variable when compiled NDEBUG
  330|      0|      assert(erased);
  331|      0|    }
  332|      0|  }
  333|      0|}
  334|       |
  335|       |static const int kNumShardBits = 4;
  336|       |static const int kNumShards = 1 << kNumShardBits;
  337|       |
  338|       |class ShardedLRUCache : public Cache {
  339|       | private:
  340|       |  LRUCache shard_[kNumShards];
  341|       |  port::Mutex id_mutex_;
  342|       |  uint64_t last_id_;
  343|       |
  344|      0|  static inline uint32_t HashSlice(const Slice& s) {
  345|      0|    return Hash(s.data(), s.size(), 0);
  346|      0|  }
  347|       |
  348|      0|  static uint32_t Shard(uint32_t hash) { return hash >> (32 - kNumShardBits); }
  349|       |
  350|       | public:
  351|      0|  explicit ShardedLRUCache(size_t capacity) : last_id_(0) {
  352|      0|    const size_t per_shard = (capacity + (kNumShards - 1)) / kNumShards;
  353|      0|    for (int s = 0; s < kNumShards; s++) {
  354|      0|      shard_[s].SetCapacity(per_shard);
  355|      0|    }
  356|      0|  }
  357|      0|  virtual ~ShardedLRUCache() {}
  358|       |  virtual Handle* Insert(const Slice& key, void* value, size_t charge,
  359|      0|                         void (*deleter)(const Slice& key, void* value)) {
  360|      0|    const uint32_t hash = HashSlice(key);
  361|      0|    return shard_[Shard(hash)].Insert(key, hash, value, charge, deleter);
  362|      0|  }
  363|      0|  virtual Handle* Lookup(const Slice& key) {
  364|      0|    const uint32_t hash = HashSlice(key);
  365|      0|    return shard_[Shard(hash)].Lookup(key, hash);
  366|      0|  }
  367|      0|  virtual void Release(Handle* handle) {
  368|      0|    LRUHandle* h = reinterpret_cast<LRUHandle*>(handle);
  369|      0|    shard_[Shard(h->hash)].Release(handle);
  370|      0|  }
  371|      0|  virtual void Erase(const Slice& key) {
  372|      0|    const uint32_t hash = HashSlice(key);
  373|      0|    shard_[Shard(hash)].Erase(key, hash);
  374|      0|  }
  375|      0|  virtual void* Value(Handle* handle) {
  376|      0|    return reinterpret_cast<LRUHandle*>(handle)->value;
  377|      0|  }
  378|      0|  virtual uint64_t NewId() {
  379|      0|    MutexLock l(&id_mutex_);
  380|      0|    return ++(last_id_);
  381|      0|  }
  382|      0|  virtual void Prune() {
  383|      0|    for (int s = 0; s < kNumShards; s++) {
  384|      0|      shard_[s].Prune();
  385|      0|    }
  386|      0|  }
  387|      0|  virtual size_t TotalCharge() const {
  388|      0|    size_t total = 0;
  389|      0|    for (int s = 0; s < kNumShards; s++) {
  390|      0|      total += shard_[s].TotalCharge();
  391|      0|    }
  392|      0|    return total;
  393|      0|  }
  394|       |};
  395|       |
  396|       |}  // end anonymous namespace
  397|       |
  398|      0|Cache* NewLRUCache(size_t capacity) { return new ShardedLRUCache(capacity); }
  399|       |
  400|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/coding.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "util/coding.h"
    6|       |
    7|       |namespace leveldb {
    8|       |
    9|      0|void EncodeFixed32(char* dst, uint32_t value) {
   10|      0|  if (port::kLittleEndian) {
   11|      0|    memcpy(dst, &value, sizeof(value));
   12|      0|  } else {
   13|      0|    dst[0] = value & 0xff;
   14|      0|    dst[1] = (value >> 8) & 0xff;
   15|      0|    dst[2] = (value >> 16) & 0xff;
   16|      0|    dst[3] = (value >> 24) & 0xff;
   17|      0|  }
   18|      0|}
   19|       |
   20|      0|void EncodeFixed64(char* dst, uint64_t value) {
   21|      0|  if (port::kLittleEndian) {
   22|      0|    memcpy(dst, &value, sizeof(value));
   23|      0|  } else {
   24|      0|    dst[0] = value & 0xff;
   25|      0|    dst[1] = (value >> 8) & 0xff;
   26|      0|    dst[2] = (value >> 16) & 0xff;
   27|      0|    dst[3] = (value >> 24) & 0xff;
   28|      0|    dst[4] = (value >> 32) & 0xff;
   29|      0|    dst[5] = (value >> 40) & 0xff;
   30|      0|    dst[6] = (value >> 48) & 0xff;
   31|      0|    dst[7] = (value >> 56) & 0xff;
   32|      0|  }
   33|      0|}
   34|       |
   35|      0|void PutFixed32(std::string* dst, uint32_t value) {
   36|      0|  char buf[sizeof(value)];
   37|      0|  EncodeFixed32(buf, value);
   38|      0|  dst->append(buf, sizeof(buf));
   39|      0|}
   40|       |
   41|      0|void PutFixed64(std::string* dst, uint64_t value) {
   42|      0|  char buf[sizeof(value)];
   43|      0|  EncodeFixed64(buf, value);
   44|      0|  dst->append(buf, sizeof(buf));
   45|      0|}
   46|       |
   47|      0|char* EncodeVarint32(char* dst, uint32_t v) {
   48|      0|  // Operate on characters as unsigneds
   49|      0|  unsigned char* ptr = reinterpret_cast<unsigned char*>(dst);
   50|      0|  static const int B = 128;
   51|      0|  if (v < (1 << 7)) {
   52|      0|    *(ptr++) = v;
   53|      0|  } else if (v < (1 << 14)) {
   54|      0|    *(ptr++) = v | B;
   55|      0|    *(ptr++) = v >> 7;
   56|      0|  } else if (v < (1 << 21)) {
   57|      0|    *(ptr++) = v | B;
   58|      0|    *(ptr++) = (v >> 7) | B;
   59|      0|    *(ptr++) = v >> 14;
   60|      0|  } else if (v < (1 << 28)) {
   61|      0|    *(ptr++) = v | B;
   62|      0|    *(ptr++) = (v >> 7) | B;
   63|      0|    *(ptr++) = (v >> 14) | B;
   64|      0|    *(ptr++) = v >> 21;
   65|      0|  } else {
   66|      0|    *(ptr++) = v | B;
   67|      0|    *(ptr++) = (v >> 7) | B;
   68|      0|    *(ptr++) = (v >> 14) | B;
   69|      0|    *(ptr++) = (v >> 21) | B;
   70|      0|    *(ptr++) = v >> 28;
   71|      0|  }
   72|      0|  return reinterpret_cast<char*>(ptr);
   73|      0|}
   74|       |
   75|      0|void PutVarint32(std::string* dst, uint32_t v) {
   76|      0|  char buf[5];
   77|      0|  char* ptr = EncodeVarint32(buf, v);
   78|      0|  dst->append(buf, ptr - buf);
   79|      0|}
   80|       |
   81|      0|char* EncodeVarint64(char* dst, uint64_t v) {
   82|      0|  static const int B = 128;
   83|      0|  unsigned char* ptr = reinterpret_cast<unsigned char*>(dst);
   84|      0|  while (v >= B) {
   85|      0|    *(ptr++) = v | B;
   86|      0|    v >>= 7;
   87|      0|  }
   88|      0|  *(ptr++) = static_cast<unsigned char>(v);
   89|      0|  return reinterpret_cast<char*>(ptr);
   90|      0|}
   91|       |
   92|      0|void PutVarint64(std::string* dst, uint64_t v) {
   93|      0|  char buf[10];
   94|      0|  char* ptr = EncodeVarint64(buf, v);
   95|      0|  dst->append(buf, ptr - buf);
   96|      0|}
   97|       |
   98|      0|void PutLengthPrefixedSlice(std::string* dst, const Slice& value) {
   99|      0|  PutVarint32(dst, value.size());
  100|      0|  dst->append(value.data(), value.size());
  101|      0|}
  102|       |
  103|      0|int VarintLength(uint64_t v) {
  104|      0|  int len = 1;
  105|      0|  while (v >= 128) {
  106|      0|    v >>= 7;
  107|      0|    len++;
  108|      0|  }
  109|      0|  return len;
  110|      0|}
  111|       |
  112|       |const char* GetVarint32PtrFallback(const char* p, const char* limit,
  113|      0|                                   uint32_t* value) {
  114|      0|  uint32_t result = 0;
  115|      0|  for (uint32_t shift = 0; shift <= 28 && p < limit; shift += 7) {
  116|      0|    uint32_t byte = *(reinterpret_cast<const unsigned char*>(p));
  117|      0|    p++;
  118|      0|    if (byte & 128) {
  119|      0|      // More bytes are present
  120|      0|      result |= ((byte & 127) << shift);
  121|      0|    } else {
  122|      0|      result |= (byte << shift);
  123|      0|      *value = result;
  124|      0|      return reinterpret_cast<const char*>(p);
  125|      0|    }
  126|      0|  }
  127|      0|  return nullptr;
  128|      0|}
  129|       |
  130|      0|bool GetVarint32(Slice* input, uint32_t* value) {
  131|      0|  const char* p = input->data();
  132|      0|  const char* limit = p + input->size();
  133|      0|  const char* q = GetVarint32Ptr(p, limit, value);
  134|      0|  if (q == nullptr) {
  135|      0|    return false;
  136|      0|  } else {
  137|      0|    *input = Slice(q, limit - q);
  138|      0|    return true;
  139|      0|  }
  140|      0|}
  141|       |
  142|      0|const char* GetVarint64Ptr(const char* p, const char* limit, uint64_t* value) {
  143|      0|  uint64_t result = 0;
  144|      0|  for (uint32_t shift = 0; shift <= 63 && p < limit; shift += 7) {
  145|      0|    uint64_t byte = *(reinterpret_cast<const unsigned char*>(p));
  146|      0|    p++;
  147|      0|    if (byte & 128) {
  148|      0|      // More bytes are present
  149|      0|      result |= ((byte & 127) << shift);
  150|      0|    } else {
  151|      0|      result |= (byte << shift);
  152|      0|      *value = result;
  153|      0|      return reinterpret_cast<const char*>(p);
  154|      0|    }
  155|      0|  }
  156|      0|  return nullptr;
  157|      0|}
  158|       |
  159|      0|bool GetVarint64(Slice* input, uint64_t* value) {
  160|      0|  const char* p = input->data();
  161|      0|  const char* limit = p + input->size();
  162|      0|  const char* q = GetVarint64Ptr(p, limit, value);
  163|      0|  if (q == nullptr) {
  164|      0|    return false;
  165|      0|  } else {
  166|      0|    *input = Slice(q, limit - q);
  167|      0|    return true;
  168|      0|  }
  169|      0|}
  170|       |
  171|       |const char* GetLengthPrefixedSlice(const char* p, const char* limit,
  172|      0|                                   Slice* result) {
  173|      0|  uint32_t len;
  174|      0|  p = GetVarint32Ptr(p, limit, &len);
  175|      0|  if (p == nullptr) return nullptr;
  176|      0|  if (p + len > limit) return nullptr;
  177|      0|  *result = Slice(p, len);
  178|      0|  return p + len;
  179|      0|}
  180|       |
  181|      0|bool GetLengthPrefixedSlice(Slice* input, Slice* result) {
  182|      0|  uint32_t len;
  183|      0|  if (GetVarint32(input, &len) && input->size() >= len) {
  184|      0|    *result = Slice(input->data(), len);
  185|      0|    input->remove_prefix(len);
  186|      0|    return true;
  187|      0|  } else {
  188|      0|    return false;
  189|      0|  }
  190|      0|}
  191|       |
  192|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/coding.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// Endian-neutral encoding:
    6|       |// * Fixed-length numbers are encoded with least-significant byte first
    7|       |// * In addition we support variable length "varint" encoding
    8|       |// * Strings are encoded prefixed by their length in varint format
    9|       |
   10|       |#ifndef STORAGE_LEVELDB_UTIL_CODING_H_
   11|       |#define STORAGE_LEVELDB_UTIL_CODING_H_
   12|       |
   13|       |#include <stdint.h>
   14|       |#include <string.h>
   15|       |
   16|       |#include <string>
   17|       |
   18|       |#include "leveldb/slice.h"
   19|       |#include "port/port.h"
   20|       |
   21|       |namespace leveldb {
   22|       |
   23|       |// Standard Put... routines append to a string
   24|       |void PutFixed32(std::string* dst, uint32_t value);
   25|       |void PutFixed64(std::string* dst, uint64_t value);
   26|       |void PutVarint32(std::string* dst, uint32_t value);
   27|       |void PutVarint64(std::string* dst, uint64_t value);
   28|       |void PutLengthPrefixedSlice(std::string* dst, const Slice& value);
   29|       |
   30|       |// Standard Get... routines parse a value from the beginning of a Slice
   31|       |// and advance the slice past the parsed value.
   32|       |bool GetVarint32(Slice* input, uint32_t* value);
   33|       |bool GetVarint64(Slice* input, uint64_t* value);
   34|       |bool GetLengthPrefixedSlice(Slice* input, Slice* result);
   35|       |
   36|       |// Pointer-based variants of GetVarint...  These either store a value
   37|       |// in *v and return a pointer just past the parsed value, or return
   38|       |// nullptr on error.  These routines only look at bytes in the range
   39|       |// [p..limit-1]
   40|       |const char* GetVarint32Ptr(const char* p, const char* limit, uint32_t* v);
   41|       |const char* GetVarint64Ptr(const char* p, const char* limit, uint64_t* v);
   42|       |
   43|       |// Returns the length of the varint32 or varint64 encoding of "v"
   44|       |int VarintLength(uint64_t v);
   45|       |
   46|       |// Lower-level versions of Put... that write directly into a character buffer
   47|       |// REQUIRES: dst has enough space for the value being written
   48|       |void EncodeFixed32(char* dst, uint32_t value);
   49|       |void EncodeFixed64(char* dst, uint64_t value);
   50|       |
   51|       |// Lower-level versions of Put... that write directly into a character buffer
   52|       |// and return a pointer just past the last byte written.
   53|       |// REQUIRES: dst has enough space for the value being written
   54|       |char* EncodeVarint32(char* dst, uint32_t value);
   55|       |char* EncodeVarint64(char* dst, uint64_t value);
   56|       |
   57|       |// Lower-level versions of Get... that read directly from a character buffer
   58|       |// without any bounds checking.
   59|       |
   60|      0|inline uint32_t DecodeFixed32(const char* ptr) {
   61|      0|  if (port::kLittleEndian) {
   62|      0|    // Load the raw bytes
   63|      0|    uint32_t result;
   64|      0|    memcpy(&result, ptr, sizeof(result));  // gcc optimizes this to a plain load
   65|      0|    return result;
   66|      0|  } else {
   67|      0|    return ((static_cast<uint32_t>(static_cast<unsigned char>(ptr[0]))) |
   68|      0|            (static_cast<uint32_t>(static_cast<unsigned char>(ptr[1])) << 8) |
   69|      0|            (static_cast<uint32_t>(static_cast<unsigned char>(ptr[2])) << 16) |
   70|      0|            (static_cast<uint32_t>(static_cast<unsigned char>(ptr[3])) << 24));
   71|      0|  }
   72|      0|}
   73|       |
   74|      0|inline uint64_t DecodeFixed64(const char* ptr) {
   75|      0|  if (port::kLittleEndian) {
   76|      0|    // Load the raw bytes
   77|      0|    uint64_t result;
   78|      0|    memcpy(&result, ptr, sizeof(result));  // gcc optimizes this to a plain load
   79|      0|    return result;
   80|      0|  } else {
   81|      0|    uint64_t lo = DecodeFixed32(ptr);
   82|      0|    uint64_t hi = DecodeFixed32(ptr + 4);
   83|      0|    return (hi << 32) | lo;
   84|      0|  }
   85|      0|}
   86|       |
   87|       |// Internal routine for use by fallback path of GetVarint32Ptr
   88|       |const char* GetVarint32PtrFallback(const char* p, const char* limit,
   89|       |                                   uint32_t* value);
   90|       |inline const char* GetVarint32Ptr(const char* p, const char* limit,
   91|      0|                                  uint32_t* value) {
   92|      0|  if (p < limit) {
   93|      0|    uint32_t result = *(reinterpret_cast<const unsigned char*>(p));
   94|      0|    if ((result & 128) == 0) {
   95|      0|      *value = result;
   96|      0|      return p + 1;
   97|      0|    }
   98|      0|  }
   99|      0|  return GetVarint32PtrFallback(p, limit, value);
  100|      0|}
  101|       |
  102|       |}  // namespace leveldb
  103|       |
  104|       |#endif  // STORAGE_LEVELDB_UTIL_CODING_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/comparator.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include <algorithm>
    6|       |#include <cstdint>
    7|       |#include <string>
    8|       |
    9|       |#include "leveldb/comparator.h"
   10|       |#include "leveldb/slice.h"
   11|       |#include "util/logging.h"
   12|       |#include "util/no_destructor.h"
   13|       |
   14|       |namespace leveldb {
   15|       |
   16|      0|Comparator::~Comparator() {}
   17|       |
   18|       |namespace {
   19|       |class BytewiseComparatorImpl : public Comparator {
   20|       | public:
   21|      0|  BytewiseComparatorImpl() {}
   22|       |
   23|      0|  virtual const char* Name() const { return "leveldb.BytewiseComparator"; }
   24|       |
   25|      0|  virtual int Compare(const Slice& a, const Slice& b) const {
   26|      0|    return a.compare(b);
   27|      0|  }
   28|       |
   29|       |  virtual void FindShortestSeparator(std::string* start,
   30|      0|                                     const Slice& limit) const {
   31|      0|    // Find length of common prefix
   32|      0|    size_t min_length = std::min(start->size(), limit.size());
   33|      0|    size_t diff_index = 0;
   34|      0|    while ((diff_index < min_length) &&
   35|      0|           ((*start)[diff_index] == limit[diff_index])) {
   36|      0|      diff_index++;
   37|      0|    }
   38|      0|
   39|      0|    if (diff_index >= min_length) {
   40|      0|      // Do not shorten if one string is a prefix of the other
   41|      0|    } else {
   42|      0|      uint8_t diff_byte = static_cast<uint8_t>((*start)[diff_index]);
   43|      0|      if (diff_byte < static_cast<uint8_t>(0xff) &&
   44|      0|          diff_byte + 1 < static_cast<uint8_t>(limit[diff_index])) {
   45|      0|        (*start)[diff_index]++;
   46|      0|        start->resize(diff_index + 1);
   47|      0|        assert(Compare(*start, limit) < 0);
   48|      0|      }
   49|      0|    }
   50|      0|  }
   51|       |
   52|      0|  virtual void FindShortSuccessor(std::string* key) const {
   53|      0|    // Find first character that can be incremented
   54|      0|    size_t n = key->size();
   55|      0|    for (size_t i = 0; i < n; i++) {
   56|      0|      const uint8_t byte = (*key)[i];
   57|      0|      if (byte != static_cast<uint8_t>(0xff)) {
   58|      0|        (*key)[i] = byte + 1;
   59|      0|        key->resize(i + 1);
   60|      0|        return;
   61|      0|      }
   62|      0|    }
   63|      0|    // *key is a run of 0xffs.  Leave it alone.
   64|      0|  }
   65|       |};
   66|       |}  // namespace
   67|       |
   68|      0|const Comparator* BytewiseComparator() {
   69|      0|  static NoDestructor<BytewiseComparatorImpl> singleton;
   70|      0|  return singleton.get();
   71|      0|}
   72|       |
   73|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/crc32c.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// A portable implementation of crc32c.
    6|       |
    7|       |#include "util/crc32c.h"
    8|       |
    9|       |#include <stddef.h>
   10|       |#include <stdint.h>
   11|       |
   12|       |#include "port/port.h"
   13|       |#include "util/coding.h"
   14|       |
   15|       |namespace leveldb {
   16|       |namespace crc32c {
   17|       |
   18|       |namespace {
   19|       |
   20|       |const uint32_t kByteExtensionTable[256] = {
   21|       |    0x00000000, 0xf26b8303, 0xe13b70f7, 0x1350f3f4, 0xc79a971f, 0x35f1141c,
   22|       |    0x26a1e7e8, 0xd4ca64eb, 0x8ad958cf, 0x78b2dbcc, 0x6be22838, 0x9989ab3b,
   23|       |    0x4d43cfd0, 0xbf284cd3, 0xac78bf27, 0x5e133c24, 0x105ec76f, 0xe235446c,
   24|       |    0xf165b798, 0x030e349b, 0xd7c45070, 0x25afd373, 0x36ff2087, 0xc494a384,
   25|       |    0x9a879fa0, 0x68ec1ca3, 0x7bbcef57, 0x89d76c54, 0x5d1d08bf, 0xaf768bbc,
   26|       |    0xbc267848, 0x4e4dfb4b, 0x20bd8ede, 0xd2d60ddd, 0xc186fe29, 0x33ed7d2a,
   27|       |    0xe72719c1, 0x154c9ac2, 0x061c6936, 0xf477ea35, 0xaa64d611, 0x580f5512,
   28|       |    0x4b5fa6e6, 0xb93425e5, 0x6dfe410e, 0x9f95c20d, 0x8cc531f9, 0x7eaeb2fa,
   29|       |    0x30e349b1, 0xc288cab2, 0xd1d83946, 0x23b3ba45, 0xf779deae, 0x05125dad,
   30|       |    0x1642ae59, 0xe4292d5a, 0xba3a117e, 0x4851927d, 0x5b016189, 0xa96ae28a,
   31|       |    0x7da08661, 0x8fcb0562, 0x9c9bf696, 0x6ef07595, 0x417b1dbc, 0xb3109ebf,
   32|       |    0xa0406d4b, 0x522bee48, 0x86e18aa3, 0x748a09a0, 0x67dafa54, 0x95b17957,
   33|       |    0xcba24573, 0x39c9c670, 0x2a993584, 0xd8f2b687, 0x0c38d26c, 0xfe53516f,
   34|       |    0xed03a29b, 0x1f682198, 0x5125dad3, 0xa34e59d0, 0xb01eaa24, 0x42752927,
   35|       |    0x96bf4dcc, 0x64d4cecf, 0x77843d3b, 0x85efbe38, 0xdbfc821c, 0x2997011f,
   36|       |    0x3ac7f2eb, 0xc8ac71e8, 0x1c661503, 0xee0d9600, 0xfd5d65f4, 0x0f36e6f7,
   37|       |    0x61c69362, 0x93ad1061, 0x80fde395, 0x72966096, 0xa65c047d, 0x5437877e,
   38|       |    0x4767748a, 0xb50cf789, 0xeb1fcbad, 0x197448ae, 0x0a24bb5a, 0xf84f3859,
   39|       |    0x2c855cb2, 0xdeeedfb1, 0xcdbe2c45, 0x3fd5af46, 0x7198540d, 0x83f3d70e,
   40|       |    0x90a324fa, 0x62c8a7f9, 0xb602c312, 0x44694011, 0x5739b3e5, 0xa55230e6,
   41|       |    0xfb410cc2, 0x092a8fc1, 0x1a7a7c35, 0xe811ff36, 0x3cdb9bdd, 0xceb018de,
   42|       |    0xdde0eb2a, 0x2f8b6829, 0x82f63b78, 0x709db87b, 0x63cd4b8f, 0x91a6c88c,
   43|       |    0x456cac67, 0xb7072f64, 0xa457dc90, 0x563c5f93, 0x082f63b7, 0xfa44e0b4,
   44|       |    0xe9141340, 0x1b7f9043, 0xcfb5f4a8, 0x3dde77ab, 0x2e8e845f, 0xdce5075c,
   45|       |    0x92a8fc17, 0x60c37f14, 0x73938ce0, 0x81f80fe3, 0x55326b08, 0xa759e80b,
   46|       |    0xb4091bff, 0x466298fc, 0x1871a4d8, 0xea1a27db, 0xf94ad42f, 0x0b21572c,
   47|       |    0xdfeb33c7, 0x2d80b0c4, 0x3ed04330, 0xccbbc033, 0xa24bb5a6, 0x502036a5,
   48|       |    0x4370c551, 0xb11b4652, 0x65d122b9, 0x97baa1ba, 0x84ea524e, 0x7681d14d,
   49|       |    0x2892ed69, 0xdaf96e6a, 0xc9a99d9e, 0x3bc21e9d, 0xef087a76, 0x1d63f975,
   50|       |    0x0e330a81, 0xfc588982, 0xb21572c9, 0x407ef1ca, 0x532e023e, 0xa145813d,
   51|       |    0x758fe5d6, 0x87e466d5, 0x94b49521, 0x66df1622, 0x38cc2a06, 0xcaa7a905,
   52|       |    0xd9f75af1, 0x2b9cd9f2, 0xff56bd19, 0x0d3d3e1a, 0x1e6dcdee, 0xec064eed,
   53|       |    0xc38d26c4, 0x31e6a5c7, 0x22b65633, 0xd0ddd530, 0x0417b1db, 0xf67c32d8,
   54|       |    0xe52cc12c, 0x1747422f, 0x49547e0b, 0xbb3ffd08, 0xa86f0efc, 0x5a048dff,
   55|       |    0x8ecee914, 0x7ca56a17, 0x6ff599e3, 0x9d9e1ae0, 0xd3d3e1ab, 0x21b862a8,
   56|       |    0x32e8915c, 0xc083125f, 0x144976b4, 0xe622f5b7, 0xf5720643, 0x07198540,
   57|       |    0x590ab964, 0xab613a67, 0xb831c993, 0x4a5a4a90, 0x9e902e7b, 0x6cfbad78,
   58|       |    0x7fab5e8c, 0x8dc0dd8f, 0xe330a81a, 0x115b2b19, 0x020bd8ed, 0xf0605bee,
   59|       |    0x24aa3f05, 0xd6c1bc06, 0xc5914ff2, 0x37faccf1, 0x69e9f0d5, 0x9b8273d6,
   60|       |    0x88d28022, 0x7ab90321, 0xae7367ca, 0x5c18e4c9, 0x4f48173d, 0xbd23943e,
   61|       |    0xf36e6f75, 0x0105ec76, 0x12551f82, 0xe03e9c81, 0x34f4f86a, 0xc69f7b69,
   62|       |    0xd5cf889d, 0x27a40b9e, 0x79b737ba, 0x8bdcb4b9, 0x988c474d, 0x6ae7c44e,
   63|       |    0xbe2da0a5, 0x4c4623a6, 0x5f16d052, 0xad7d5351};
   64|       |
   65|       |const uint32_t kStrideExtensionTable0[256] = {
   66|       |    0x00000000, 0x30d23865, 0x61a470ca, 0x517648af, 0xc348e194, 0xf39ad9f1,
   67|       |    0xa2ec915e, 0x923ea93b, 0x837db5d9, 0xb3af8dbc, 0xe2d9c513, 0xd20bfd76,
   68|       |    0x4035544d, 0x70e76c28, 0x21912487, 0x11431ce2, 0x03171d43, 0x33c52526,
   69|       |    0x62b36d89, 0x526155ec, 0xc05ffcd7, 0xf08dc4b2, 0xa1fb8c1d, 0x9129b478,
   70|       |    0x806aa89a, 0xb0b890ff, 0xe1ced850, 0xd11ce035, 0x4322490e, 0x73f0716b,
   71|       |    0x228639c4, 0x125401a1, 0x062e3a86, 0x36fc02e3, 0x678a4a4c, 0x57587229,
   72|       |    0xc566db12, 0xf5b4e377, 0xa4c2abd8, 0x941093bd, 0x85538f5f, 0xb581b73a,
   73|       |    0xe4f7ff95, 0xd425c7f0, 0x461b6ecb, 0x76c956ae, 0x27bf1e01, 0x176d2664,
   74|       |    0x053927c5, 0x35eb1fa0, 0x649d570f, 0x544f6f6a, 0xc671c651, 0xf6a3fe34,
   75|       |    0xa7d5b69b, 0x97078efe, 0x8644921c, 0xb696aa79, 0xe7e0e2d6, 0xd732dab3,
   76|       |    0x450c7388, 0x75de4bed, 0x24a80342, 0x147a3b27, 0x0c5c750c, 0x3c8e4d69,
   77|       |    0x6df805c6, 0x5d2a3da3, 0xcf149498, 0xffc6acfd, 0xaeb0e452, 0x9e62dc37,
   78|       |    0x8f21c0d5, 0xbff3f8b0, 0xee85b01f, 0xde57887a, 0x4c692141, 0x7cbb1924,
   79|       |    0x2dcd518b, 0x1d1f69ee, 0x0f4b684f, 0x3f99502a, 0x6eef1885, 0x5e3d20e0,
   80|       |    0xcc0389db, 0xfcd1b1be, 0xada7f911, 0x9d75c174, 0x8c36dd96, 0xbce4e5f3,
   81|       |    0xed92ad5c, 0xdd409539, 0x4f7e3c02, 0x7fac0467, 0x2eda4cc8, 0x1e0874ad,
   82|       |    0x0a724f8a, 0x3aa077ef, 0x6bd63f40, 0x5b040725, 0xc93aae1e, 0xf9e8967b,
   83|       |    0xa89eded4, 0x984ce6b1, 0x890ffa53, 0xb9ddc236, 0xe8ab8a99, 0xd879b2fc,
   84|       |    0x4a471bc7, 0x7a9523a2, 0x2be36b0d, 0x1b315368, 0x096552c9, 0x39b76aac,
   85|       |    0x68c12203, 0x58131a66, 0xca2db35d, 0xfaff8b38, 0xab89c397, 0x9b5bfbf2,
   86|       |    0x8a18e710, 0xbacadf75, 0xebbc97da, 0xdb6eafbf, 0x49500684, 0x79823ee1,
   87|       |    0x28f4764e, 0x18264e2b, 0x18b8ea18, 0x286ad27d, 0x791c9ad2, 0x49cea2b7,
   88|       |    0xdbf00b8c, 0xeb2233e9, 0xba547b46, 0x8a864323, 0x9bc55fc1, 0xab1767a4,
   89|       |    0xfa612f0b, 0xcab3176e, 0x588dbe55, 0x685f8630, 0x3929ce9f, 0x09fbf6fa,
   90|       |    0x1baff75b, 0x2b7dcf3e, 0x7a0b8791, 0x4ad9bff4, 0xd8e716cf, 0xe8352eaa,
   91|       |    0xb9436605, 0x89915e60, 0x98d24282, 0xa8007ae7, 0xf9763248, 0xc9a40a2d,
   92|       |    0x5b9aa316, 0x6b489b73, 0x3a3ed3dc, 0x0aecebb9, 0x1e96d09e, 0x2e44e8fb,
   93|       |    0x7f32a054, 0x4fe09831, 0xddde310a, 0xed0c096f, 0xbc7a41c0, 0x8ca879a5,
   94|       |    0x9deb6547, 0xad395d22, 0xfc4f158d, 0xcc9d2de8, 0x5ea384d3, 0x6e71bcb6,
   95|       |    0x3f07f419, 0x0fd5cc7c, 0x1d81cddd, 0x2d53f5b8, 0x7c25bd17, 0x4cf78572,
   96|       |    0xdec92c49, 0xee1b142c, 0xbf6d5c83, 0x8fbf64e6, 0x9efc7804, 0xae2e4061,
   97|       |    0xff5808ce, 0xcf8a30ab, 0x5db49990, 0x6d66a1f5, 0x3c10e95a, 0x0cc2d13f,
   98|       |    0x14e49f14, 0x2436a771, 0x7540efde, 0x4592d7bb, 0xd7ac7e80, 0xe77e46e5,
   99|       |    0xb6080e4a, 0x86da362f, 0x97992acd, 0xa74b12a8, 0xf63d5a07, 0xc6ef6262,
  100|       |    0x54d1cb59, 0x6403f33c, 0x3575bb93, 0x05a783f6, 0x17f38257, 0x2721ba32,
  101|       |    0x7657f29d, 0x4685caf8, 0xd4bb63c3, 0xe4695ba6, 0xb51f1309, 0x85cd2b6c,
  102|       |    0x948e378e, 0xa45c0feb, 0xf52a4744, 0xc5f87f21, 0x57c6d61a, 0x6714ee7f,
  103|       |    0x3662a6d0, 0x06b09eb5, 0x12caa592, 0x22189df7, 0x736ed558, 0x43bced3d,
  104|       |    0xd1824406, 0xe1507c63, 0xb02634cc, 0x80f40ca9, 0x91b7104b, 0xa165282e,
  105|       |    0xf0136081, 0xc0c158e4, 0x52fff1df, 0x622dc9ba, 0x335b8115, 0x0389b970,
  106|       |    0x11ddb8d1, 0x210f80b4, 0x7079c81b, 0x40abf07e, 0xd2955945, 0xe2476120,
  107|       |    0xb331298f, 0x83e311ea, 0x92a00d08, 0xa272356d, 0xf3047dc2, 0xc3d645a7,
  108|       |    0x51e8ec9c, 0x613ad4f9, 0x304c9c56, 0x009ea433};
  109|       |
  110|       |const uint32_t kStrideExtensionTable1[256] = {
  111|       |    0x00000000, 0x54075546, 0xa80eaa8c, 0xfc09ffca, 0x55f123e9, 0x01f676af,
  112|       |    0xfdff8965, 0xa9f8dc23, 0xabe247d2, 0xffe51294, 0x03eced5e, 0x57ebb818,
  113|       |    0xfe13643b, 0xaa14317d, 0x561dceb7, 0x021a9bf1, 0x5228f955, 0x062fac13,
  114|       |    0xfa2653d9, 0xae21069f, 0x07d9dabc, 0x53de8ffa, 0xafd77030, 0xfbd02576,
  115|       |    0xf9cabe87, 0xadcdebc1, 0x51c4140b, 0x05c3414d, 0xac3b9d6e, 0xf83cc828,
  116|       |    0x043537e2, 0x503262a4, 0xa451f2aa, 0xf056a7ec, 0x0c5f5826, 0x58580d60,
  117|       |    0xf1a0d143, 0xa5a78405, 0x59ae7bcf, 0x0da92e89, 0x0fb3b578, 0x5bb4e03e,
  118|       |    0xa7bd1ff4, 0xf3ba4ab2, 0x5a429691, 0x0e45c3d7, 0xf24c3c1d, 0xa64b695b,
  119|       |    0xf6790bff, 0xa27e5eb9, 0x5e77a173, 0x0a70f435, 0xa3882816, 0xf78f7d50,
  120|       |    0x0b86829a, 0x5f81d7dc, 0x5d9b4c2d, 0x099c196b, 0xf595e6a1, 0xa192b3e7,
  121|       |    0x086a6fc4, 0x5c6d3a82, 0xa064c548, 0xf463900e, 0x4d4f93a5, 0x1948c6e3,
  122|       |    0xe5413929, 0xb1466c6f, 0x18beb04c, 0x4cb9e50a, 0xb0b01ac0, 0xe4b74f86,
  123|       |    0xe6add477, 0xb2aa8131, 0x4ea37efb, 0x1aa42bbd, 0xb35cf79e, 0xe75ba2d8,
  124|       |    0x1b525d12, 0x4f550854, 0x1f676af0, 0x4b603fb6, 0xb769c07c, 0xe36e953a,
  125|       |    0x4a964919, 0x1e911c5f, 0xe298e395, 0xb69fb6d3, 0xb4852d22, 0xe0827864,
  126|       |    0x1c8b87ae, 0x488cd2e8, 0xe1740ecb, 0xb5735b8d, 0x497aa447, 0x1d7df101,
  127|       |    0xe91e610f, 0xbd193449, 0x4110cb83, 0x15179ec5, 0xbcef42e6, 0xe8e817a0,
  128|       |    0x14e1e86a, 0x40e6bd2c, 0x42fc26dd, 0x16fb739b, 0xeaf28c51, 0xbef5d917,
  129|       |    0x170d0534, 0x430a5072, 0xbf03afb8, 0xeb04fafe, 0xbb36985a, 0xef31cd1c,
  130|       |    0x133832d6, 0x473f6790, 0xeec7bbb3, 0xbac0eef5, 0x46c9113f, 0x12ce4479,
  131|       |    0x10d4df88, 0x44d38ace, 0xb8da7504, 0xecdd2042, 0x4525fc61, 0x1122a927,
  132|       |    0xed2b56ed, 0xb92c03ab, 0x9a9f274a, 0xce98720c, 0x32918dc6, 0x6696d880,
  133|       |    0xcf6e04a3, 0x9b6951e5, 0x6760ae2f, 0x3367fb69, 0x317d6098, 0x657a35de,
  134|       |    0x9973ca14, 0xcd749f52, 0x648c4371, 0x308b1637, 0xcc82e9fd, 0x9885bcbb,
  135|       |    0xc8b7de1f, 0x9cb08b59, 0x60b97493, 0x34be21d5, 0x9d46fdf6, 0xc941a8b0,
  136|       |    0x3548577a, 0x614f023c, 0x635599cd, 0x3752cc8b, 0xcb5b3341, 0x9f5c6607,
  137|       |    0x36a4ba24, 0x62a3ef62, 0x9eaa10a8, 0xcaad45ee, 0x3eced5e0, 0x6ac980a6,
  138|       |    0x96c07f6c, 0xc2c72a2a, 0x6b3ff609, 0x3f38a34f, 0xc3315c85, 0x973609c3,
  139|       |    0x952c9232, 0xc12bc774, 0x3d2238be, 0x69256df8, 0xc0ddb1db, 0x94dae49d,
  140|       |    0x68d31b57, 0x3cd44e11, 0x6ce62cb5, 0x38e179f3, 0xc4e88639, 0x90efd37f,
  141|       |    0x39170f5c, 0x6d105a1a, 0x9119a5d0, 0xc51ef096, 0xc7046b67, 0x93033e21,
  142|       |    0x6f0ac1eb, 0x3b0d94ad, 0x92f5488e, 0xc6f21dc8, 0x3afbe202, 0x6efcb744,
  143|       |    0xd7d0b4ef, 0x83d7e1a9, 0x7fde1e63, 0x2bd94b25, 0x82219706, 0xd626c240,
  144|       |    0x2a2f3d8a, 0x7e2868cc, 0x7c32f33d, 0x2835a67b, 0xd43c59b1, 0x803b0cf7,
  145|       |    0x29c3d0d4, 0x7dc48592, 0x81cd7a58, 0xd5ca2f1e, 0x85f84dba, 0xd1ff18fc,
  146|       |    0x2df6e736, 0x79f1b270, 0xd0096e53, 0x840e3b15, 0x7807c4df, 0x2c009199,
  147|       |    0x2e1a0a68, 0x7a1d5f2e, 0x8614a0e4, 0xd213f5a2, 0x7beb2981, 0x2fec7cc7,
  148|       |    0xd3e5830d, 0x87e2d64b, 0x73814645, 0x27861303, 0xdb8fecc9, 0x8f88b98f,
  149|       |    0x267065ac, 0x727730ea, 0x8e7ecf20, 0xda799a66, 0xd8630197, 0x8c6454d1,
  150|       |    0x706dab1b, 0x246afe5d, 0x8d92227e, 0xd9957738, 0x259c88f2, 0x719bddb4,
  151|       |    0x21a9bf10, 0x75aeea56, 0x89a7159c, 0xdda040da, 0x74589cf9, 0x205fc9bf,
  152|       |    0xdc563675, 0x88516333, 0x8a4bf8c2, 0xde4cad84, 0x2245524e, 0x76420708,
  153|       |    0xdfbadb2b, 0x8bbd8e6d, 0x77b471a7, 0x23b324e1};
  154|       |
  155|       |const uint32_t kStrideExtensionTable2[256] = {
  156|       |    0x00000000, 0x678efd01, 0xcf1dfa02, 0xa8930703, 0x9bd782f5, 0xfc597ff4,
  157|       |    0x54ca78f7, 0x334485f6, 0x3243731b, 0x55cd8e1a, 0xfd5e8919, 0x9ad07418,
  158|       |    0xa994f1ee, 0xce1a0cef, 0x66890bec, 0x0107f6ed, 0x6486e636, 0x03081b37,
  159|       |    0xab9b1c34, 0xcc15e135, 0xff5164c3, 0x98df99c2, 0x304c9ec1, 0x57c263c0,
  160|       |    0x56c5952d, 0x314b682c, 0x99d86f2f, 0xfe56922e, 0xcd1217d8, 0xaa9cead9,
  161|       |    0x020fedda, 0x658110db, 0xc90dcc6c, 0xae83316d, 0x0610366e, 0x619ecb6f,
  162|       |    0x52da4e99, 0x3554b398, 0x9dc7b49b, 0xfa49499a, 0xfb4ebf77, 0x9cc04276,
  163|       |    0x34534575, 0x53ddb874, 0x60993d82, 0x0717c083, 0xaf84c780, 0xc80a3a81,
  164|       |    0xad8b2a5a, 0xca05d75b, 0x6296d058, 0x05182d59, 0x365ca8af, 0x51d255ae,
  165|       |    0xf94152ad, 0x9ecfafac, 0x9fc85941, 0xf846a440, 0x50d5a343, 0x375b5e42,
  166|       |    0x041fdbb4, 0x639126b5, 0xcb0221b6, 0xac8cdcb7, 0x97f7ee29, 0xf0791328,
  167|       |    0x58ea142b, 0x3f64e92a, 0x0c206cdc, 0x6bae91dd, 0xc33d96de, 0xa4b36bdf,
  168|       |    0xa5b49d32, 0xc23a6033, 0x6aa96730, 0x0d279a31, 0x3e631fc7, 0x59ede2c6,
  169|       |    0xf17ee5c5, 0x96f018c4, 0xf371081f, 0x94fff51e, 0x3c6cf21d, 0x5be20f1c,
  170|       |    0x68a68aea, 0x0f2877eb, 0xa7bb70e8, 0xc0358de9, 0xc1327b04, 0xa6bc8605,
  171|       |    0x0e2f8106, 0x69a17c07, 0x5ae5f9f1, 0x3d6b04f0, 0x95f803f3, 0xf276fef2,
  172|       |    0x5efa2245, 0x3974df44, 0x91e7d847, 0xf6692546, 0xc52da0b0, 0xa2a35db1,
  173|       |    0x0a305ab2, 0x6dbea7b3, 0x6cb9515e, 0x0b37ac5f, 0xa3a4ab5c, 0xc42a565d,
  174|       |    0xf76ed3ab, 0x90e02eaa, 0x387329a9, 0x5ffdd4a8, 0x3a7cc473, 0x5df23972,
  175|       |    0xf5613e71, 0x92efc370, 0xa1ab4686, 0xc625bb87, 0x6eb6bc84, 0x09384185,
  176|       |    0x083fb768, 0x6fb14a69, 0xc7224d6a, 0xa0acb06b, 0x93e8359d, 0xf466c89c,
  177|       |    0x5cf5cf9f, 0x3b7b329e, 0x2a03aaa3, 0x4d8d57a2, 0xe51e50a1, 0x8290ada0,
  178|       |    0xb1d42856, 0xd65ad557, 0x7ec9d254, 0x19472f55, 0x1840d9b8, 0x7fce24b9,
  179|       |    0xd75d23ba, 0xb0d3debb, 0x83975b4d, 0xe419a64c, 0x4c8aa14f, 0x2b045c4e,
  180|       |    0x4e854c95, 0x290bb194, 0x8198b697, 0xe6164b96, 0xd552ce60, 0xb2dc3361,
  181|       |    0x1a4f3462, 0x7dc1c963, 0x7cc63f8e, 0x1b48c28f, 0xb3dbc58c, 0xd455388d,
  182|       |    0xe711bd7b, 0x809f407a, 0x280c4779, 0x4f82ba78, 0xe30e66cf, 0x84809bce,
  183|       |    0x2c139ccd, 0x4b9d61cc, 0x78d9e43a, 0x1f57193b, 0xb7c41e38, 0xd04ae339,
  184|       |    0xd14d15d4, 0xb6c3e8d5, 0x1e50efd6, 0x79de12d7, 0x4a9a9721, 0x2d146a20,
  185|       |    0x85876d23, 0xe2099022, 0x878880f9, 0xe0067df8, 0x48957afb, 0x2f1b87fa,
  186|       |    0x1c5f020c, 0x7bd1ff0d, 0xd342f80e, 0xb4cc050f, 0xb5cbf3e2, 0xd2450ee3,
  187|       |    0x7ad609e0, 0x1d58f4e1, 0x2e1c7117, 0x49928c16, 0xe1018b15, 0x868f7614,
  188|       |    0xbdf4448a, 0xda7ab98b, 0x72e9be88, 0x15674389, 0x2623c67f, 0x41ad3b7e,
  189|       |    0xe93e3c7d, 0x8eb0c17c, 0x8fb73791, 0xe839ca90, 0x40aacd93, 0x27243092,
  190|       |    0x1460b564, 0x73ee4865, 0xdb7d4f66, 0xbcf3b267, 0xd972a2bc, 0xbefc5fbd,
  191|       |    0x166f58be, 0x71e1a5bf, 0x42a52049, 0x252bdd48, 0x8db8da4b, 0xea36274a,
  192|       |    0xeb31d1a7, 0x8cbf2ca6, 0x242c2ba5, 0x43a2d6a4, 0x70e65352, 0x1768ae53,
  193|       |    0xbffba950, 0xd8755451, 0x74f988e6, 0x137775e7, 0xbbe472e4, 0xdc6a8fe5,
  194|       |    0xef2e0a13, 0x88a0f712, 0x2033f011, 0x47bd0d10, 0x46bafbfd, 0x213406fc,
  195|       |    0x89a701ff, 0xee29fcfe, 0xdd6d7908, 0xbae38409, 0x1270830a, 0x75fe7e0b,
  196|       |    0x107f6ed0, 0x77f193d1, 0xdf6294d2, 0xb8ec69d3, 0x8ba8ec25, 0xec261124,
  197|       |    0x44b51627, 0x233beb26, 0x223c1dcb, 0x45b2e0ca, 0xed21e7c9, 0x8aaf1ac8,
  198|       |    0xb9eb9f3e, 0xde65623f, 0x76f6653c, 0x1178983d};
  199|       |
  200|       |const uint32_t kStrideExtensionTable3[256] = {
  201|       |    0x00000000, 0xf20c0dfe, 0xe1f46d0d, 0x13f860f3, 0xc604aceb, 0x3408a115,
  202|       |    0x27f0c1e6, 0xd5fccc18, 0x89e52f27, 0x7be922d9, 0x6811422a, 0x9a1d4fd4,
  203|       |    0x4fe183cc, 0xbded8e32, 0xae15eec1, 0x5c19e33f, 0x162628bf, 0xe42a2541,
  204|       |    0xf7d245b2, 0x05de484c, 0xd0228454, 0x222e89aa, 0x31d6e959, 0xc3dae4a7,
  205|       |    0x9fc30798, 0x6dcf0a66, 0x7e376a95, 0x8c3b676b, 0x59c7ab73, 0xabcba68d,
  206|       |    0xb833c67e, 0x4a3fcb80, 0x2c4c517e, 0xde405c80, 0xcdb83c73, 0x3fb4318d,
  207|       |    0xea48fd95, 0x1844f06b, 0x0bbc9098, 0xf9b09d66, 0xa5a97e59, 0x57a573a7,
  208|       |    0x445d1354, 0xb6511eaa, 0x63add2b2, 0x91a1df4c, 0x8259bfbf, 0x7055b241,
  209|       |    0x3a6a79c1, 0xc866743f, 0xdb9e14cc, 0x29921932, 0xfc6ed52a, 0x0e62d8d4,
  210|       |    0x1d9ab827, 0xef96b5d9, 0xb38f56e6, 0x41835b18, 0x527b3beb, 0xa0773615,
  211|       |    0x758bfa0d, 0x8787f7f3, 0x947f9700, 0x66739afe, 0x5898a2fc, 0xaa94af02,
  212|       |    0xb96ccff1, 0x4b60c20f, 0x9e9c0e17, 0x6c9003e9, 0x7f68631a, 0x8d646ee4,
  213|       |    0xd17d8ddb, 0x23718025, 0x3089e0d6, 0xc285ed28, 0x17792130, 0xe5752cce,
  214|       |    0xf68d4c3d, 0x048141c3, 0x4ebe8a43, 0xbcb287bd, 0xaf4ae74e, 0x5d46eab0,
  215|       |    0x88ba26a8, 0x7ab62b56, 0x694e4ba5, 0x9b42465b, 0xc75ba564, 0x3557a89a,
  216|       |    0x26afc869, 0xd4a3c597, 0x015f098f, 0xf3530471, 0xe0ab6482, 0x12a7697c,
  217|       |    0x74d4f382, 0x86d8fe7c, 0x95209e8f, 0x672c9371, 0xb2d05f69, 0x40dc5297,
  218|       |    0x53243264, 0xa1283f9a, 0xfd31dca5, 0x0f3dd15b, 0x1cc5b1a8, 0xeec9bc56,
  219|       |    0x3b35704e, 0xc9397db0, 0xdac11d43, 0x28cd10bd, 0x62f2db3d, 0x90fed6c3,
  220|       |    0x8306b630, 0x710abbce, 0xa4f677d6, 0x56fa7a28, 0x45021adb, 0xb70e1725,
  221|       |    0xeb17f41a, 0x191bf9e4, 0x0ae39917, 0xf8ef94e9, 0x2d1358f1, 0xdf1f550f,
  222|       |    0xcce735fc, 0x3eeb3802, 0xb13145f8, 0x433d4806, 0x50c528f5, 0xa2c9250b,
  223|       |    0x7735e913, 0x8539e4ed, 0x96c1841e, 0x64cd89e0, 0x38d46adf, 0xcad86721,
  224|       |    0xd92007d2, 0x2b2c0a2c, 0xfed0c634, 0x0cdccbca, 0x1f24ab39, 0xed28a6c7,
  225|       |    0xa7176d47, 0x551b60b9, 0x46e3004a, 0xb4ef0db4, 0x6113c1ac, 0x931fcc52,
  226|       |    0x80e7aca1, 0x72eba15f, 0x2ef24260, 0xdcfe4f9e, 0xcf062f6d, 0x3d0a2293,
  227|       |    0xe8f6ee8b, 0x1afae375, 0x09028386, 0xfb0e8e78, 0x9d7d1486, 0x6f711978,
  228|       |    0x7c89798b, 0x8e857475, 0x5b79b86d, 0xa975b593, 0xba8dd560, 0x4881d89e,
  229|       |    0x14983ba1, 0xe694365f, 0xf56c56ac, 0x07605b52, 0xd29c974a, 0x20909ab4,
  230|       |    0x3368fa47, 0xc164f7b9, 0x8b5b3c39, 0x795731c7, 0x6aaf5134, 0x98a35cca,
  231|       |    0x4d5f90d2, 0xbf539d2c, 0xacabfddf, 0x5ea7f021, 0x02be131e, 0xf0b21ee0,
  232|       |    0xe34a7e13, 0x114673ed, 0xc4babff5, 0x36b6b20b, 0x254ed2f8, 0xd742df06,
  233|       |    0xe9a9e704, 0x1ba5eafa, 0x085d8a09, 0xfa5187f7, 0x2fad4bef, 0xdda14611,
  234|       |    0xce5926e2, 0x3c552b1c, 0x604cc823, 0x9240c5dd, 0x81b8a52e, 0x73b4a8d0,
  235|       |    0xa64864c8, 0x54446936, 0x47bc09c5, 0xb5b0043b, 0xff8fcfbb, 0x0d83c245,
  236|       |    0x1e7ba2b6, 0xec77af48, 0x398b6350, 0xcb876eae, 0xd87f0e5d, 0x2a7303a3,
  237|       |    0x766ae09c, 0x8466ed62, 0x979e8d91, 0x6592806f, 0xb06e4c77, 0x42624189,
  238|       |    0x519a217a, 0xa3962c84, 0xc5e5b67a, 0x37e9bb84, 0x2411db77, 0xd61dd689,
  239|       |    0x03e11a91, 0xf1ed176f, 0xe215779c, 0x10197a62, 0x4c00995d, 0xbe0c94a3,
  240|       |    0xadf4f450, 0x5ff8f9ae, 0x8a0435b6, 0x78083848, 0x6bf058bb, 0x99fc5545,
  241|       |    0xd3c39ec5, 0x21cf933b, 0x3237f3c8, 0xc03bfe36, 0x15c7322e, 0xe7cb3fd0,
  242|       |    0xf4335f23, 0x063f52dd, 0x5a26b1e2, 0xa82abc1c, 0xbbd2dcef, 0x49ded111,
  243|       |    0x9c221d09, 0x6e2e10f7, 0x7dd67004, 0x8fda7dfa};
  244|       |
  245|       |// CRCs are pre- and post- conditioned by xoring with all ones.
  246|       |static constexpr const uint32_t kCRC32Xor = static_cast<uint32_t>(0xffffffffU);
  247|       |
  248|       |// Reads a little-endian 32-bit integer from a 32-bit-aligned buffer.
  249|      0|inline uint32_t ReadUint32LE(const uint8_t* buffer) {
  250|      0|  return DecodeFixed32(reinterpret_cast<const char*>(buffer));
  251|      0|}
  252|       |
  253|       |// Returns the smallest address >= the given address that is aligned to N bytes.
  254|       |//
  255|       |// N must be a power of two.
  256|       |template <int N>
  257|      0|constexpr inline const uint8_t* RoundUp(const uint8_t* pointer) {
  258|      0|  return reinterpret_cast<uint8_t*>(
  259|      0|      (reinterpret_cast<uintptr_t>(pointer) + (N - 1)) &
  260|      0|      ~static_cast<uintptr_t>(N - 1));
  261|      0|}
  262|       |
  263|       |}  // namespace
  264|       |
  265|       |// Determine if the CPU running this program can accelerate the CRC32C
  266|       |// calculation.
  267|      0|static bool CanAccelerateCRC32C() {
  268|      0|  // port::AcceleretedCRC32C returns zero when unable to accelerate.
  269|      0|  static const char kTestCRCBuffer[] = "TestCRCBuffer";
  270|      0|  static const char kBufSize = sizeof(kTestCRCBuffer) - 1;
  271|      0|  static const uint32_t kTestCRCValue = 0xdcbc59fa;
  272|      0|
  273|      0|  return port::AcceleratedCRC32C(0, kTestCRCBuffer, kBufSize) == kTestCRCValue;
  274|      0|}
  275|       |
  276|      0|uint32_t Extend(uint32_t crc, const char* data, size_t n) {
  277|      0|  static bool accelerate = CanAccelerateCRC32C();
  278|      0|  if (accelerate) {
  279|      0|    return port::AcceleratedCRC32C(crc, data, n);
  280|      0|  }
  281|      0|
  282|      0|  const uint8_t* p = reinterpret_cast<const uint8_t*>(data);
  283|      0|  const uint8_t* e = p + n;
  284|      0|  uint32_t l = crc ^ kCRC32Xor;
  285|      0|
  286|      0|// Process one byte at a time.
  287|      0|#define STEP1                              \
  288|      0|  do {                                     \
  289|      0|    int c = (l & 0xff) ^ *p++;             \
  290|      0|    l = kByteExtensionTable[c] ^ (l >> 8); \
  291|      0|  } while (0)
  292|      0|
  293|      0|// Process one of the 4 strides of 4-byte data.
  294|      0|#define STEP4(s)                                                               \
  295|      0|  do {                                                                         \
  296|      0|    crc##s = ReadUint32LE(p + s * 4) ^ kStrideExtensionTable3[crc##s & 0xff] ^ \
  297|      0|             kStrideExtensionTable2[(crc##s >> 8) & 0xff] ^                    \
  298|      0|             kStrideExtensionTable1[(crc##s >> 16) & 0xff] ^                   \
  299|      0|             kStrideExtensionTable0[crc##s >> 24];                             \
  300|      0|  } while (0)
  301|      0|
  302|      0|// Process a 16-byte swath of 4 strides, each of which has 4 bytes of data.
  303|      0|#define STEP16 \
  304|      0|  do {         \
  305|      0|    STEP4(0);  \
  306|      0|    STEP4(1);  \
  307|      0|    STEP4(2);  \
  308|      0|    STEP4(3);  \
  309|      0|    p += 16;   \
  310|      0|  } while (0)
  311|      0|
  312|      0|// Process 4 bytes that were already loaded into a word.
  313|      0|#define STEP4W(w)                                   \
  314|      0|  do {                                              \
  315|      0|    w ^= l;                                         \
  316|      0|    for (size_t i = 0; i < 4; ++i) {                \
  317|      0|      w = (w >> 8) ^ kByteExtensionTable[w & 0xff]; \
  318|      0|    }                                               \
  319|      0|    l = w;                                          \
  320|      0|  } while (0)
  321|      0|
  322|      0|  // Point x at first 4-byte aligned byte in the buffer. This might be past the
  323|      0|  // end of the buffer.
  324|      0|  const uint8_t* x = RoundUp<4>(p);
  325|      0|  if (x <= e) {
  326|      0|    // Process bytes p is 4-byte aligned.
  327|      0|    while (p != x) {
  328|      0|      STEP1;
  329|      0|    }
  330|      0|  }
  331|      0|
  332|      0|  if ((e - p) >= 16) {
  333|      0|    // Load a 16-byte swath into the stride partial results.
  334|      0|    uint32_t crc0 = ReadUint32LE(p + 0 * 4) ^ l;
  335|      0|    uint32_t crc1 = ReadUint32LE(p + 1 * 4);
  336|      0|    uint32_t crc2 = ReadUint32LE(p + 2 * 4);
  337|      0|    uint32_t crc3 = ReadUint32LE(p + 3 * 4);
  338|      0|    p += 16;
  339|      0|
  340|      0|    // It is possible to get better speeds (at least on x86) by interleaving
  341|      0|    // prefetching 256 bytes ahead with processing 64 bytes at a time. See the
  342|      0|    // portable implementation in https://github.com/google/crc32c/.
  343|      0|
  344|      0|    // Process one 16-byte swath at a time.
  345|      0|    while ((e - p) >= 16) {
  346|      0|      STEP16;
  347|      0|    }
  348|      0|
  349|      0|    // Advance one word at a time as far as possible.
  350|      0|    while ((e - p) >= 4) {
  351|      0|      STEP4(0);
  352|      0|      uint32_t tmp = crc0;
  353|      0|      crc0 = crc1;
  354|      0|      crc1 = crc2;
  355|      0|      crc2 = crc3;
  356|      0|      crc3 = tmp;
  357|      0|      p += 4;
  358|      0|    }
  359|      0|
  360|      0|    // Combine the 4 partial stride results.
  361|      0|    l = 0;
  362|      0|    STEP4W(crc0);
  363|      0|    STEP4W(crc1);
  364|      0|    STEP4W(crc2);
  365|      0|    STEP4W(crc3);
  366|      0|  }
  367|      0|
  368|      0|  // Process the last few bytes.
  369|      0|  while (p != e) {
  370|      0|    STEP1;
  371|      0|  }
  372|      0|#undef STEP4W
  373|      0|#undef STEP16
  374|      0|#undef STEP4
  375|      0|#undef STEP1
  376|      0|  return l ^ kCRC32Xor;
  377|      0|}
  378|       |
  379|       |}  // namespace crc32c
  380|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/crc32c.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_UTIL_CRC32C_H_
    6|       |#define STORAGE_LEVELDB_UTIL_CRC32C_H_
    7|       |
    8|       |#include <stddef.h>
    9|       |#include <stdint.h>
   10|       |
   11|       |namespace leveldb {
   12|       |namespace crc32c {
   13|       |
   14|       |// Return the crc32c of concat(A, data[0,n-1]) where init_crc is the
   15|       |// crc32c of some string A.  Extend() is often used to maintain the
   16|       |// crc32c of a stream of data.
   17|       |uint32_t Extend(uint32_t init_crc, const char* data, size_t n);
   18|       |
   19|       |// Return the crc32c of data[0,n-1]
   20|      0|inline uint32_t Value(const char* data, size_t n) { return Extend(0, data, n); }
   21|       |
   22|       |static const uint32_t kMaskDelta = 0xa282ead8ul;
   23|       |
   24|       |// Return a masked representation of crc.
   25|       |//
   26|       |// Motivation: it is problematic to compute the CRC of a string that
   27|       |// contains embedded CRCs.  Therefore we recommend that CRCs stored
   28|       |// somewhere (e.g., in files) should be masked before being stored.
   29|      0|inline uint32_t Mask(uint32_t crc) {
   30|      0|  // Rotate right by 15 bits and add a constant.
   31|      0|  return ((crc >> 15) | (crc << 17)) + kMaskDelta;
   32|      0|}
   33|       |
   34|       |// Return the crc whose masked representation is masked_crc.
   35|      0|inline uint32_t Unmask(uint32_t masked_crc) {
   36|      0|  uint32_t rot = masked_crc - kMaskDelta;
   37|      0|  return ((rot >> 17) | (rot << 15));
   38|      0|}
   39|       |
   40|       |}  // namespace crc32c
   41|       |}  // namespace leveldb
   42|       |
   43|       |#endif  // STORAGE_LEVELDB_UTIL_CRC32C_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/env.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "leveldb/env.h"
    6|       |
    7|       |namespace leveldb {
    8|       |
    9|      0|Env::~Env() {}
   10|       |
   11|      0|Status Env::NewAppendableFile(const std::string& fname, WritableFile** result) {
   12|      0|  return Status::NotSupported("NewAppendableFile", fname);
   13|      0|}
   14|       |
   15|      0|SequentialFile::~SequentialFile() {}
   16|       |
   17|      0|RandomAccessFile::~RandomAccessFile() {}
   18|       |
   19|      0|WritableFile::~WritableFile() {}
   20|       |
   21|      0|Logger::~Logger() {}
   22|       |
   23|      0|FileLock::~FileLock() {}
   24|       |
   25|      0|void Log(Logger* info_log, const char* format, ...) {
   26|      0|  if (info_log != nullptr) {
   27|      0|    va_list ap;
   28|      0|    va_start(ap, format);
   29|      0|    info_log->Logv(format, ap);
   30|      0|    va_end(ap);
   31|      0|  }
   32|      0|}
   33|       |
   34|       |static Status DoWriteStringToFile(Env* env, const Slice& data,
   35|      0|                                  const std::string& fname, bool should_sync) {
   36|      0|  WritableFile* file;
   37|      0|  Status s = env->NewWritableFile(fname, &file);
   38|      0|  if (!s.ok()) {
   39|      0|    return s;
   40|      0|  }
   41|      0|  s = file->Append(data);
   42|      0|  if (s.ok() && should_sync) {
   43|      0|    s = file->Sync();
   44|      0|  }
   45|      0|  if (s.ok()) {
   46|      0|    s = file->Close();
   47|      0|  }
   48|      0|  delete file;  // Will auto-close if we did not close above
   49|      0|  if (!s.ok()) {
   50|      0|    env->DeleteFile(fname);
   51|      0|  }
   52|      0|  return s;
   53|      0|}
   54|       |
   55|       |Status WriteStringToFile(Env* env, const Slice& data,
   56|      0|                         const std::string& fname) {
   57|      0|  return DoWriteStringToFile(env, data, fname, false);
   58|      0|}
   59|       |
   60|       |Status WriteStringToFileSync(Env* env, const Slice& data,
   61|      0|                             const std::string& fname) {
   62|      0|  return DoWriteStringToFile(env, data, fname, true);
   63|      0|}
   64|       |
   65|      0|Status ReadFileToString(Env* env, const std::string& fname, std::string* data) {
   66|      0|  data->clear();
   67|      0|  SequentialFile* file;
   68|      0|  Status s = env->NewSequentialFile(fname, &file);
   69|      0|  if (!s.ok()) {
   70|      0|    return s;
   71|      0|  }
   72|      0|  static const int kBufferSize = 8192;
   73|      0|  char* space = new char[kBufferSize];
   74|      0|  while (true) {
   75|      0|    Slice fragment;
   76|      0|    s = file->Read(kBufferSize, &fragment, space);
   77|      0|    if (!s.ok()) {
   78|      0|      break;
   79|      0|    }
   80|      0|    data->append(fragment.data(), fragment.size());
   81|      0|    if (fragment.empty()) {
   82|      0|      break;
   83|      0|    }
   84|      0|  }
   85|      0|  delete[] space;
   86|      0|  delete file;
   87|      0|  return s;
   88|      0|}
   89|       |
   90|      0|EnvWrapper::~EnvWrapper() {}
   91|       |
   92|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/env_posix.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include <dirent.h>
    6|       |#include <fcntl.h>
    7|       |#include <pthread.h>
    8|       |#include <sys/mman.h>
    9|       |#include <sys/resource.h>
   10|       |#include <sys/stat.h>
   11|       |#include <sys/time.h>
   12|       |#include <sys/types.h>
   13|       |#include <unistd.h>
   14|       |
   15|       |#include <atomic>
   16|       |#include <cerrno>
   17|       |#include <cstddef>
   18|       |#include <cstdint>
   19|       |#include <cstdio>
   20|       |#include <cstdlib>
   21|       |#include <cstring>
   22|       |#include <limits>
   23|       |#include <queue>
   24|       |#include <set>
   25|       |#include <string>
   26|       |#include <thread>
   27|       |#include <type_traits>
   28|       |#include <utility>
   29|       |
   30|       |#include "leveldb/env.h"
   31|       |#include "leveldb/slice.h"
   32|       |#include "leveldb/status.h"
   33|       |#include "port/port.h"
   34|       |#include "port/thread_annotations.h"
   35|       |#include "util/env_posix_test_helper.h"
   36|       |#include "util/posix_logger.h"
   37|       |
   38|       |namespace leveldb {
   39|       |
   40|       |namespace {
   41|       |
   42|       |// Set by EnvPosixTestHelper::SetReadOnlyMMapLimit() and MaxOpenFiles().
   43|       |int g_open_read_only_file_limit = -1;
   44|       |
   45|       |// Up to 1000 mmap regions for 64-bit binaries; none for 32-bit.
   46|       |constexpr const int kDefaultMmapLimit = (sizeof(void*) >= 8) ? 1000 : 0;
   47|       |
   48|       |// Can be set using EnvPosixTestHelper::SetReadOnlyMMapLimit.
   49|       |int g_mmap_limit = kDefaultMmapLimit;
   50|       |
   51|       |constexpr const size_t kWritableFileBufferSize = 65536;
   52|       |
   53|      0|Status PosixError(const std::string& context, int error_number) {
   54|      0|  if (error_number == ENOENT) {
   55|      0|    return Status::NotFound(context, std::strerror(error_number));
   56|      0|  } else {
   57|      0|    return Status::IOError(context, std::strerror(error_number));
   58|      0|  }
   59|      0|}
   60|       |
   61|       |// Helper class to limit resource usage to avoid exhaustion.
   62|       |// Currently used to limit read-only file descriptors and mmap file usage
   63|       |// so that we do not run out of file descriptors or virtual memory, or run into
   64|       |// kernel performance problems for very large databases.
   65|       |class Limiter {
   66|       | public:
   67|       |  // Limit maximum number of resources to |max_acquires|.
   68|      0|  Limiter(int max_acquires) : acquires_allowed_(max_acquires) {}
   69|       |
   70|       |  Limiter(const Limiter&) = delete;
   71|       |  Limiter operator=(const Limiter&) = delete;
   72|       |
   73|       |  // If another resource is available, acquire it and return true.
   74|       |  // Else return false.
   75|      0|  bool Acquire() {
   76|      0|    int old_acquires_allowed =
   77|      0|        acquires_allowed_.fetch_sub(1, std::memory_order_relaxed);
   78|      0|
   79|      0|    if (old_acquires_allowed > 0) return true;
   80|      0|
   81|      0|    acquires_allowed_.fetch_add(1, std::memory_order_relaxed);
   82|      0|    return false;
   83|      0|  }
   84|       |
   85|       |  // Release a resource acquired by a previous call to Acquire() that returned
   86|       |  // true.
   87|      0|  void Release() { acquires_allowed_.fetch_add(1, std::memory_order_relaxed); }
   88|       |
   89|       | private:
   90|       |  // The number of available resources.
   91|       |  //
   92|       |  // This is a counter and is not tied to the invariants of any other class, so
   93|       |  // it can be operated on safely using std::memory_order_relaxed.
   94|       |  std::atomic<int> acquires_allowed_;
   95|       |};
   96|       |
   97|       |// Implements sequential read access in a file using read().
   98|       |//
   99|       |// Instances of this class are thread-friendly but not thread-safe, as required
  100|       |// by the SequentialFile API.
  101|       |class PosixSequentialFile final : public SequentialFile {
  102|       | public:
  103|       |  PosixSequentialFile(std::string filename, int fd)
  104|      0|      : fd_(fd), filename_(filename) {}
  105|      0|  ~PosixSequentialFile() override { close(fd_); }
  106|       |
  107|      0|  Status Read(size_t n, Slice* result, char* scratch) override {
  108|      0|    Status status;
  109|      0|    while (true) {
  110|      0|      ::ssize_t read_size = ::read(fd_, scratch, n);
  111|      0|      if (read_size < 0) {  // Read error.
  112|      0|        if (errno == EINTR) {
  113|      0|          continue;  // Retry
  114|      0|        }
  115|      0|        status = PosixError(filename_, errno);
  116|      0|        break;
  117|      0|      }
  118|      0|      *result = Slice(scratch, read_size);
  119|      0|      break;
  120|      0|    }
  121|      0|    return status;
  122|      0|  }
  123|       |
  124|      0|  Status Skip(uint64_t n) override {
  125|      0|    if (::lseek(fd_, n, SEEK_CUR) == static_cast<off_t>(-1)) {
  126|      0|      return PosixError(filename_, errno);
  127|      0|    }
  128|      0|    return Status::OK();
  129|      0|  }
  130|       |
  131|       | private:
  132|       |  const int fd_;
  133|       |  const std::string filename_;
  134|       |};
  135|       |
  136|       |// Implements random read access in a file using pread().
  137|       |//
  138|       |// Instances of this class are thread-safe, as required by the RandomAccessFile
  139|       |// API. Instances are immutable and Read() only calls thread-safe library
  140|       |// functions.
  141|       |class PosixRandomAccessFile final : public RandomAccessFile {
  142|       | public:
  143|       |  // The new instance takes ownership of |fd|. |fd_limiter| must outlive this
  144|       |  // instance, and will be used to determine if .
  145|       |  PosixRandomAccessFile(std::string filename, int fd, Limiter* fd_limiter)
  146|       |      : has_permanent_fd_(fd_limiter->Acquire()),
  147|       |        fd_(has_permanent_fd_ ? fd : -1),
  148|       |        fd_limiter_(fd_limiter),
  149|      0|        filename_(std::move(filename)) {
  150|      0|    if (!has_permanent_fd_) {
  151|      0|      assert(fd_ == -1);
  152|      0|      ::close(fd);  // The file will be opened on every read.
  153|      0|    }
  154|      0|  }
  155|       |
  156|      0|  ~PosixRandomAccessFile() override {
  157|      0|    if (has_permanent_fd_) {
  158|      0|      assert(fd_ != -1);
  159|      0|      ::close(fd_);
  160|      0|      fd_limiter_->Release();
  161|      0|    }
  162|      0|  }
  163|       |
  164|       |  Status Read(uint64_t offset, size_t n, Slice* result,
  165|      0|              char* scratch) const override {
  166|      0|    int fd = fd_;
  167|      0|    if (!has_permanent_fd_) {
  168|      0|      fd = ::open(filename_.c_str(), O_RDONLY);
  169|      0|      if (fd < 0) {
  170|      0|        return PosixError(filename_, errno);
  171|      0|      }
  172|      0|    }
  173|      0|
  174|      0|    assert(fd != -1);
  175|      0|
  176|      0|    Status status;
  177|      0|    ssize_t read_size = ::pread(fd, scratch, n, static_cast<off_t>(offset));
  178|      0|    *result = Slice(scratch, (read_size < 0) ? 0 : read_size);
  179|      0|    if (read_size < 0) {
  180|      0|      // An error: return a non-ok status.
  181|      0|      status = PosixError(filename_, errno);
  182|      0|    }
  183|      0|    if (!has_permanent_fd_) {
  184|      0|      // Close the temporary file descriptor opened earlier.
  185|      0|      assert(fd != fd_);
  186|      0|      ::close(fd);
  187|      0|    }
  188|      0|    return status;
  189|      0|  }
  190|       |
  191|       | private:
  192|       |  const bool has_permanent_fd_;  // If false, the file is opened on every read.
  193|       |  const int fd_;                 // -1 if has_permanent_fd_ is false.
  194|       |  Limiter* const fd_limiter_;
  195|       |  const std::string filename_;
  196|       |};
  197|       |
  198|       |// Implements random read access in a file using mmap().
  199|       |//
  200|       |// Instances of this class are thread-safe, as required by the RandomAccessFile
  201|       |// API. Instances are immutable and Read() only calls thread-safe library
  202|       |// functions.
  203|       |class PosixMmapReadableFile final : public RandomAccessFile {
  204|       | public:
  205|       |  // mmap_base[0, length-1] points to the memory-mapped contents of the file. It
  206|       |  // must be the result of a successful call to mmap(). This instances takes
  207|       |  // over the ownership of the region.
  208|       |  //
  209|       |  // |mmap_limiter| must outlive this instance. The caller must have already
  210|       |  // aquired the right to use one mmap region, which will be released when this
  211|       |  // instance is destroyed.
  212|       |  PosixMmapReadableFile(std::string filename, char* mmap_base, size_t length,
  213|       |                        Limiter* mmap_limiter)
  214|       |      : mmap_base_(mmap_base),
  215|       |        length_(length),
  216|       |        mmap_limiter_(mmap_limiter),
  217|      0|        filename_(std::move(filename)) {}
  218|       |
  219|      0|  ~PosixMmapReadableFile() override {
  220|      0|    ::munmap(static_cast<void*>(mmap_base_), length_);
  221|      0|    mmap_limiter_->Release();
  222|      0|  }
  223|       |
  224|       |  Status Read(uint64_t offset, size_t n, Slice* result,
  225|      0|              char* scratch) const override {
  226|      0|    if (offset + n > length_) {
  227|      0|      *result = Slice();
  228|      0|      return PosixError(filename_, EINVAL);
  229|      0|    }
  230|      0|
  231|      0|    *result = Slice(mmap_base_ + offset, n);
  232|      0|    return Status::OK();
  233|      0|  }
  234|       |
  235|       | private:
  236|       |  char* const mmap_base_;
  237|       |  const size_t length_;
  238|       |  Limiter* const mmap_limiter_;
  239|       |  const std::string filename_;
  240|       |};
  241|       |
  242|       |class PosixWritableFile final : public WritableFile {
  243|       | public:
  244|       |  PosixWritableFile(std::string filename, int fd)
  245|       |      : pos_(0),
  246|       |        fd_(fd),
  247|       |        is_manifest_(IsManifest(filename)),
  248|       |        filename_(std::move(filename)),
  249|      0|        dirname_(Dirname(filename_)) {}
  250|       |
  251|      0|  ~PosixWritableFile() override {
  252|      0|    if (fd_ >= 0) {
  253|      0|      // Ignoring any potential errors
  254|      0|      Close();
  255|      0|    }
  256|      0|  }
  257|       |
  258|      0|  Status Append(const Slice& data) override {
  259|      0|    size_t write_size = data.size();
  260|      0|    const char* write_data = data.data();
  261|      0|
  262|      0|    // Fit as much as possible into buffer.
  263|      0|    size_t copy_size = std::min(write_size, kWritableFileBufferSize - pos_);
  264|      0|    std::memcpy(buf_ + pos_, write_data, copy_size);
  265|      0|    write_data += copy_size;
  266|      0|    write_size -= copy_size;
  267|      0|    pos_ += copy_size;
  268|      0|    if (write_size == 0) {
  269|      0|      return Status::OK();
  270|      0|    }
  271|      0|
  272|      0|    // Can't fit in buffer, so need to do at least one write.
  273|      0|    Status status = FlushBuffer();
  274|      0|    if (!status.ok()) {
  275|      0|      return status;
  276|      0|    }
  277|      0|
  278|      0|    // Small writes go to buffer, large writes are written directly.
  279|      0|    if (write_size < kWritableFileBufferSize) {
  280|      0|      std::memcpy(buf_, write_data, write_size);
  281|      0|      pos_ = write_size;
  282|      0|      return Status::OK();
  283|      0|    }
  284|      0|    return WriteUnbuffered(write_data, write_size);
  285|      0|  }
  286|       |
  287|      0|  Status Close() override {
  288|      0|    Status status = FlushBuffer();
  289|      0|    const int close_result = ::close(fd_);
  290|      0|    if (close_result < 0 && status.ok()) {
  291|      0|      status = PosixError(filename_, errno);
  292|      0|    }
  293|      0|    fd_ = -1;
  294|      0|    return status;
  295|      0|  }
  296|       |
  297|      0|  Status Flush() override { return FlushBuffer(); }
  298|       |
  299|      0|  Status Sync() override {
  300|      0|    // Ensure new files referred to by the manifest are in the filesystem.
  301|      0|    //
  302|      0|    // This needs to happen before the manifest file is flushed to disk, to
  303|      0|    // avoid crashing in a state where the manifest refers to files that are not
  304|      0|    // yet on disk.
  305|      0|    Status status = SyncDirIfManifest();
  306|      0|    if (!status.ok()) {
  307|      0|      return status;
  308|      0|    }
  309|      0|
  310|      0|    status = FlushBuffer();
  311|      0|    if (!status.ok()) {
  312|      0|      return status;
  313|      0|    }
  314|      0|
  315|      0|    return SyncFd(fd_, filename_);
  316|      0|  }
  317|       |
  318|       | private:
  319|      0|  Status FlushBuffer() {
  320|      0|    Status status = WriteUnbuffered(buf_, pos_);
  321|      0|    pos_ = 0;
  322|      0|    return status;
  323|      0|  }
  324|       |
  325|      0|  Status WriteUnbuffered(const char* data, size_t size) {
  326|      0|    while (size > 0) {
  327|      0|      ssize_t write_result = ::write(fd_, data, size);
  328|      0|      if (write_result < 0) {
  329|      0|        if (errno == EINTR) {
  330|      0|          continue;  // Retry
  331|      0|        }
  332|      0|        return PosixError(filename_, errno);
  333|      0|      }
  334|      0|      data += write_result;
  335|      0|      size -= write_result;
  336|      0|    }
  337|      0|    return Status::OK();
  338|      0|  }
  339|       |
  340|      0|  Status SyncDirIfManifest() {
  341|      0|    Status status;
  342|      0|    if (!is_manifest_) {
  343|      0|      return status;
  344|      0|    }
  345|      0|
  346|      0|    int fd = ::open(dirname_.c_str(), O_RDONLY);
  347|      0|    if (fd < 0) {
  348|      0|      status = PosixError(dirname_, errno);
  349|      0|    } else {
  350|      0|      status = SyncFd(fd, dirname_);
  351|      0|      ::close(fd);
  352|      0|    }
  353|      0|    return status;
  354|      0|  }
  355|       |
  356|       |  // Ensures that all the caches associated with the given file descriptor's
  357|       |  // data are flushed all the way to durable media, and can withstand power
  358|       |  // failures.
  359|       |  //
  360|       |  // The path argument is only used to populate the description string in the
  361|       |  // returned Status if an error occurs.
  362|      0|  static Status SyncFd(int fd, const std::string& fd_path) {
  363|      0|#if HAVE_FULLFSYNC
  364|      0|    // On macOS and iOS, fsync() doesn't guarantee durability past power
  365|      0|    // failures. fcntl(F_FULLFSYNC) is required for that purpose. Some
  366|      0|    // filesystems don't support fcntl(F_FULLFSYNC), and require a fallback to
  367|      0|    // fsync().
  368|      0|    if (::fcntl(fd, F_FULLFSYNC) == 0) {
  369|      0|      return Status::OK();
  370|      0|    }
  371|      0|#endif  // HAVE_FULLFSYNC
  372|      0|
  373|       |#if HAVE_FDATASYNC
  374|       |    bool sync_success = ::fdatasync(fd) == 0;
  375|       |#else
  376|      0|    bool sync_success = ::fsync(fd) == 0;
  377|      0|#endif  // HAVE_FDATASYNC
  378|      0|
  379|      0|    if (sync_success) {
  380|      0|      return Status::OK();
  381|      0|    }
  382|      0|    return PosixError(fd_path, errno);
  383|      0|  }
  384|       |
  385|       |  // Returns the directory name in a path pointing to a file.
  386|       |  //
  387|       |  // Returns "." if the path does not contain any directory separator.
  388|      0|  static std::string Dirname(const std::string& filename) {
  389|      0|    std::string::size_type separator_pos = filename.rfind('/');
  390|      0|    if (separator_pos == std::string::npos) {
  391|      0|      return std::string(".");
  392|      0|    }
  393|      0|    // The filename component should not contain a path separator. If it does,
  394|      0|    // the splitting was done incorrectly.
  395|      0|    assert(filename.find('/', separator_pos + 1) == std::string::npos);
  396|      0|
  397|      0|    return filename.substr(0, separator_pos);
  398|      0|  }
  399|       |
  400|       |  // Extracts the file name from a path pointing to a file.
  401|       |  //
  402|       |  // The returned Slice points to |filename|'s data buffer, so it is only valid
  403|       |  // while |filename| is alive and unchanged.
  404|      0|  static Slice Basename(const std::string& filename) {
  405|      0|    std::string::size_type separator_pos = filename.rfind('/');
  406|      0|    if (separator_pos == std::string::npos) {
  407|      0|      return Slice(filename);
  408|      0|    }
  409|      0|    // The filename component should not contain a path separator. If it does,
  410|      0|    // the splitting was done incorrectly.
  411|      0|    assert(filename.find('/', separator_pos + 1) == std::string::npos);
  412|      0|
  413|      0|    return Slice(filename.data() + separator_pos + 1,
  414|      0|                 filename.length() - separator_pos - 1);
  415|      0|  }
  416|       |
  417|       |  // True if the given file is a manifest file.
  418|      0|  static bool IsManifest(const std::string& filename) {
  419|      0|    return Basename(filename).starts_with("MANIFEST");
  420|      0|  }
  421|       |
  422|       |  // buf_[0, pos_ - 1] contains data to be written to fd_.
  423|       |  char buf_[kWritableFileBufferSize];
  424|       |  size_t pos_;
  425|       |  int fd_;
  426|       |
  427|       |  const bool is_manifest_;  // True if the file's name starts with MANIFEST.
  428|       |  const std::string filename_;
  429|       |  const std::string dirname_;  // The directory of filename_.
  430|       |};
  431|       |
  432|      0|int LockOrUnlock(int fd, bool lock) {
  433|      0|  errno = 0;
  434|      0|  struct ::flock file_lock_info;
  435|      0|  std::memset(&file_lock_info, 0, sizeof(file_lock_info));
  436|      0|  file_lock_info.l_type = (lock ? F_WRLCK : F_UNLCK);
  437|      0|  file_lock_info.l_whence = SEEK_SET;
  438|      0|  file_lock_info.l_start = 0;
  439|      0|  file_lock_info.l_len = 0;  // Lock/unlock entire file.
  440|      0|  return ::fcntl(fd, F_SETLK, &file_lock_info);
  441|      0|}
  442|       |
  443|       |// Instances are thread-safe because they are immutable.
  444|       |class PosixFileLock : public FileLock {
  445|       | public:
  446|       |  PosixFileLock(int fd, std::string filename)
  447|      0|      : fd_(fd), filename_(std::move(filename)) {}
  448|       |
  449|      0|  int fd() const { return fd_; }
  450|      0|  const std::string& filename() const { return filename_; }
  451|       |
  452|       | private:
  453|       |  const int fd_;
  454|       |  const std::string filename_;
  455|       |};
  456|       |
  457|       |// Tracks the files locked by PosixEnv::LockFile().
  458|       |//
  459|       |// We maintain a separate set instead of relying on fcntrl(F_SETLK) because
  460|       |// fcntl(F_SETLK) does not provide any protection against multiple uses from the
  461|       |// same process.
  462|       |//
  463|       |// Instances are thread-safe because all member data is guarded by a mutex.
  464|       |class PosixLockTable {
  465|       | public:
  466|      0|  bool Insert(const std::string& fname) LOCKS_EXCLUDED(mu_) {
  467|      0|    mu_.Lock();
  468|      0|    bool succeeded = locked_files_.insert(fname).second;
  469|      0|    mu_.Unlock();
  470|      0|    return succeeded;
  471|      0|  }
  472|      0|  void Remove(const std::string& fname) LOCKS_EXCLUDED(mu_) {
  473|      0|    mu_.Lock();
  474|      0|    locked_files_.erase(fname);
  475|      0|    mu_.Unlock();
  476|      0|  }
  477|       |
  478|       | private:
  479|       |  port::Mutex mu_;
  480|       |  std::set<std::string> locked_files_ GUARDED_BY(mu_);
  481|       |};
  482|       |
  483|       |class PosixEnv : public Env {
  484|       | public:
  485|       |  PosixEnv();
  486|      0|  ~PosixEnv() override {
  487|      0|    static char msg[] = "PosixEnv singleton destroyed. Unsupported behavior!\n";
  488|      0|    std::fwrite(msg, 1, sizeof(msg), stderr);
  489|      0|    std::abort();
  490|      0|  }
  491|       |
  492|       |  Status NewSequentialFile(const std::string& filename,
  493|      0|                           SequentialFile** result) override {
  494|      0|    int fd = ::open(filename.c_str(), O_RDONLY);
  495|      0|    if (fd < 0) {
  496|      0|      *result = nullptr;
  497|      0|      return PosixError(filename, errno);
  498|      0|    }
  499|      0|
  500|      0|    *result = new PosixSequentialFile(filename, fd);
  501|      0|    return Status::OK();
  502|      0|  }
  503|       |
  504|       |  Status NewRandomAccessFile(const std::string& filename,
  505|      0|                             RandomAccessFile** result) override {
  506|      0|    *result = nullptr;
  507|      0|    int fd = ::open(filename.c_str(), O_RDONLY);
  508|      0|    if (fd < 0) {
  509|      0|      return PosixError(filename, errno);
  510|      0|    }
  511|      0|
  512|      0|    if (!mmap_limiter_.Acquire()) {
  513|      0|      *result = new PosixRandomAccessFile(filename, fd, &fd_limiter_);
  514|      0|      return Status::OK();
  515|      0|    }
  516|      0|
  517|      0|    uint64_t file_size;
  518|      0|    Status status = GetFileSize(filename, &file_size);
  519|      0|    if (status.ok()) {
  520|      0|      void* mmap_base =
  521|      0|          ::mmap(/*addr=*/nullptr, file_size, PROT_READ, MAP_SHARED, fd, 0);
  522|      0|      if (mmap_base != MAP_FAILED) {
  523|      0|        *result = new PosixMmapReadableFile(filename,
  524|      0|                                            reinterpret_cast<char*>(mmap_base),
  525|      0|                                            file_size, &mmap_limiter_);
  526|      0|      } else {
  527|      0|        status = PosixError(filename, errno);
  528|      0|      }
  529|      0|    }
  530|      0|    ::close(fd);
  531|      0|    if (!status.ok()) {
  532|      0|      mmap_limiter_.Release();
  533|      0|    }
  534|      0|    return status;
  535|      0|  }
  536|       |
  537|       |  Status NewWritableFile(const std::string& filename,
  538|      0|                         WritableFile** result) override {
  539|      0|    int fd = ::open(filename.c_str(), O_TRUNC | O_WRONLY | O_CREAT, 0644);
  540|      0|    if (fd < 0) {
  541|      0|      *result = nullptr;
  542|      0|      return PosixError(filename, errno);
  543|      0|    }
  544|      0|
  545|      0|    *result = new PosixWritableFile(filename, fd);
  546|      0|    return Status::OK();
  547|      0|  }
  548|       |
  549|       |  Status NewAppendableFile(const std::string& filename,
  550|      0|                           WritableFile** result) override {
  551|      0|    int fd = ::open(filename.c_str(), O_APPEND | O_WRONLY | O_CREAT, 0644);
  552|      0|    if (fd < 0) {
  553|      0|      *result = nullptr;
  554|      0|      return PosixError(filename, errno);
  555|      0|    }
  556|      0|
  557|      0|    *result = new PosixWritableFile(filename, fd);
  558|      0|    return Status::OK();
  559|      0|  }
  560|       |
  561|      0|  bool FileExists(const std::string& filename) override {
  562|      0|    return ::access(filename.c_str(), F_OK) == 0;
  563|      0|  }
  564|       |
  565|       |  Status GetChildren(const std::string& directory_path,
  566|      0|                     std::vector<std::string>* result) override {
  567|      0|    result->clear();
  568|      0|    ::DIR* dir = ::opendir(directory_path.c_str());
  569|      0|    if (dir == nullptr) {
  570|      0|      return PosixError(directory_path, errno);
  571|      0|    }
  572|      0|    struct ::dirent* entry;
  573|      0|    while ((entry = ::readdir(dir)) != nullptr) {
  574|      0|      result->emplace_back(entry->d_name);
  575|      0|    }
  576|      0|    ::closedir(dir);
  577|      0|    return Status::OK();
  578|      0|  }
  579|       |
  580|      0|  Status DeleteFile(const std::string& filename) override {
  581|      0|    if (::unlink(filename.c_str()) != 0) {
  582|      0|      return PosixError(filename, errno);
  583|      0|    }
  584|      0|    return Status::OK();
  585|      0|  }
  586|       |
  587|      0|  Status CreateDir(const std::string& dirname) override {
  588|      0|    if (::mkdir(dirname.c_str(), 0755) != 0) {
  589|      0|      return PosixError(dirname, errno);
  590|      0|    }
  591|      0|    return Status::OK();
  592|      0|  }
  593|       |
  594|      0|  Status DeleteDir(const std::string& dirname) override {
  595|      0|    if (::rmdir(dirname.c_str()) != 0) {
  596|      0|      return PosixError(dirname, errno);
  597|      0|    }
  598|      0|    return Status::OK();
  599|      0|  }
  600|       |
  601|      0|  Status GetFileSize(const std::string& filename, uint64_t* size) override {
  602|      0|    struct ::stat file_stat;
  603|      0|    if (::stat(filename.c_str(), &file_stat) != 0) {
  604|      0|      *size = 0;
  605|      0|      return PosixError(filename, errno);
  606|      0|    }
  607|      0|    *size = file_stat.st_size;
  608|      0|    return Status::OK();
  609|      0|  }
  610|       |
  611|      0|  Status RenameFile(const std::string& from, const std::string& to) override {
  612|      0|    if (std::rename(from.c_str(), to.c_str()) != 0) {
  613|      0|      return PosixError(from, errno);
  614|      0|    }
  615|      0|    return Status::OK();
  616|      0|  }
  617|       |
  618|      0|  Status LockFile(const std::string& filename, FileLock** lock) override {
  619|      0|    *lock = nullptr;
  620|      0|
  621|      0|    int fd = ::open(filename.c_str(), O_RDWR | O_CREAT, 0644);
  622|      0|    if (fd < 0) {
  623|      0|      return PosixError(filename, errno);
  624|      0|    }
  625|      0|
  626|      0|    if (!locks_.Insert(filename)) {
  627|      0|      ::close(fd);
  628|      0|      return Status::IOError("lock " + filename, "already held by process");
  629|      0|    }
  630|      0|
  631|      0|    if (LockOrUnlock(fd, true) == -1) {
  632|      0|      int lock_errno = errno;
  633|      0|      ::close(fd);
  634|      0|      locks_.Remove(filename);
  635|      0|      return PosixError("lock " + filename, lock_errno);
  636|      0|    }
  637|      0|
  638|      0|    *lock = new PosixFileLock(fd, filename);
  639|      0|    return Status::OK();
  640|      0|  }
  641|       |
  642|      0|  Status UnlockFile(FileLock* lock) override {
  643|      0|    PosixFileLock* posix_file_lock = static_cast<PosixFileLock*>(lock);
  644|      0|    if (LockOrUnlock(posix_file_lock->fd(), false) == -1) {
  645|      0|      return PosixError("unlock " + posix_file_lock->filename(), errno);
  646|      0|    }
  647|      0|    locks_.Remove(posix_file_lock->filename());
  648|      0|    ::close(posix_file_lock->fd());
  649|      0|    delete posix_file_lock;
  650|      0|    return Status::OK();
  651|      0|  }
  652|       |
  653|       |  void Schedule(void (*background_work_function)(void* background_work_arg),
  654|       |                void* background_work_arg) override;
  655|       |
  656|       |  void StartThread(void (*thread_main)(void* thread_main_arg),
  657|       |                   void* thread_main_arg) override;
  658|       |
  659|      0|  Status GetTestDirectory(std::string* result) override {
  660|      0|    const char* env = std::getenv("TEST_TMPDIR");
  661|      0|    if (env && env[0] != '\0') {
  662|      0|      *result = env;
  663|      0|    } else {
  664|      0|      char buf[100];
  665|      0|      std::snprintf(buf, sizeof(buf), "/tmp/leveldbtest-%d",
  666|      0|                    static_cast<int>(::geteuid()));
  667|      0|      *result = buf;
  668|      0|    }
  669|      0|
  670|      0|    // The CreateDir status is ignored because the directory may already exist.
  671|      0|    CreateDir(*result);
  672|      0|
  673|      0|    return Status::OK();
  674|      0|  }
  675|       |
  676|      0|  Status NewLogger(const std::string& filename, Logger** result) override {
  677|      0|    std::FILE* fp = std::fopen(filename.c_str(), "w");
  678|      0|    if (fp == nullptr) {
  679|      0|      *result = nullptr;
  680|      0|      return PosixError(filename, errno);
  681|      0|    } else {
  682|      0|      *result = new PosixLogger(fp);
  683|      0|      return Status::OK();
  684|      0|    }
  685|      0|  }
  686|       |
  687|      0|  uint64_t NowMicros() override {
  688|      0|    static constexpr uint64_t kUsecondsPerSecond = 1000000;
  689|      0|    struct ::timeval tv;
  690|      0|    ::gettimeofday(&tv, nullptr);
  691|      0|    return static_cast<uint64_t>(tv.tv_sec) * kUsecondsPerSecond + tv.tv_usec;
  692|      0|  }
  693|       |
  694|      0|  void SleepForMicroseconds(int micros) override { ::usleep(micros); }
  695|       |
  696|       | private:
  697|       |  void BackgroundThreadMain();
  698|       |
  699|      0|  static void BackgroundThreadEntryPoint(PosixEnv* env) {
  700|      0|    env->BackgroundThreadMain();
  701|      0|  }
  702|       |
  703|       |  // Stores the work item data in a Schedule() call.
  704|       |  //
  705|       |  // Instances are constructed on the thread calling Schedule() and used on the
  706|       |  // background thread.
  707|       |  //
  708|       |  // This structure is thread-safe beacuse it is immutable.
  709|       |  struct BackgroundWorkItem {
  710|       |    explicit BackgroundWorkItem(void (*function)(void* arg), void* arg)
  711|      0|        : function(function), arg(arg) {}
  712|       |
  713|       |    void (*const function)(void*);
  714|       |    void* const arg;
  715|       |  };
  716|       |
  717|       |  port::Mutex background_work_mutex_;
  718|       |  port::CondVar background_work_cv_ GUARDED_BY(background_work_mutex_);
  719|       |  bool started_background_thread_ GUARDED_BY(background_work_mutex_);
  720|       |
  721|       |  std::queue<BackgroundWorkItem> background_work_queue_
  722|       |      GUARDED_BY(background_work_mutex_);
  723|       |
  724|       |  PosixLockTable locks_;  // Thread-safe.
  725|       |  Limiter mmap_limiter_;  // Thread-safe.
  726|       |  Limiter fd_limiter_;    // Thread-safe.
  727|       |};
  728|       |
  729|       |// Return the maximum number of concurrent mmaps.
  730|      0|int MaxMmaps() { return g_mmap_limit; }
  731|       |
  732|       |// Return the maximum number of read-only files to keep open.
  733|      0|int MaxOpenFiles() {
  734|      0|  if (g_open_read_only_file_limit >= 0) {
  735|      0|    return g_open_read_only_file_limit;
  736|      0|  }
  737|      0|  struct ::rlimit rlim;
  738|      0|  if (::getrlimit(RLIMIT_NOFILE, &rlim)) {
  739|      0|    // getrlimit failed, fallback to hard-coded default.
  740|      0|    g_open_read_only_file_limit = 50;
  741|      0|  } else if (rlim.rlim_cur == RLIM_INFINITY) {
  742|      0|    g_open_read_only_file_limit = std::numeric_limits<int>::max();
  743|      0|  } else {
  744|      0|    // Allow use of 20% of available file descriptors for read-only files.
  745|      0|    g_open_read_only_file_limit = rlim.rlim_cur / 5;
  746|      0|  }
  747|      0|  return g_open_read_only_file_limit;
  748|      0|}
  749|       |
  750|       |}  // namespace
  751|       |
  752|       |PosixEnv::PosixEnv()
  753|       |    : background_work_cv_(&background_work_mutex_),
  754|       |      started_background_thread_(false),
  755|       |      mmap_limiter_(MaxMmaps()),
  756|      0|      fd_limiter_(MaxOpenFiles()) {}
  757|       |
  758|       |void PosixEnv::Schedule(
  759|       |    void (*background_work_function)(void* background_work_arg),
  760|      0|    void* background_work_arg) {
  761|      0|  background_work_mutex_.Lock();
  762|      0|
  763|      0|  // Start the background thread, if we haven't done so already.
  764|      0|  if (!started_background_thread_) {
  765|      0|    started_background_thread_ = true;
  766|      0|    std::thread background_thread(PosixEnv::BackgroundThreadEntryPoint, this);
  767|      0|    background_thread.detach();
  768|      0|  }
  769|      0|
  770|      0|  // If the queue is empty, the background thread may be waiting for work.
  771|      0|  if (background_work_queue_.empty()) {
  772|      0|    background_work_cv_.Signal();
  773|      0|  }
  774|      0|
  775|      0|  background_work_queue_.emplace(background_work_function, background_work_arg);
  776|      0|  background_work_mutex_.Unlock();
  777|      0|}
  778|       |
  779|      0|void PosixEnv::BackgroundThreadMain() {
  780|      0|  while (true) {
  781|      0|    background_work_mutex_.Lock();
  782|      0|
  783|      0|    // Wait until there is work to be done.
  784|      0|    while (background_work_queue_.empty()) {
  785|      0|      background_work_cv_.Wait();
  786|      0|    }
  787|      0|
  788|      0|    assert(!background_work_queue_.empty());
  789|      0|    auto background_work_function = background_work_queue_.front().function;
  790|      0|    void* background_work_arg = background_work_queue_.front().arg;
  791|      0|    background_work_queue_.pop();
  792|      0|
  793|      0|    background_work_mutex_.Unlock();
  794|      0|    background_work_function(background_work_arg);
  795|      0|  }
  796|      0|}
  797|       |
  798|       |namespace {
  799|       |
  800|       |// Wraps an Env instance whose destructor is never created.
  801|       |//
  802|       |// Intended usage:
  803|       |//   using PlatformSingletonEnv = SingletonEnv<PlatformEnv>;
  804|       |//   void ConfigurePosixEnv(int param) {
  805|       |//     PlatformSingletonEnv::AssertEnvNotInitialized();
  806|       |//     // set global configuration flags.
  807|       |//   }
  808|       |//   Env* Env::Default() {
  809|       |//     static PlatformSingletonEnv default_env;
  810|       |//     return default_env.env();
  811|       |//   }
  812|       |template <typename EnvType>
  813|       |class SingletonEnv {
  814|       | public:
  815|      0|  SingletonEnv() {
  816|      0|#if !defined(NDEBUG)
  817|      0|    env_initialized_.store(true, std::memory_order::memory_order_relaxed);
  818|      0|#endif  // !defined(NDEBUG)
  819|      0|    static_assert(sizeof(env_storage_) >= sizeof(EnvType),
  820|      0|                  "env_storage_ will not fit the Env");
  821|      0|    static_assert(alignof(decltype(env_storage_)) >= alignof(EnvType),
  822|      0|                  "env_storage_ does not meet the Env's alignment needs");
  823|      0|    new (&env_storage_) EnvType();
  824|      0|  }
  825|       |  ~SingletonEnv() = default;
  826|       |
  827|       |  SingletonEnv(const SingletonEnv&) = delete;
  828|       |  SingletonEnv& operator=(const SingletonEnv&) = delete;
  829|       |
  830|      0|  Env* env() { return reinterpret_cast<Env*>(&env_storage_); }
  831|       |
  832|      0|  static void AssertEnvNotInitialized() {
  833|      0|#if !defined(NDEBUG)
  834|      0|    assert(!env_initialized_.load(std::memory_order::memory_order_relaxed));
  835|      0|#endif  // !defined(NDEBUG)
  836|      0|  }
  837|       |
  838|       | private:
  839|       |  typename std::aligned_storage<sizeof(EnvType), alignof(EnvType)>::type
  840|       |      env_storage_;
  841|       |#if !defined(NDEBUG)
  842|       |  static std::atomic<bool> env_initialized_;
  843|       |#endif  // !defined(NDEBUG)
  844|       |};
  845|       |
  846|       |#if !defined(NDEBUG)
  847|       |template <typename EnvType>
  848|       |std::atomic<bool> SingletonEnv<EnvType>::env_initialized_;
  849|       |#endif  // !defined(NDEBUG)
  850|       |
  851|       |using PosixDefaultEnv = SingletonEnv<PosixEnv>;
  852|       |
  853|       |}  // namespace
  854|       |
  855|       |void PosixEnv::StartThread(void (*thread_main)(void* thread_main_arg),
  856|      0|                           void* thread_main_arg) {
  857|      0|  std::thread new_thread(thread_main, thread_main_arg);
  858|      0|  new_thread.detach();
  859|      0|}
  860|       |
  861|      0|void EnvPosixTestHelper::SetReadOnlyFDLimit(int limit) {
  862|      0|  PosixDefaultEnv::AssertEnvNotInitialized();
  863|      0|  g_open_read_only_file_limit = limit;
  864|      0|}
  865|       |
  866|      0|void EnvPosixTestHelper::SetReadOnlyMMapLimit(int limit) {
  867|      0|  PosixDefaultEnv::AssertEnvNotInitialized();
  868|      0|  g_mmap_limit = limit;
  869|      0|}
  870|       |
  871|      0|Env* Env::Default() {
  872|      0|  static PosixDefaultEnv env_container;
  873|      0|  return env_container.env();
  874|      0|}
  875|       |
  876|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/filter_policy.cc:
    1|       |// Copyright (c) 2012 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "leveldb/filter_policy.h"
    6|       |
    7|       |namespace leveldb {
    8|       |
    9|      0|FilterPolicy::~FilterPolicy() {}
   10|       |
   11|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/hash.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "util/hash.h"
    6|       |
    7|       |#include <string.h>
    8|       |
    9|       |#include "util/coding.h"
   10|       |
   11|       |// The FALLTHROUGH_INTENDED macro can be used to annotate implicit fall-through
   12|       |// between switch labels. The real definition should be provided externally.
   13|       |// This one is a fallback version for unsupported compilers.
   14|       |#ifndef FALLTHROUGH_INTENDED
   15|       |#define FALLTHROUGH_INTENDED \
   16|      0|  do {                       \
   17|      0|  } while (0)
   18|       |#endif
   19|       |
   20|       |namespace leveldb {
   21|       |
   22|      0|uint32_t Hash(const char* data, size_t n, uint32_t seed) {
   23|      0|  // Similar to murmur hash
   24|      0|  const uint32_t m = 0xc6a4a793;
   25|      0|  const uint32_t r = 24;
   26|      0|  const char* limit = data + n;
   27|      0|  uint32_t h = seed ^ (n * m);
   28|      0|
   29|      0|  // Pick up four bytes at a time
   30|      0|  while (data + 4 <= limit) {
   31|      0|    uint32_t w = DecodeFixed32(data);
   32|      0|    data += 4;
   33|      0|    h += w;
   34|      0|    h *= m;
   35|      0|    h ^= (h >> 16);
   36|      0|  }
   37|      0|
   38|      0|  // Pick up remaining bytes
   39|      0|  switch (limit - data) {
   40|      0|    case 3:
   41|      0|      h += static_cast<unsigned char>(data[2]) << 16;
   42|      0|      FALLTHROUGH_INTENDED;
   43|      0|    case 2:
   44|      0|      h += static_cast<unsigned char>(data[1]) << 8;
   45|      0|      FALLTHROUGH_INTENDED;
   46|      0|    case 1:
   47|      0|      h += static_cast<unsigned char>(data[0]);
   48|      0|      h *= m;
   49|      0|      h ^= (h >> r);
   50|      0|      break;
   51|      0|  }
   52|      0|  return h;
   53|      0|}
   54|       |
   55|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/histogram.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "util/histogram.h"
    6|       |
    7|       |#include <math.h>
    8|       |#include <stdio.h>
    9|       |
   10|       |#include "port/port.h"
   11|       |
   12|       |namespace leveldb {
   13|       |
   14|       |const double Histogram::kBucketLimit[kNumBuckets] = {
   15|       |    1,
   16|       |    2,
   17|       |    3,
   18|       |    4,
   19|       |    5,
   20|       |    6,
   21|       |    7,
   22|       |    8,
   23|       |    9,
   24|       |    10,
   25|       |    12,
   26|       |    14,
   27|       |    16,
   28|       |    18,
   29|       |    20,
   30|       |    25,
   31|       |    30,
   32|       |    35,
   33|       |    40,
   34|       |    45,
   35|       |    50,
   36|       |    60,
   37|       |    70,
   38|       |    80,
   39|       |    90,
   40|       |    100,
   41|       |    120,
   42|       |    140,
   43|       |    160,
   44|       |    180,
   45|       |    200,
   46|       |    250,
   47|       |    300,
   48|       |    350,
   49|       |    400,
   50|       |    450,
   51|       |    500,
   52|       |    600,
   53|       |    700,
   54|       |    800,
   55|       |    900,
   56|       |    1000,
   57|       |    1200,
   58|       |    1400,
   59|       |    1600,
   60|       |    1800,
   61|       |    2000,
   62|       |    2500,
   63|       |    3000,
   64|       |    3500,
   65|       |    4000,
   66|       |    4500,
   67|       |    5000,
   68|       |    6000,
   69|       |    7000,
   70|       |    8000,
   71|       |    9000,
   72|       |    10000,
   73|       |    12000,
   74|       |    14000,
   75|       |    16000,
   76|       |    18000,
   77|       |    20000,
   78|       |    25000,
   79|       |    30000,
   80|       |    35000,
   81|       |    40000,
   82|       |    45000,
   83|       |    50000,
   84|       |    60000,
   85|       |    70000,
   86|       |    80000,
   87|       |    90000,
   88|       |    100000,
   89|       |    120000,
   90|       |    140000,
   91|       |    160000,
   92|       |    180000,
   93|       |    200000,
   94|       |    250000,
   95|       |    300000,
   96|       |    350000,
   97|       |    400000,
   98|       |    450000,
   99|       |    500000,
  100|       |    600000,
  101|       |    700000,
  102|       |    800000,
  103|       |    900000,
  104|       |    1000000,
  105|       |    1200000,
  106|       |    1400000,
  107|       |    1600000,
  108|       |    1800000,
  109|       |    2000000,
  110|       |    2500000,
  111|       |    3000000,
  112|       |    3500000,
  113|       |    4000000,
  114|       |    4500000,
  115|       |    5000000,
  116|       |    6000000,
  117|       |    7000000,
  118|       |    8000000,
  119|       |    9000000,
  120|       |    10000000,
  121|       |    12000000,
  122|       |    14000000,
  123|       |    16000000,
  124|       |    18000000,
  125|       |    20000000,
  126|       |    25000000,
  127|       |    30000000,
  128|       |    35000000,
  129|       |    40000000,
  130|       |    45000000,
  131|       |    50000000,
  132|       |    60000000,
  133|       |    70000000,
  134|       |    80000000,
  135|       |    90000000,
  136|       |    100000000,
  137|       |    120000000,
  138|       |    140000000,
  139|       |    160000000,
  140|       |    180000000,
  141|       |    200000000,
  142|       |    250000000,
  143|       |    300000000,
  144|       |    350000000,
  145|       |    400000000,
  146|       |    450000000,
  147|       |    500000000,
  148|       |    600000000,
  149|       |    700000000,
  150|       |    800000000,
  151|       |    900000000,
  152|       |    1000000000,
  153|       |    1200000000,
  154|       |    1400000000,
  155|       |    1600000000,
  156|       |    1800000000,
  157|       |    2000000000,
  158|       |    2500000000.0,
  159|       |    3000000000.0,
  160|       |    3500000000.0,
  161|       |    4000000000.0,
  162|       |    4500000000.0,
  163|       |    5000000000.0,
  164|       |    6000000000.0,
  165|       |    7000000000.0,
  166|       |    8000000000.0,
  167|       |    9000000000.0,
  168|       |    1e200,
  169|       |};
  170|       |
  171|      0|void Histogram::Clear() {
  172|      0|  min_ = kBucketLimit[kNumBuckets - 1];
  173|      0|  max_ = 0;
  174|      0|  num_ = 0;
  175|      0|  sum_ = 0;
  176|      0|  sum_squares_ = 0;
  177|      0|  for (int i = 0; i < kNumBuckets; i++) {
  178|      0|    buckets_[i] = 0;
  179|      0|  }
  180|      0|}
  181|       |
  182|      0|void Histogram::Add(double value) {
  183|      0|  // Linear search is fast enough for our usage in db_bench
  184|      0|  int b = 0;
  185|      0|  while (b < kNumBuckets - 1 && kBucketLimit[b] <= value) {
  186|      0|    b++;
  187|      0|  }
  188|      0|  buckets_[b] += 1.0;
  189|      0|  if (min_ > value) min_ = value;
  190|      0|  if (max_ < value) max_ = value;
  191|      0|  num_++;
  192|      0|  sum_ += value;
  193|      0|  sum_squares_ += (value * value);
  194|      0|}
  195|       |
  196|      0|void Histogram::Merge(const Histogram& other) {
  197|      0|  if (other.min_ < min_) min_ = other.min_;
  198|      0|  if (other.max_ > max_) max_ = other.max_;
  199|      0|  num_ += other.num_;
  200|      0|  sum_ += other.sum_;
  201|      0|  sum_squares_ += other.sum_squares_;
  202|      0|  for (int b = 0; b < kNumBuckets; b++) {
  203|      0|    buckets_[b] += other.buckets_[b];
  204|      0|  }
  205|      0|}
  206|       |
  207|      0|double Histogram::Median() const { return Percentile(50.0); }
  208|       |
  209|      0|double Histogram::Percentile(double p) const {
  210|      0|  double threshold = num_ * (p / 100.0);
  211|      0|  double sum = 0;
  212|      0|  for (int b = 0; b < kNumBuckets; b++) {
  213|      0|    sum += buckets_[b];
  214|      0|    if (sum >= threshold) {
  215|      0|      // Scale linearly within this bucket
  216|      0|      double left_point = (b == 0) ? 0 : kBucketLimit[b - 1];
  217|      0|      double right_point = kBucketLimit[b];
  218|      0|      double left_sum = sum - buckets_[b];
  219|      0|      double right_sum = sum;
  220|      0|      double pos = (threshold - left_sum) / (right_sum - left_sum);
  221|      0|      double r = left_point + (right_point - left_point) * pos;
  222|      0|      if (r < min_) r = min_;
  223|      0|      if (r > max_) r = max_;
  224|      0|      return r;
  225|      0|    }
  226|      0|  }
  227|      0|  return max_;
  228|      0|}
  229|       |
  230|      0|double Histogram::Average() const {
  231|      0|  if (num_ == 0.0) return 0;
  232|      0|  return sum_ / num_;
  233|      0|}
  234|       |
  235|      0|double Histogram::StandardDeviation() const {
  236|      0|  if (num_ == 0.0) return 0;
  237|      0|  double variance = (sum_squares_ * num_ - sum_ * sum_) / (num_ * num_);
  238|      0|  return sqrt(variance);
  239|      0|}
  240|       |
  241|      0|std::string Histogram::ToString() const {
  242|      0|  std::string r;
  243|      0|  char buf[200];
  244|      0|  snprintf(buf, sizeof(buf), "Count: %.0f  Average: %.4f  StdDev: %.2f\n", num_,
  245|      0|           Average(), StandardDeviation());
  246|      0|  r.append(buf);
  247|      0|  snprintf(buf, sizeof(buf), "Min: %.4f  Median: %.4f  Max: %.4f\n",
  248|      0|           (num_ == 0.0 ? 0.0 : min_), Median(), max_);
  249|      0|  r.append(buf);
  250|      0|  r.append("------------------------------------------------------\n");
  251|      0|  const double mult = 100.0 / num_;
  252|      0|  double sum = 0;
  253|      0|  for (int b = 0; b < kNumBuckets; b++) {
  254|      0|    if (buckets_[b] <= 0.0) continue;
  255|      0|    sum += buckets_[b];
  256|      0|    snprintf(buf, sizeof(buf), "[ %7.0f, %7.0f ) %7.0f %7.3f%% %7.3f%% ",
  257|      0|             ((b == 0) ? 0.0 : kBucketLimit[b - 1]),  // left
  258|      0|             kBucketLimit[b],                         // right
  259|      0|             buckets_[b],                             // count
  260|      0|             mult * buckets_[b],                      // percentage
  261|      0|             mult * sum);                             // cumulative percentage
  262|      0|    r.append(buf);
  263|      0|
  264|      0|    // Add hash marks based on percentage; 20 marks for 100%.
  265|      0|    int marks = static_cast<int>(20 * (buckets_[b] / num_) + 0.5);
  266|      0|    r.append(marks, '#');
  267|      0|    r.push_back('\n');
  268|      0|  }
  269|      0|  return r;
  270|      0|}
  271|       |
  272|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/histogram.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_UTIL_HISTOGRAM_H_
    6|       |#define STORAGE_LEVELDB_UTIL_HISTOGRAM_H_
    7|       |
    8|       |#include <string>
    9|       |
   10|       |namespace leveldb {
   11|       |
   12|       |class Histogram {
   13|       | public:
   14|      0|  Histogram() {}
   15|      0|  ~Histogram() {}
   16|       |
   17|       |  void Clear();
   18|       |  void Add(double value);
   19|       |  void Merge(const Histogram& other);
   20|       |
   21|       |  std::string ToString() const;
   22|       |
   23|       | private:
   24|       |  enum { kNumBuckets = 154 };
   25|       |
   26|       |  double Median() const;
   27|       |  double Percentile(double p) const;
   28|       |  double Average() const;
   29|       |  double StandardDeviation() const;
   30|       |
   31|       |  static const double kBucketLimit[kNumBuckets];
   32|       |
   33|       |  double min_;
   34|       |  double max_;
   35|       |  double num_;
   36|       |  double sum_;
   37|       |  double sum_squares_;
   38|       |
   39|       |  double buckets_[kNumBuckets];
   40|       |};
   41|       |
   42|       |}  // namespace leveldb
   43|       |
   44|       |#endif  // STORAGE_LEVELDB_UTIL_HISTOGRAM_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/logging.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "util/logging.h"
    6|       |
    7|       |#include <errno.h>
    8|       |#include <stdarg.h>
    9|       |#include <stdio.h>
   10|       |#include <stdlib.h>
   11|       |
   12|       |#include <limits>
   13|       |
   14|       |#include "leveldb/env.h"
   15|       |#include "leveldb/slice.h"
   16|       |
   17|       |namespace leveldb {
   18|       |
   19|      0|void AppendNumberTo(std::string* str, uint64_t num) {
   20|      0|  char buf[30];
   21|      0|  snprintf(buf, sizeof(buf), "%llu", (unsigned long long)num);
   22|      0|  str->append(buf);
   23|      0|}
   24|       |
   25|      0|void AppendEscapedStringTo(std::string* str, const Slice& value) {
   26|      0|  for (size_t i = 0; i < value.size(); i++) {
   27|      0|    char c = value[i];
   28|      0|    if (c >= ' ' && c <= '~') {
   29|      0|      str->push_back(c);
   30|      0|    } else {
   31|      0|      char buf[10];
   32|      0|      snprintf(buf, sizeof(buf), "\\x%02x",
   33|      0|               static_cast<unsigned int>(c) & 0xff);
   34|      0|      str->append(buf);
   35|      0|    }
   36|      0|  }
   37|      0|}
   38|       |
   39|      0|std::string NumberToString(uint64_t num) {
   40|      0|  std::string r;
   41|      0|  AppendNumberTo(&r, num);
   42|      0|  return r;
   43|      0|}
   44|       |
   45|      0|std::string EscapeString(const Slice& value) {
   46|      0|  std::string r;
   47|      0|  AppendEscapedStringTo(&r, value);
   48|      0|  return r;
   49|      0|}
   50|       |
   51|      0|bool ConsumeDecimalNumber(Slice* in, uint64_t* val) {
   52|      0|  // Constants that will be optimized away.
   53|      0|  constexpr const uint64_t kMaxUint64 = std::numeric_limits<uint64_t>::max();
   54|      0|  constexpr const char kLastDigitOfMaxUint64 =
   55|      0|      '0' + static_cast<char>(kMaxUint64 % 10);
   56|      0|
   57|      0|  uint64_t value = 0;
   58|      0|
   59|      0|  // reinterpret_cast-ing from char* to unsigned char* to avoid signedness.
   60|      0|  const unsigned char* start =
   61|      0|      reinterpret_cast<const unsigned char*>(in->data());
   62|      0|
   63|      0|  const unsigned char* end = start + in->size();
   64|      0|  const unsigned char* current = start;
   65|      0|  for (; current != end; ++current) {
   66|      0|    const unsigned char ch = *current;
   67|      0|    if (ch < '0' || ch > '9') break;
   68|      0|
   69|      0|    // Overflow check.
   70|      0|    // kMaxUint64 / 10 is also constant and will be optimized away.
   71|      0|    if (value > kMaxUint64 / 10 ||
   72|      0|        (value == kMaxUint64 / 10 && ch > kLastDigitOfMaxUint64)) {
   73|      0|      return false;
   74|      0|    }
   75|      0|
   76|      0|    value = (value * 10) + (ch - '0');
   77|      0|  }
   78|      0|
   79|      0|  *val = value;
   80|      0|  const size_t digits_consumed = current - start;
   81|      0|  in->remove_prefix(digits_consumed);
   82|      0|  return digits_consumed != 0;
   83|      0|}
   84|       |
   85|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/mutexlock.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_UTIL_MUTEXLOCK_H_
    6|       |#define STORAGE_LEVELDB_UTIL_MUTEXLOCK_H_
    7|       |
    8|       |#include "port/port.h"
    9|       |#include "port/thread_annotations.h"
   10|       |
   11|       |namespace leveldb {
   12|       |
   13|       |// Helper class that locks a mutex on construction and unlocks the mutex when
   14|       |// the destructor of the MutexLock object is invoked.
   15|       |//
   16|       |// Typical usage:
   17|       |//
   18|       |//   void MyClass::MyMethod() {
   19|       |//     MutexLock l(&mu_);       // mu_ is an instance variable
   20|       |//     ... some complex code, possibly with multiple return paths ...
   21|       |//   }
   22|       |
   23|       |class SCOPED_LOCKABLE MutexLock {
   24|       | public:
   25|      0|  explicit MutexLock(port::Mutex* mu) EXCLUSIVE_LOCK_FUNCTION(mu) : mu_(mu) {
   26|      0|    this->mu_->Lock();
   27|      0|  }
   28|      0|  ~MutexLock() UNLOCK_FUNCTION() { this->mu_->Unlock(); }
   29|       |
   30|       |  MutexLock(const MutexLock&) = delete;
   31|       |  MutexLock& operator=(const MutexLock&) = delete;
   32|       |
   33|       | private:
   34|       |  port::Mutex* const mu_;
   35|       |};
   36|       |
   37|       |}  // namespace leveldb
   38|       |
   39|       |#endif  // STORAGE_LEVELDB_UTIL_MUTEXLOCK_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/no_destructor.h:
    1|       |// Copyright (c) 2018 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_UTIL_NO_DESTRUCTOR_H_
    6|       |#define STORAGE_LEVELDB_UTIL_NO_DESTRUCTOR_H_
    7|       |
    8|       |#include <type_traits>
    9|       |#include <utility>
   10|       |
   11|       |namespace leveldb {
   12|       |
   13|       |// Wraps an instance whose destructor is never called.
   14|       |//
   15|       |// This is intended for use with function-level static variables.
   16|       |template <typename InstanceType>
   17|       |class NoDestructor {
   18|       | public:
   19|       |  template <typename... ConstructorArgTypes>
   20|      0|  explicit NoDestructor(ConstructorArgTypes&&... constructor_args) {
   21|      0|    static_assert(sizeof(instance_storage_) >= sizeof(InstanceType),
   22|      0|                  "instance_storage_ is not large enough to hold the instance");
   23|      0|    static_assert(
   24|      0|        alignof(decltype(instance_storage_)) >= alignof(InstanceType),
   25|      0|        "instance_storage_ does not meet the instance's alignment requirement");
   26|      0|    new (&instance_storage_)
   27|      0|        InstanceType(std::forward<ConstructorArgTypes>(constructor_args)...);
   28|      0|  }
   29|       |
   30|       |  ~NoDestructor() = default;
   31|       |
   32|       |  NoDestructor(const NoDestructor&) = delete;
   33|       |  NoDestructor& operator=(const NoDestructor&) = delete;
   34|       |
   35|      0|  InstanceType* get() {
   36|      0|    return reinterpret_cast<InstanceType*>(&instance_storage_);
   37|      0|  }
   38|       |
   39|       | private:
   40|       |  typename std::aligned_storage<sizeof(InstanceType),
   41|       |                                alignof(InstanceType)>::type instance_storage_;
   42|       |};
   43|       |
   44|       |}  // namespace leveldb
   45|       |
   46|       |#endif  // STORAGE_LEVELDB_UTIL_NO_DESTRUCTOR_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/options.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "leveldb/options.h"
    6|       |
    7|       |#include "leveldb/comparator.h"
    8|       |#include "leveldb/env.h"
    9|       |
   10|       |namespace leveldb {
   11|       |
   12|      0|Options::Options() : comparator(BytewiseComparator()), env(Env::Default()) {}
   13|       |
   14|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/posix_logger.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |//
    5|       |// Logger implementation that can be shared by all environments
    6|       |// where enough posix functionality is available.
    7|       |
    8|       |#ifndef STORAGE_LEVELDB_UTIL_POSIX_LOGGER_H_
    9|       |#define STORAGE_LEVELDB_UTIL_POSIX_LOGGER_H_
   10|       |
   11|       |#include <sys/time.h>
   12|       |
   13|       |#include <cassert>
   14|       |#include <cstdarg>
   15|       |#include <cstdio>
   16|       |#include <ctime>
   17|       |#include <sstream>
   18|       |#include <thread>
   19|       |
   20|       |#include "leveldb/env.h"
   21|       |
   22|       |namespace leveldb {
   23|       |
   24|       |class PosixLogger final : public Logger {
   25|       | public:
   26|       |  // Creates a logger that writes to the given file.
   27|       |  //
   28|       |  // The PosixLogger instance takes ownership of the file handle.
   29|      0|  explicit PosixLogger(std::FILE* fp) : fp_(fp) { assert(fp != nullptr); }
   30|       |
   31|      0|  ~PosixLogger() override { std::fclose(fp_); }
   32|       |
   33|      0|  void Logv(const char* format, va_list arguments) override {
   34|      0|    // Record the time as close to the Logv() call as possible.
   35|      0|    struct ::timeval now_timeval;
   36|      0|    ::gettimeofday(&now_timeval, nullptr);
   37|      0|    const std::time_t now_seconds = now_timeval.tv_sec;
   38|      0|    struct std::tm now_components;
   39|      0|    ::localtime_r(&now_seconds, &now_components);
   40|      0|
   41|      0|    // Record the thread ID.
   42|      0|    constexpr const int kMaxThreadIdSize = 32;
   43|      0|    std::ostringstream thread_stream;
   44|      0|    thread_stream << std::this_thread::get_id();
   45|      0|    std::string thread_id = thread_stream.str();
   46|      0|    if (thread_id.size() > kMaxThreadIdSize) {
   47|      0|      thread_id.resize(kMaxThreadIdSize);
   48|      0|    }
   49|      0|
   50|      0|    // We first attempt to print into a stack-allocated buffer. If this attempt
   51|      0|    // fails, we make a second attempt with a dynamically allocated buffer.
   52|      0|    constexpr const int kStackBufferSize = 512;
   53|      0|    char stack_buffer[kStackBufferSize];
   54|      0|    static_assert(sizeof(stack_buffer) == static_cast<size_t>(kStackBufferSize),
   55|      0|                  "sizeof(char) is expected to be 1 in C++");
   56|      0|
   57|      0|    int dynamic_buffer_size = 0;  // Computed in the first iteration.
   58|      0|    for (int iteration = 0; iteration < 2; ++iteration) {
   59|      0|      const int buffer_size =
   60|      0|          (iteration == 0) ? kStackBufferSize : dynamic_buffer_size;
   61|      0|      char* const buffer =
   62|      0|          (iteration == 0) ? stack_buffer : new char[dynamic_buffer_size];
   63|      0|
   64|      0|      // Print the header into the buffer.
   65|      0|      int buffer_offset = snprintf(
   66|      0|          buffer, buffer_size, "%04d/%02d/%02d-%02d:%02d:%02d.%06d %s ",
   67|      0|          now_components.tm_year + 1900, now_components.tm_mon + 1,
   68|      0|          now_components.tm_mday, now_components.tm_hour, now_components.tm_min,
   69|      0|          now_components.tm_sec, static_cast<int>(now_timeval.tv_usec),
   70|      0|          thread_id.c_str());
   71|      0|
   72|      0|      // The header can be at most 28 characters (10 date + 15 time +
   73|      0|      // 3 delimiters) plus the thread ID, which should fit comfortably into the
   74|      0|      // static buffer.
   75|      0|      assert(buffer_offset <= 28 + kMaxThreadIdSize);
   76|      0|      static_assert(28 + kMaxThreadIdSize < kStackBufferSize,
   77|      0|                    "stack-allocated buffer may not fit the message header");
   78|      0|      assert(buffer_offset < buffer_size);
   79|      0|
   80|      0|      // Print the message into the buffer.
   81|      0|      std::va_list arguments_copy;
   82|      0|      va_copy(arguments_copy, arguments);
   83|      0|      buffer_offset +=
   84|      0|          std::vsnprintf(buffer + buffer_offset, buffer_size - buffer_offset,
   85|      0|                         format, arguments_copy);
   86|      0|      va_end(arguments_copy);
   87|      0|
   88|      0|      // The code below may append a newline at the end of the buffer, which
   89|      0|      // requires an extra character.
   90|      0|      if (buffer_offset >= buffer_size - 1) {
   91|      0|        // The message did not fit into the buffer.
   92|      0|        if (iteration == 0) {
   93|      0|          // Re-run the loop and use a dynamically-allocated buffer. The buffer
   94|      0|          // will be large enough for the log message, an extra newline and a
   95|      0|          // null terminator.
   96|      0|          dynamic_buffer_size = buffer_offset + 2;
   97|      0|          continue;
   98|      0|        }
   99|      0|
  100|      0|        // The dynamically-allocated buffer was incorrectly sized. This should
  101|      0|        // not happen, assuming a correct implementation of (v)snprintf. Fail
  102|      0|        // in tests, recover by truncating the log message in production.
  103|      0|        assert(false);
  104|      0|        buffer_offset = buffer_size - 1;
  105|      0|      }
  106|      0|
  107|      0|      // Add a newline if necessary.
  108|      0|      if (buffer[buffer_offset - 1] != '\n') {
  109|      0|        buffer[buffer_offset] = '\n';
  110|      0|        ++buffer_offset;
  111|      0|      }
  112|      0|
  113|      0|      assert(buffer_offset <= buffer_size);
  114|      0|      std::fwrite(buffer, 1, buffer_offset, fp_);
  115|      0|      std::fflush(fp_);
  116|      0|
  117|      0|      if (iteration != 0) {
  118|      0|        delete[] buffer;
  119|      0|      }
  120|      0|      break;
  121|      0|    }
  122|      0|  }
  123|       |
  124|       | private:
  125|       |  std::FILE* const fp_;
  126|       |};
  127|       |
  128|       |}  // namespace leveldb
  129|       |
  130|       |#endif  // STORAGE_LEVELDB_UTIL_POSIX_LOGGER_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/random.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_UTIL_RANDOM_H_
    6|       |#define STORAGE_LEVELDB_UTIL_RANDOM_H_
    7|       |
    8|       |#include <stdint.h>
    9|       |
   10|       |namespace leveldb {
   11|       |
   12|       |// A very simple random number generator.  Not especially good at
   13|       |// generating truly random bits, but good enough for our needs in this
   14|       |// package.
   15|       |class Random {
   16|       | private:
   17|       |  uint32_t seed_;
   18|       |
   19|       | public:
   20|      0|  explicit Random(uint32_t s) : seed_(s & 0x7fffffffu) {
   21|      0|    // Avoid bad seeds.
   22|      0|    if (seed_ == 0 || seed_ == 2147483647L) {
   23|      0|      seed_ = 1;
   24|      0|    }
   25|      0|  }
   26|      0|  uint32_t Next() {
   27|      0|    static const uint32_t M = 2147483647L;  // 2^31-1
   28|      0|    static const uint64_t A = 16807;        // bits 14, 8, 7, 5, 2, 1, 0
   29|      0|    // We are computing
   30|      0|    //       seed_ = (seed_ * A) % M,    where M = 2^31-1
   31|      0|    //
   32|      0|    // seed_ must not be zero or M, or else all subsequent computed values
   33|      0|    // will be zero or M respectively.  For all other values, seed_ will end
   34|      0|    // up cycling through every number in [1,M-1]
   35|      0|    uint64_t product = seed_ * A;
   36|      0|
   37|      0|    // Compute (product % M) using the fact that ((x << 31) % M) == x.
   38|      0|    seed_ = static_cast<uint32_t>((product >> 31) + (product & M));
   39|      0|    // The first reduction may overflow by 1 bit, so we may need to
   40|      0|    // repeat.  mod == M is not possible; using > allows the faster
   41|      0|    // sign-bit-based test.
   42|      0|    if (seed_ > M) {
   43|      0|      seed_ -= M;
   44|      0|    }
   45|      0|    return seed_;
   46|      0|  }
   47|       |  // Returns a uniformly distributed value in the range [0..n-1]
   48|       |  // REQUIRES: n > 0
   49|      0|  uint32_t Uniform(int n) { return Next() % n; }
   50|       |
   51|       |  // Randomly returns true ~"1/n" of the time, and false otherwise.
   52|       |  // REQUIRES: n > 0
   53|      0|  bool OneIn(int n) { return (Next() % n) == 0; }
   54|       |
   55|       |  // Skewed: pick "base" uniformly from range [0,max_log] and then
   56|       |  // return "base" random bits.  The effect is to pick a number in the
   57|       |  // range [0,2^max_log-1] with exponential bias towards smaller numbers.
   58|      0|  uint32_t Skewed(int max_log) { return Uniform(1 << Uniform(max_log + 1)); }
   59|       |};
   60|       |
   61|       |}  // namespace leveldb
   62|       |
   63|       |#endif  // STORAGE_LEVELDB_UTIL_RANDOM_H_

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/status.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "leveldb/status.h"
    6|       |
    7|       |#include <stdio.h>
    8|       |
    9|       |#include "port/port.h"
   10|       |
   11|       |namespace leveldb {
   12|       |
   13|      0|const char* Status::CopyState(const char* state) {
   14|      0|  uint32_t size;
   15|      0|  memcpy(&size, state, sizeof(size));
   16|      0|  char* result = new char[size + 5];
   17|      0|  memcpy(result, state, size + 5);
   18|      0|  return result;
   19|      0|}
   20|       |
   21|      0|Status::Status(Code code, const Slice& msg, const Slice& msg2) {
   22|      0|  assert(code != kOk);
   23|      0|  const uint32_t len1 = msg.size();
   24|      0|  const uint32_t len2 = msg2.size();
   25|      0|  const uint32_t size = len1 + (len2 ? (2 + len2) : 0);
   26|      0|  char* result = new char[size + 5];
   27|      0|  memcpy(result, &size, sizeof(size));
   28|      0|  result[4] = static_cast<char>(code);
   29|      0|  memcpy(result + 5, msg.data(), len1);
   30|      0|  if (len2) {
   31|      0|    result[5 + len1] = ':';
   32|      0|    result[6 + len1] = ' ';
   33|      0|    memcpy(result + 7 + len1, msg2.data(), len2);
   34|      0|  }
   35|      0|  state_ = result;
   36|      0|}
   37|       |
   38|      0|std::string Status::ToString() const {
   39|      0|  if (state_ == nullptr) {
   40|      0|    return "OK";
   41|      0|  } else {
   42|      0|    char tmp[30];
   43|      0|    const char* type;
   44|      0|    switch (code()) {
   45|      0|      case kOk:
   46|      0|        type = "OK";
   47|      0|        break;
   48|      0|      case kNotFound:
   49|      0|        type = "NotFound: ";
   50|      0|        break;
   51|      0|      case kCorruption:
   52|      0|        type = "Corruption: ";
   53|      0|        break;
   54|      0|      case kNotSupported:
   55|      0|        type = "Not implemented: ";
   56|      0|        break;
   57|      0|      case kInvalidArgument:
   58|      0|        type = "Invalid argument: ";
   59|      0|        break;
   60|      0|      case kIOError:
   61|      0|        type = "IO error: ";
   62|      0|        break;
   63|      0|      default:
   64|      0|        snprintf(tmp, sizeof(tmp),
   65|      0|                 "Unknown code(%d): ", static_cast<int>(code()));
   66|      0|        type = tmp;
   67|      0|        break;
   68|      0|    }
   69|      0|    std::string result(type);
   70|      0|    uint32_t length;
   71|      0|    memcpy(&length, state_, sizeof(length));
   72|      0|    result.append(state_ + 5, length);
   73|      0|    return result;
   74|      0|  }
   75|      0|}
   76|       |
   77|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/testharness.cc:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#include "util/testharness.h"
    6|       |
    7|       |#include <stdlib.h>
    8|       |#include <sys/stat.h>
    9|       |#include <sys/types.h>
   10|       |
   11|       |#include <string>
   12|       |#include <vector>
   13|       |
   14|       |#include "leveldb/env.h"
   15|       |
   16|       |namespace leveldb {
   17|       |namespace test {
   18|       |
   19|       |namespace {
   20|       |struct Test {
   21|       |  const char* base;
   22|       |  const char* name;
   23|       |  void (*func)();
   24|       |};
   25|       |std::vector<Test>* tests;
   26|       |}  // namespace
   27|       |
   28|      0|bool RegisterTest(const char* base, const char* name, void (*func)()) {
   29|      0|  if (tests == nullptr) {
   30|      0|    tests = new std::vector<Test>;
   31|      0|  }
   32|      0|  Test t;
   33|      0|  t.base = base;
   34|      0|  t.name = name;
   35|      0|  t.func = func;
   36|      0|  tests->push_back(t);
   37|      0|  return true;
   38|      0|}
   39|       |
   40|      0|int RunAllTests() {
   41|      0|  const char* matcher = getenv("LEVELDB_TESTS");
   42|      0|
   43|      0|  int num = 0;
   44|      0|  if (tests != nullptr) {
   45|      0|    for (size_t i = 0; i < tests->size(); i++) {
   46|      0|      const Test& t = (*tests)[i];
   47|      0|      if (matcher != nullptr) {
   48|      0|        std::string name = t.base;
   49|      0|        name.push_back('.');
   50|      0|        name.append(t.name);
   51|      0|        if (strstr(name.c_str(), matcher) == nullptr) {
   52|      0|          continue;
   53|      0|        }
   54|      0|      }
   55|      0|      fprintf(stderr, "==== Test %s.%s\n", t.base, t.name);
   56|      0|      (*t.func)();
   57|      0|      ++num;
   58|      0|    }
   59|      0|  }
   60|      0|  fprintf(stderr, "==== PASSED %d tests\n", num);
   61|      0|  return 0;
   62|      0|}
   63|       |
   64|      0|std::string TmpDir() {
   65|      0|  std::string dir;
   66|      0|  Status s = Env::Default()->GetTestDirectory(&dir);
   67|      0|  ASSERT_TRUE(s.ok()) << s.ToString();
   68|      0|  return dir;
   69|      0|}
   70|       |
   71|      0|int RandomSeed() {
   72|      0|  const char* env = getenv("TEST_RANDOM_SEED");
   73|      0|  int result = (env != nullptr ? atoi(env) : 301);
   74|      0|  if (result <= 0) {
   75|      0|    result = 301;
   76|      0|  }
   77|      0|  return result;
   78|      0|}
   79|       |
   80|       |}  // namespace test
   81|       |}  // namespace leveldb

/Users/aafraneokese/Documents/Learn IoS Features/Functionality/Architecture /MVVM Example/LoginDemo/Pods/leveldb-library/util/testharness.h:
    1|       |// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
    2|       |// Use of this source code is governed by a BSD-style license that can be
    3|       |// found in the LICENSE file. See the AUTHORS file for names of contributors.
    4|       |
    5|       |#ifndef STORAGE_LEVELDB_UTIL_TESTHARNESS_H_
    6|       |#define STORAGE_LEVELDB_UTIL_TESTHARNESS_H_
    7|       |
    8|       |#include <stdio.h>
    9|       |#include <stdlib.h>
   10|       |
   11|       |#include <sstream>
   12|       |
   13|       |#include "leveldb/status.h"
   14|       |
   15|       |namespace leveldb {
   16|       |namespace test {
   17|       |
   18|       |// Run some of the tests registered by the TEST() macro.  If the
   19|       |// environment variable "LEVELDB_TESTS" is not set, runs all tests.
   20|       |// Otherwise, runs only the tests whose name contains the value of
   21|       |// "LEVELDB_TESTS" as a substring.  E.g., suppose the tests are:
   22|       |//    TEST(Foo, Hello) { ... }
   23|       |//    TEST(Foo, World) { ... }
   24|       |// LEVELDB_TESTS=Hello will run the first test
   25|       |// LEVELDB_TESTS=o     will run both tests
   26|       |// LEVELDB_TESTS=Junk  will run no tests
   27|       |//
   28|       |// Returns 0 if all tests pass.
   29|       |// Dies or returns a non-zero value if some test fails.
   30|       |int RunAllTests();
   31|       |
   32|       |// Return the directory to use for temporary storage.
   33|       |std::string TmpDir();
   34|       |
   35|       |// Return a randomization seed for this run.  Typically returns the
   36|       |// same number on repeated invocations of this binary, but automated
   37|       |// runs may be able to vary the seed.
   38|       |int RandomSeed();
   39|       |
   40|       |// An instance of Tester is allocated to hold temporary state during
   41|       |// the execution of an assertion.
   42|       |class Tester {
   43|       | private:
   44|       |  bool ok_;
   45|       |  const char* fname_;
   46|       |  int line_;
   47|       |  std::stringstream ss_;
   48|       |
   49|       | public:
   50|      0|  Tester(const char* f, int l) : ok_(true), fname_(f), line_(l) {}
   51|       |
   52|      0|  ~Tester() {
   53|      0|    if (!ok_) {
   54|      0|      fprintf(stderr, "%s:%d:%s\n", fname_, line_, ss_.str().c_str());
   55|      0|      exit(1);
   56|      0|    }
   57|      0|  }
   58|       |
   59|      0|  Tester& Is(bool b, const char* msg) {
   60|      0|    if (!b) {
   61|      0|      ss_ << " Assertion failure " << msg;
   62|      0|      ok_ = false;
   63|      0|    }
   64|      0|    return *this;
   65|      0|  }
   66|       |
   67|      0|  Tester& IsOk(const Status& s) {
   68|      0|    if (!s.ok()) {
   69|      0|      ss_ << " " << s.ToString();
   70|      0|      ok_ = false;
   71|      0|    }
   72|      0|    return *this;
   73|      0|  }
   74|       |
   75|       |#define BINARY_OP(name, op)                          \
   76|       |  template <class X, class Y>                        \
   77|       |  Tester& name(const X& x, const Y& y) {             \
   78|       |    if (!(x op y)) {                                 \
   79|       |      ss_ << " failed: " << x << (" " #op " ") << y; \
   80|       |      ok_ = false;                                   \
   81|       |    }                                                \
   82|       |    return *this;                                    \
   83|       |  }
   84|       |
   85|       |  BINARY_OP(IsEq, ==)
   86|       |  BINARY_OP(IsNe, !=)
   87|       |  BINARY_OP(IsGe, >=)
   88|       |  BINARY_OP(IsGt, >)
   89|       |  BINARY_OP(IsLe, <=)
   90|       |  BINARY_OP(IsLt, <)
   91|       |#undef BINARY_OP
   92|       |
   93|       |  // Attach the specified value to the error message if an error has occurred
   94|       |  template <class V>
   95|      0|  Tester& operator<<(const V& value) {
   96|      0|    if (!ok_) {
   97|      0|      ss_ << " " << value;
   98|      0|    }
   99|      0|    return *this;
  100|      0|  }
  101|       |};
  102|       |
  103|      0|#define ASSERT_TRUE(c) ::leveldb::test::Tester(__FILE__, __LINE__).Is((c), #c)
  104|       |#define ASSERT_OK(s) ::leveldb::test::Tester(__FILE__, __LINE__).IsOk((s))
  105|       |#define ASSERT_EQ(a, b) \
  106|       |  ::leveldb::test::Tester(__FILE__, __LINE__).IsEq((a), (b))
  107|       |#define ASSERT_NE(a, b) \
  108|       |  ::leveldb::test::Tester(__FILE__, __LINE__).IsNe((a), (b))
  109|       |#define ASSERT_GE(a, b) \
  110|       |  ::leveldb::test::Tester(__FILE__, __LINE__).IsGe((a), (b))
  111|       |#define ASSERT_GT(a, b) \
  112|       |  ::leveldb::test::Tester(__FILE__, __LINE__).IsGt((a), (b))
  113|       |#define ASSERT_LE(a, b) \
  114|       |  ::leveldb::test::Tester(__FILE__, __LINE__).IsLe((a), (b))
  115|       |#define ASSERT_LT(a, b) \
  116|       |  ::leveldb::test::Tester(__FILE__, __LINE__).IsLt((a), (b))
  117|       |
  118|       |#define TCONCAT(a, b) TCONCAT1(a, b)
  119|       |#define TCONCAT1(a, b) a##b
  120|       |
  121|       |#define TEST(base, name)                                              \
  122|       |  class TCONCAT(_Test_, name) : public base {                         \
  123|       |   public:                                                            \
  124|       |    void _Run();                                                      \
  125|       |    static void _RunIt() {                                            \
  126|       |      TCONCAT(_Test_, name) t;                                        \
  127|       |      t._Run();                                                       \
  128|       |    }                                                                 \
  129|       |  };                                                                  \
  130|       |  bool TCONCAT(_Test_ignored_, name) = ::leveldb::test::RegisterTest( \
  131|       |      #base, #name, &TCONCAT(_Test_, name)::_RunIt);                  \
  132|       |  void TCONCAT(_Test_, name)::_Run()
  133|       |
  134|       |// Register the specified test.  Typically not used directly, but
  135|       |// invoked via the macro expansion of TEST.
  136|       |bool RegisterTest(const char* base, const char* name, void (*func)());
  137|       |
  138|       |}  // namespace test
  139|       |}  // namespace leveldb
  140|       |
  141|       |#endif  // STORAGE_LEVELDB_UTIL_TESTHARNESS_H_

